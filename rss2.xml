<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Velih&#39;s Blog</title>
    <link>https://velih.de/</link>
    
    <atom:link href="https://velih.de/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description></description>
    <pubDate>Thu, 23 May 2024 12:56:08 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>大鹏半岛海柴角地名资料收集</title>
      <link>https://velih.de/2023/02/22/7PJPGJ5G+VW/</link>
      <guid>https://velih.de/2023/02/22/7PJPGJ5G+VW/</guid>
      <pubDate>Wed, 22 Feb 2023 11:24:01 GMT</pubDate>
      
        
        
          
          
      <description></description>
          
        
      
      
      
      <content:encoded><![CDATA[<p>海柴角位于大鹏半岛，这里目前还没有被开发，因为礁石林立，风急浪高，船只靠岸也很困难，徒步几乎是达到的唯一选择。</p><p>海柴角地名是深圳特区成立后才有，在此之前海柴角有不少曾用名。就像是甲岸村之于隔岸村，羊台山之于阳台山、羊蹄山，海柴角似乎是另一个“地名规范”的受害者，只是相比前两者，海柴角人迹罕至，更鲜有人为之发声。</p><p>本文尽可能收集了有关海柴角的历史文献资料，由于不具备历史地理学、语言学等相关专业的研究知识，所以暂只限于收集。</p><h2 id="海柴角">海柴角</h2><p>1987年《深圳市地名志》中如下描述海柴角：</p><blockquote><p>在大鹏区三门岛北面 4.3 公里，突出海面 0.55 公里，植被较好，由花岗岩构成，因此角无风三尺浪，有风浪头百丈高，惊涛拍岸似劈柴声而得名。</p></blockquote><p>此后海柴角便成为官方正式用名。</p><p><img src="%E5%A4%A7%E9%B9%8F%E5%8D%8A%E5%B2%9B.%E6%B7%B1%E5%9C%B3%E5%B8%82%E8%A1%8C%E6%94%BF%E5%8C%BA%E5%88%92%E5%9B%BE.2008.%E6%B7%B1%E5%9C%B3%E5%B8%82%E6%B0%91%E6%94%BF%E5%B1%80.%E6%96%B9%E8%88%86.%E5%8E%9FTIF%E8%BD%ACJPG.jpg" alt="深圳市行政区划图大鹏半岛|2008|深圳市民政局"></p><h2 id="鞋柴角">鞋柴角</h2><p>东涌本地居民称之为鞋柴角。东涌股份在其官网<a href="http://www.szdongchong.com/?r=post/show&amp;id=34">写到</a>：</p><blockquote><p>海柴角是大鹏湾和大亚湾的流水界，浪大流急，海上漂浮物都汇聚到这一带，附近渔民经常在此处见到漂浮的鞋和木材，故名鞋柴角。1986年，深圳地名委员会正式定名为海柴角。大鹏山歌中这样唱道：“鞋柴无风三尺浪”，“无风起浪是骇豺”。</p></blockquote><p>另有大鹏山歌《村落歌》唱：</p><blockquote><p>“杨梅冲茶鹿咀角，大水坑打紫菜回。马料河水流冲街，大围炊烟熏<strong>鞋柴</strong>。”</p></blockquote><p>1983年出版的《深圳地貌》记录深圳市经纬度范围时写到：</p><blockquote><p>深圳市的经纬度位置，按陆地计，南起北纬22°26′59″（大鹏半岛南端），北至北纬22°51′49″（罗田水库北缘），西起东经113°45′44″（沙井均益围），东至东经114°37′2″（大鹏半岛<strong>鞋柴角</strong>）；按岛屿计，最南点为北纬22°24′01″（内伶仃岛东角咀）；最西点为东经113°46′50″（内伶仃岛牛利角）；按海界计，南起北纬22°09′，西起东经113°9′36″，东至东经114°8′43″。</p></blockquote><p>1999年出版的《广东省志：地名志》与2014年出版的《广东省志（1979-2000）：行政区划·地名卷》介绍七娘山时均使用鞋柴角：</p><blockquote><p>七娘山又名大鹏山。在宝安县东部，大鹏半岛南段的南澳镇境内。东起<strong>鞋柴角</strong>，西至枫木浪水库，南起东角，北至东山。面积约45平方公里。主峰海拔867.4米，是宝安县第一高峰。该山7个山峰，相传是七仙女下凡所成，故名。</p></blockquote><p>1988年-1990年之间由深圳市国土局编写的《深圳市国土规划》甚至同时使用了鞋柴角和海柴角两个名称：</p><ul><li>在第1页使用 <em>海柴角</em> 名称记录深圳市地理位置：</li></ul><blockquote><p>深圳市位于北纬22°27′（大鹏半岛南端）──22°52′（罗田水库北缘），东经113°46′（沙井均益围）──114°37′（大鹏半岛<strong>海柴角</strong>）。</p></blockquote><ul><li>在第72页使用 <em>鞋柴角</em> 名称记录深圳东部海岸线范围：</li></ul><blockquote><p>东部海岸线从沙头角至与惠阳交界的白沙湾总长约155公里,其中特区岸线21.4公里。主要由大鹏湾和大亚湾组成，其中大鹏湾岸线长约60公里，大鹏半岛端部（穿岩至<strong>鞋柴角</strong>）岸线24公里，大亚湾海岸线71公里。</p></blockquote><p>但在历史资料中未见有“鞋柴角”，倒是有不少类似的名字：</p><h3 id="崖柴角">崖柴角</h3><p>《粤大记》、《雍正广东通志》、《嘉庆新安县志》这三本地方志书都标注为<strong>崖柴角</strong>：<br><img src="%E5%B9%BF%E4%B8%9C%E6%B2%BF%E6%B5%B7%E5%9B%BE.1595.%E7%B2%A4%E5%A4%A7%E8%AE%B0.%E6%98%8E%E4%B8%87%E5%8E%86%E5%BB%BF%E4%B8%89%E5%B9%B4.%E9%83%AD%E6%A3%90.%E4%B9%A6%E7%9B%AE%E6%96%87%E7%8C%AE%E5%87%BA%E7%89%88%E7%A4%BE.1990.%E5%8D%B7%E4%B8%89%E5%8D%81%E4%BA%8C%E6%B5%B7%E9%98%B2%E5%9B%BE.png" alt="粤大记.广东沿海图|1595.明万历廿三年|郭棐|《粤大记·卷三十二海防图》书目文献出版社.1990"><br><img src="%E5%B9%BF%E4%B8%9C%E6%B5%B7%E9%98%B2%E5%9B%BE.1731.%E9%9B%8D%E6%AD%A3%E5%B9%BF%E4%B8%9C%E9%80%9A%E5%BF%97.%E6%B8%85%E9%9B%8D%E6%AD%A3%E4%B9%9D%E5%B9%B4.%E9%83%9D%E7%8E%89%E9%BA%9F.%E9%92%A6%E5%AE%9A%E5%9B%9B%E5%BA%93%E5%85%A8%E4%B9%A6.%E6%96%87%E6%B8%8A%E9%98%81%E5%9B%9B%E5%BA%93%E5%85%A8%E4%B9%A6.%E5%8F%B0%E6%B9%BE%E5%95%86%E5%8A%A1%E5%8D%B0%E4%B9%A6%E9%A6%86.1986.%E5%B9%BF%E4%B8%9C%E9%80%9A%E5%BF%97%E4%B8%80.%E5%8D%B7%E4%B8%89%E8%88%86%E5%9B%BE.png" alt="雍正广东通志.广东海防图|1731.清雍正九年|郝玉麟|《文渊阁四库全书·雍正广东通志·卷三舆图》台湾商务印书馆.1986"><br><img src="%E6%96%B0%E5%AE%89%E5%8E%BF%E8%88%86%E5%9B%BE.1819.%E6%96%B0%E5%AE%89%E5%8E%BF%E5%BF%97.%E6%B8%85%E5%98%89%E5%BA%86%E4%BA%8C%E5%8D%81%E5%9B%9B%E5%B9%B4.%E8%88%92%E6%87%8B%E5%AE%98.%E7%8E%8B%E5%B4%87%E7%86%99.Education.in.Hong.Kong.Pre-1841-1941.Anthony.Sweeting.1990.png" alt="《新安县志》新安县舆图|1819.清嘉庆二十四年|舒懋官.王崇熙|《Education in Hong Kong: Pre 1841-1941》Anthony Sweeting.1990"></p><h3 id="𩋘濟角-鞋㨈角">𩋘<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>濟角/鞋㨈角</h3><p><img src="%E5%BB%A3%E6%9D%B1%E6%B2%BF%E6%B5%B7%E7%B5%B1%E5%B1%AC%E5%9C%96.%E6%B8%85%E9%81%93%E5%85%89%E5%8D%81%E4%B9%9D%E5%B9%B4%EF%BC%881839%EF%BC%89%E5%89%8D.%E8%AD%9A%E5%BB%A3%E6%BF%82%E5%80%9F%E5%B1%95.%E9%A6%99%E6%B8%AF%E6%B5%B7%E4%BA%8B%E5%8D%9A%E7%89%A9%E9%A4%A8.GoogleArt.jpg" alt="廣東沿海統屬圖|清道光十九年（1839）前|譚廣濂借展|香港海事博物館|GoogleArt"><br><img src="%E5%8D%97%E4%B8%AD%E5%9B%BD%E6%B5%B7%E5%B2%B8%E5%9B%BE%EF%BC%88%E5%B1%80%E9%83%A8%EF%BC%89.18--.%E4%BD%9A%E5%90%8D.%E6%B3%95%E5%9B%BD%E5%9B%BD%E5%AE%B6%E5%9B%BE%E4%B9%A6%E9%A6%86%E8%97%8F.%E6%BE%B3%E9%97%A8%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E5%9B%BE%E4%B9%A6%E9%A6%86.jpeg" alt="南中国海岸图（局部）|18--|佚名|法国国家图书馆藏|澳门科技大学图书馆"></p><h3 id="鞋揽角">鞋揽角</h3><p>1730年《海国闻见录》将其标注为<strong>鞋攬角</strong>，在清中后期出现了一批以之为底本的摹绘本海图，这些摹绘本基本都按照<strong>鞋攬角</strong>进行标注，如<a href="http://lunamap.must.edu.mo/luna/servlet/detail/MUST~2~2~907~627%3A%E4%B8%AD%E8%8F%AF%E6%B2%BF%E6%B5%B7%E5%BD%A2%E5%8B%A2%E5%85%A8%E5%9C%96--Part-5">《中华沿海形势全图》</a>、<a href="https://digitalatlas.asdc.sinica.edu.tw/map.jsp?id=A103000138#">《海疆洋界形势全图》</a> 等等<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>。</p><p><img src="%E6%B2%BF%E6%B5%B7%E5%85%A8%E5%9B%BE.1730.%E6%B5%B7%E5%9B%BD%E9%97%BB%E8%A7%81%E5%BD%95.%E9%9B%8D%E6%AD%A3%E5%85%AB%E5%B9%B4.%E9%99%88%E4%BC%A6%E7%82%AF.%E9%92%A6%E5%AE%9A%E5%9B%9B%E5%BA%93%E5%85%A8%E4%B9%A6.%E6%96%87%E6%B8%8A%E9%98%81%E5%9B%9B%E5%BA%93%E5%85%A8%E4%B9%A6.%E5%8F%B0%E6%B9%BE%E5%95%86%E5%8A%A1%E5%8D%B0%E4%B9%A6%E9%A6%86.1986.%E6%B5%B7%E5%9B%BD%E9%97%BB%E8%A7%81%E5%BD%95.%E4%B8%8B%E5%8D%B7%E5%8D%81%E5%9B%9B.png" alt="海国闻见录.沿海全图|1730.雍正八年|陈伦炯|《文渊阁四库全书·海国闻见录·下卷十四》台湾商务印书馆.1986"><br><img src="%E4%B8%AD%E5%8D%8E%E6%B2%BF%E6%B5%B7%E5%BD%A2%E5%8A%BF%E5%85%A8%E5%9B%BE%EF%BC%88%E5%B1%80%E9%83%A8%EF%BC%89.1774-1795.%E4%BD%9A%E5%90%8D.%E5%8C%97%E4%BA%AC%E5%A4%A7%E5%AD%A6%E5%9B%BE%E4%B9%A6%E9%A6%86%E8%97%8F.%E6%BE%B3%E9%97%A8%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E5%9B%BE%E4%B9%A6%E9%A6%86.jpeg" alt="中华沿海形势全图（局部）|1774-1795|佚名|北京大学图书馆藏|澳门科技大学图书馆"></p><h2 id="奚齐角-蹊跻角">奚齐角/蹊跻角</h2><p>清同治年间（1862-1875）《广东图志》<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>载：</p><blockquote><p>县东北海岸与归善县西南海岸以大鹏山分界，东南为上太阬村，又屈西南过大鹏所城，又西南过水头村，又屈东南过东山村，又东南过杨梅阬，又东南过鹿嘴角，又东南过<strong>蹊跻角</strong>，又屈西南过东涌口，又西南过老大鹏汛，又屈西北过西涌口，又西北，过鹅公湾(海船可以寄碇)，又西北过沙鱼涌口，又西北过葵涌……</p></blockquote><p>这是<strong>蹊跻角</strong>这一名字的最早记录，没有被标注在配图中，不过同时期的《广东图》中标注有<strong>蹊跻角</strong>:<br><img src="%E6%96%B0%E5%AE%89.%E5%BB%A3%E6%9D%B1%E5%9C%96%E4%BA%8C%E5%8D%81%E4%B8%89%E5%8D%B7.1866_GZDD023428001_0040.png" alt="广东图.新安|1866.清同治五年刻本|《广州大典》"></p><p>1897年（清光绪二十三年）《广东舆地全图》在《新安县图》中标注了<strong>蹊跻角</strong>，配文和《广东图志》类似，1909年（清宣统元年）《广东图说十四卷首一卷》配相同文字：</p><blockquote><p>县东北海岸与归善县西南海岸以大鹏山分界，西南为岭下，又西南过大坑村，屈西北过大鹏所城，屈西北过水头村，又南过蛟田村，屈东北过东山，屈东南过东山村杨梅阬，屈东过鹿嘴角，屈西南过<strong>蹊跻角</strong>东涌口，屈西北过西涌口老大鹏汛……</p></blockquote><p><img src="%E5%B9%BF%E4%B8%9C%E8%88%86%E5%9C%B0%E5%85%A8%E5%9B%BE_%E6%96%B0%E5%AE%89%E5%8E%BF%E5%9B%BE%E8%A1%A8_%E6%96%B0%E5%AE%89%E5%8E%BF%E5%9B%BE%EF%BC%88%E5%B1%80%E9%83%A8%EF%BC%89%7C1897.%E6%B8%85%E5%85%89%E7%BB%AA%E4%BA%8C%E5%8D%81%E4%B8%89%E5%B9%B4%7C%E5%BC%A0%E4%BA%BA%E9%AA%8F.jpg" alt="广东舆地全图_新安县图表_新安县图（局部）|1897.清光绪二十三年|张人骏|香港中文大学图书馆"></p><!-- https://repository.lib.cuhk.edu.hk/en/item/cuhk-2448416 --><p>1926年《七省沿海形胜图其四之南日屿至三央口》中标注为<strong>溪跻角</strong>：<br><img src="%E4%B8%83%E7%9C%81%E6%B2%BF%E6%B5%B7%E5%BD%A2%E5%8B%9D%E5%9C%96.%E5%85%B6%E5%9B%9B.%E8%87%AA%E5%8D%97%E6%97%A5%E5%B6%BC%E8%87%B3%E4%B8%89%E5%A4%BE%E5%8F%A3%EF%BC%88%E5%B1%80%E9%83%A8%EF%BC%89_1926_%E7%AB%A5%E4%B8%96%E4%BA%A8_%E5%95%86%E5%8B%99%E5%8D%B0%E6%9B%B8%E9%A4%A8.%E6%B0%91%E5%9B%BD%E5%8D%81%E4%BA%94%E5%B9%B4%E5%86%8D%E7%89%88_%E5%93%88%E4%BD%9B%E5%A4%A7%E5%AD%A6%E5%9B%BE%E4%B9%A6%E9%A6%86.png" alt="七省沿海形勝圖.其四.自南日嶼至三夾口（局部）|1926|童世亨|商務印書館.民国十五年再版|哈佛大学图书馆"></p><p>在几组民国时期由广东省陆地测量局测绘的地形图中，1930年12月印制的广东省十万分一地形图（CMS L100-81）《平海》中标注<strong>蹊跻角</strong>：<br><img src="CMSL100-81_%E5%B9%B3%E6%B5%B7%EF%BC%88%E5%B1%80%E9%83%A8%EF%BC%89.jpg" alt="十萬分一廣東省地形圖（CMS L100-81）平海（局部）|1930|軍事委員會軍令部陸地測量總局|國立臺灣大學圖書館"></p><p>1930年测绘1945年印刷的广东五万分一地形图《大鹏》中标注<strong>奚齊角</strong>：<br><img src="%E5%BB%A3%E6%9D%B1%E4%BA%94%E8%90%AC%E5%88%86%E4%B8%80%E5%9C%B0%E5%BD%A2%E5%9C%96.%E5%A4%A7%E9%B9%8F%EF%BC%88%E5%B1%80%E9%83%A8%EF%BC%89.1930.jpg" alt="廣東五萬分一地形圖|1930年测绘|軍事委員會軍令部第四廳|中央研究院"></p><p>1930年代制作的<a href="https://gis.sinica.edu.tw/showwmts/index.php?s=ccts&amp;l=China_50K_Guangdong">五万分一广东省地形图</a>（CMS L50-81）<a href="https://catalog.digitalarchives.tw/item/00/85/43/c8.html">《大鹏》</a>中标注<strong>奚齊角</strong>：<br><img src="CMSL50-81_%E5%A4%A7%E9%B5%AC%EF%BC%88%E5%B1%80%E9%83%A8%EF%BC%89.jpg" alt="五萬分一廣東省地形圖（CMS L50-81）大鵬（局部）|1930|中央研究院"></p><p>1938年一幅由台湾总督府文教局学务课制作的《广东省地图》中，标有<strong>釒奚角</strong><sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>：<br><img src="%E5%BB%A3%E6%9D%B1%E7%9C%81%E5%9C%B0%E5%9C%96%EF%BC%88%E5%B1%80%E9%83%A8%EF%BC%89_1938.%E6%98%AD%E5%92%8C13%E5%B9%B4_%E8%87%BA%E7%81%A3%E7%B8%BD%E7%9D%A3%E5%BA%9C%E6%96%87%E6%95%8E%E5%B1%80%E5%AD%B8%E5%8B%99%E8%AA%B2_%E9%A6%99%E6%B8%AF%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E5%9B%BE%E4%B9%A6%E9%A6%86.jpg" alt="廣東省地圖（局部）|1938.昭和13年|臺灣總督府文敎局學務課|香港科技大学图书馆"></p><!-- https://lbezone.hkust.edu.hk/bib/b923439 --><p>1949年由英国陆军部 (Great Britain War Office) 制作发行的名为《Kwangtung 1:50000》(GSGS 4691) 的广东省中英双语地图中，标注为<strong>奚齐角（HSI-CH’I CHIAO）</strong>：<br><img src="Chinese.Province.of.Kwangtung.Part.1949.National.Library.of.Australia.hkmaps.hk.jpg" alt="Kwangtung 1:50000.Ch'i-Niang Shan &amp; San-Men|1949|National Library of Australia|hkmaps.hk"></p><!-- https://catalogue.nla.gov.au/catalog/1525528 --><p>一张1930年之前由英国水文局（UKHO）制作的名为<a href="https://hydrographic.epexio.com/records/COD/2/17/1/3026">《Chart 3026: China, south east coast. Macau to Pedro Blanco, including Hong Kong, pre-1930》</a>的海事地图同样标注为 <strong>Hsi Chi Chiao</strong><sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>。此图的布局与1976年国内出版的名为《大星山角到珠江口》的航海图非常类似，后者在同样的位置被标注为<strong>鞋柴角（Xiechai Jiǎo）</strong>。<br><img src="%E5%A4%A7%E6%98%9F%E5%B1%B1%E8%A7%92%E5%88%B0%E7%8F%A0%E6%B1%9F%E5%8F%A3%EF%BC%88%E5%B1%80%E9%83%A8%EF%BC%89.%E5%BE%9E%E5%9C%93%E6%96%B9%E5%88%B0%E7%B6%93%E7%B7%AF_%E9%A6%99%E6%B8%AF%E8%88%87%E8%8F%AF%E5%8D%97%E6%AD%B7%E5%8F%B2%E5%9C%B0%E5%9C%96%E8%97%8F%E7%8F%8D_%E8%AD%9A%E5%BB%A3%E6%BF%82_%E4%B8%AD%E8%8F%AF%E6%9B%B8%E5%B1%80_2010.jpg" alt="大星山角到珠江口（局部）|1976|《從圓方到經緯：香港與華南歷史地圖藏珍》譚廣濂.中華書局.2010"></p><p>1965年广东省人民委员会发布的《珠江口渔场管理试行规定》中使用<strong>奚齐角</strong>界定珠江口海域的2、3号渔场：</p><blockquote><p>规定：东至惠阳县属大星簪岩开始，西至珠海县荷包岛的凤尾嘴之间的海域。这一海域划分为10个海区。各海区位置是:<br>……<br>(2)从宝安县大鹏角(即北纬22°27’，东经114°30.5’)开始，经大亚湾的钓鱼公小星山南角、大六甲岛、<strong>奚齐角</strong>连接线以内为第3号海区。此海区允许流动渔船中载重10吨、20匹马力以下的机动灯光罟、小钓艇、风帆灯光罟和其他小艇进人生产。<br>(3)从宝安县的<strong>奚齐角</strong>(即北纬22°34’，东经114°39.3’)，小星山南角(即北纬22°35.5’，东经114°50.5’)，大星山角(即北纬22°32.7’，东经114°53.1’))的连接线以北的大亚湾内海为第4号海区。<br>……</p><p>– <cite>摘自 2001年出版的《珠海市志》</cite></p></blockquote><p>2020年6月台风鹦鹉影响深圳期间，有游客被困<strong>奚齐角</strong>：</p><blockquote><p>就在台风登陆的前一天，6月13日，大鹏新区警方接到市民户外穿越被困警情：三名游客于当日11时许，在南澳办事处海柴角海岸线往东涌方向奚齐角爬山，因体力不支迷路被困。</p><p>– <cite>2020年6月15日《深圳晚报》《大鹏：联合救援队救出被困风雨中三游客》<a href="https://wb.sznews.com/PC/layout/202006/15/node_A03.html">https://wb.sznews.com/PC/layout/202006/15/node_A03.html</a></cite></p></blockquote><p>同样是《深圳晚报》，2012年7月24日有题为<a href="https://news.ifeng.com/c/7fckebmEGIw">《风大雨大6驴友被困<strong>海柴角</strong>》</a>的报道。</p><p>目前的 Google 地图有趣得同时显示了海柴角，鞋柴角，奚齐角三个名称：<br><img src="%E5%A5%9A%E9%BD%90%E8%A7%92.GoogleMap.202302.jpg" alt="奚齐角|Google 地图|2023年2月"></p><h2 id="参考">参考</h2><ul><li><a href="http://www.ccartoa.org.tw/news/2021/202108.html">廣東測繪機構之歷史地圖(光緒31年〜民國28年) - 許哲明</a></li><li><a href="http://www.ccartoa.org.tw/news/2022/202202.html">早期大陸地區《五萬分一地形圖》製作之概況 - 許哲明</a></li><li><a href="http://www.ccartoa.org.tw/news/2020/202006.html">大陸地區十萬分一民國圖 - 許哲明</a></li></ul><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>见<a href="https://www.zdic.net/hans/%F0%A9%8B%98">左：革，右：隹 - 汉典</a> ，同“鞋”。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>具体列表可见成一农《明清海防总图研究》。 <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>《广东图志九十二卷首一卷》有多个版本，部分版本名为《广东图说》，需要与《广东图说十四卷首一卷》相区别。 <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>该字疑似错字，查无此异体字，见<a href="https://dict.variants.moe.edu.tw/searchR.jsp?ID=8&amp;ID=167&amp;ID=10&amp;page=1">部首查询 [8画, 金, +10] - 教育部《异体字字典》</a> <a href="#fnref4" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>UKHO 已有200多年的海事地图制作历史，其公开的少数 Admiralty Chart 并没有高清图，但是 <strong>Hsi Chi Chiao</strong> 可以从此图中辨认出来。 <a href="#fnref5" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content:encoded>
      
      
      
      <category domain="https://velih.de/tags/%E6%94%B6%E9%9B%86/">收集</category>
      
      
      <comments>https://velih.de/2023/02/22/7PJPGJ5G+VW/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>IPFS 静态网站部署指南</title>
      <link>https://velih.de/2023/02/02/ipfs-static-site/</link>
      <guid>https://velih.de/2023/02/02/ipfs-static-site/</guid>
      <pubDate>Thu, 02 Feb 2023 12:05:43 GMT</pubDate>
      
        
        
          
          
      <description></description>
          
        
      
      
      
      <content:encoded><![CDATA[<p>与四年前写博客 在 IPFS 上部署静态博客 时相比，现在 IPFS 更加成熟了，也多了很多相关的服务，也考虑到原来的博文现在看来有点繁琐且过时，所以这次进行了重构并添加了周边服务的介绍。</p><h2 id="1-安装-IPFS">1. 安装 IPFS</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 IPFS，此处使用 brew 为例</span></span><br><span class="line">brew install ipfs</span><br><span class="line"><span class="comment"># 初始化，生成本地公私钥，默认配置等</span></span><br><span class="line">ipfs init</span><br><span class="line"><span class="comment"># 保持 IPFS 运行</span></span><br><span class="line">ipfs daemon</span><br></pre></td></tr></table></figure><h2 id="2-IPFS-本地访问静态页面">2. IPFS 本地访问静态页面</h2><p>一般我们的静态页面都包含一个 index.html，放在 public 文件夹中，现在将 public 文件夹添加到 IPFS 中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipfs add -r public</span><br></pre></td></tr></table></figure><p>产生如下输入，表明添加成功</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">added QmT47uvcmBktejvAmKgEUwZjCUZQpvmdd2ZxgT5LsfmjFJ public/content-hash.js</span><br><span class="line">added QmXeszC4BUxYc9kX2RA3hTLXUJYhh6qSGvs7qcHJq9XmkE public/index.html</span><br><span class="line">added QmW3bcW7H3j1jxutqrLWZ959wF5Qj3iD1VgnK3Vm46cbH2 public/my-decoder.js</span><br><span class="line">added QmdkSpWEaZFM6iPGbtDqkd6bukw7BijNkxaG5a7L5vYoRL public</span><br><span class="line">  187.86 KiB / 187.86 KiB [=======================================================] 100.00%</span><br></pre></td></tr></table></figure><p>使用 public 目录的 CID 通过本地 IPFS Gateway 便可访问这个简单的网页 <a href="http://localhost:8080/ipfs/QmdkSpWEaZFM6iPGbtDqkd6bukw7BijNkxaG5a7L5vYoRL">http://localhost:8080/ipfs/QmdkSpWEaZFM6iPGbtDqkd6bukw7BijNkxaG5a7L5vYoRL</a></p><h2 id="3-借助-IPNS-保持链接不变">3. 借助 IPNS 保持链接不变</h2><p>如果现在我们的网页发生一些变更，则变更后的 public 目录 CID 会发生变化，导致网页访问地址发生变化，否则就只能访问旧版本的网页，IPNS 就用于解决这个问题。</p><p>通过以下命令将 public 目录的 CID 发布(绑定)到当前节点的 PeerID（节点公钥的哈希）。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipfs name publish QmdkSpWEaZFM6iPGbtDqkd6bukw7BijNkxaG5a7L5vYoRL</span><br></pre></td></tr></table></figure><p>输出如下，k51q…jzot 便是 PeerID。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Published to k51qzi5uqu5dgcop6koxxjmjg6ul5u14g5up8xsyxdarr21r6s1565qie6jzot: /ipfs/QmdkSpWEaZFM6iPGbtDqkd6bukw7BijNkxaG5a7L5vYoRL</span><br></pre></td></tr></table></figure><p>现在我们可以通过 <a href="http://localhost:8080/ipns/k51qzi5uqu5dgcop6koxxjmjg6ul5u14g5up8xsyxdarr21r6s1565qie6jzot">http://localhost:8080/ipns/k51qzi5uqu5dgcop6koxxjmjg6ul5u14g5up8xsyxdarr21r6s1565qie6jzot</a> 访问简单网页（每个节点因为私钥不同，所以 PeerID 也不同，你需要改变链接中的 PeerID 部分再尝试访问），之后如果网页有所变更，只要再次 name publish 操作便仍然可以使用此链接访问变更后的网页。</p><h2 id="4-绑定域名缩短访问链接">4. 绑定域名缩短访问链接</h2><p>目前的访问链接很长，我们可以把 ipns 绑定到自己拥有的域名来缩短访问链接，以托管在 cloudflare 的本站域名 <a href="http://velih.de">velih.de</a> 为例，在 DNS 管理中添加一条 TXT 记录，Name 配置为 <code>_dnslink.你的子域名名称</code>，直接使用一级域名则配置为 <code>_dnslink</code>，Content 配置为 <code>dnslink=/ipns/你的IPNS</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TXT _dnslink.enstool.velih.de dnslink=/ipns/k51qzi5uqu5dgcop6koxxjmjg6ul5u14g5up8xsyxdarr21r6s1565qie6jzot</span><br></pre></td></tr></table></figure><p>现在我们可以直接通过 <a href="http://localhost:8080/ipns/enstool.velih.de">http://localhost:8080/ipns/enstool.velih.de</a> 来访问简单网页了。然后我们将本地 Gateway 地址替换为<a href="https://ipfs.github.io/public-gateway-checker/">公共 Gateway 列表</a>中的域名实现公网访问了，比如：</p><ul><li><a href="https://cf-ipfs.com/ipns/enstool.velih.de">https://cf-ipfs.com/ipns/enstool.velih.de</a></li><li><a href="https://4everland.io/ipns/enstool.velih.de">https://4everland.io/ipns/enstool.velih.de</a></li></ul><h2 id="5-域名直接访问">5. 域名直接访问</h2><p>再进一步，继续为域名添加一条 CNAME 记录，Name 配置为你的子域名名称，一级域名则设置为 <code>@</code>，Content 配置为一个公共的或者自建的 Gateway，我这里将 <code>enstool</code> 这个子域名绑定到了 Cloudflare 提供的公共 Gateway <code>cf-ipfs.com</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CNAME enstool.velih.de cf-ipfs.com</span><br></pre></td></tr></table></figure><p>此时，可以直接通过 <a href="https://enstool.velih.de">https://enstool.velih.de</a> 进行访问了。</p><h2 id="6-去中心化域名访问：以-ENS-为例">6. 去中心化域名访问：以 ENS 为例</h2><p>域名存在一些中心化的问题，比如注册机构是中心化的，DNS 的解析是中心化的，去中心化域名提供了另一种选择。</p><p>在 <a href="https://eips.ethereum.org/EIPS/eip-1577">EIP-1557</a> 中 ENS 开始支持 ContentHash，IPNS 就是可以配置的 ContentHash 的一种。只要为 ENS 配置上 IPNS 便可以连接 ENS 与存在 IPFS 中的内容了。</p><p>以 <code>velih.eth</code> 为例，在该 ENS 的<a href="https://app.ens.domains/name/velih.eth">管理界面</a>，点击 <em><strong>ADD/EDIT RECORD</strong></em>，选择添加 <em><strong>Content</strong></em>，值设置为 <code>/ipns/你的IPNS</code>，注意这一步会产生一笔交易，一定要确定填写的内容的正确性，<em><strong>Save</strong></em> 保存后再点击下方 <em><strong>Confirm</strong></em> 确认，与钱包交互签名交易，交易确认后便可以通过以下方式使用 ENS 访问网站了：</p><ul><li>使用 ENS 解析网关<ul><li>eth.limo：访问 <a href="https://velih.eth.limo">https://velih.eth.limo</a></li><li>eth.link：访问 <a href="https://velih.eth.link">https://velih.eth.link</a></li></ul></li><li>浏览器插件<ul><li>MetaMask：访问 <a href="https://velih.eth">https://velih.eth</a></li><li>IPFS Companion：运行本地 IPFS 实例后，访问 <a href="https://velih.eth">https://velih.eth</a></li></ul></li><li>在支持 ENS 的浏览器中直接访问<ul><li>Brave：访问 <a href="velih.eth">velih.eth</a></li><li>Opera：访问 <a href="ipns://velih.eth">ipns://velih.eth</a></li></ul></li></ul><p>另一种常用的 ContentHash 是 IPFS 的 CID，格式为 <code>/ipfs/cid</code> 或者 <code>ipfs://cid</code>。这种方式问题在于之前提到的，每次网页变更都需要重新配置一次，也就是需要产生一笔花费手续费的交易，因此适合不怎么变更的内容。不过 Ethereum 创始人 Vitalik 的博客 ENS vitalik.eth 就使用的这种形式。每次 Vitalik 发布新的文章后都会通过交易变更 IPFS CID，比如 Vitalik 发布 2022 年最后一篇文章后便执行<a href="https://etherscan.io/tx/0x93d97a0d291843f5cd726c03be855297e1ad45d5a7182da02a9c7c162c9e8167">交易</a>，以变更 vitalik.eth 的 ContentHash 为 0xe301017012208007f6b5b03e0aa1d1829c568ce4f52e177058448b73ad8d831228931925900f，通过 Content Hash Decoder 工具可以转换得到实际内容为 /ipfs/QmWxRwMg3bHyJxfAuPnUky2yNgNt51qmZqC99Ffenjxa94，便是此时博客根目录的 IPFS CID。</p><div style="width: 100%;" >    <script type="text/javascript" src="/js/ipfs/content-hash.js"></script>    <label>Content Hash Decoder</label><br>    <input type="text" id="input_ch" placeholder="Paste a content hash here to decode" size="85"        style="line-height: 1.15;padding: 0.5rem;"><br>    <div style="display: none;" id="div_result">        <span>Codec: </span><span id="span_result_codec"></span><br>        <span>Content: </span><span id="span_result_content"></span>    </div>    <script>        const input = document.getElementById('input_ch');        const div_result = document.getElementById('div_result');        const span_result_codec = document.getElementById('span_result_codec');        const span_result_content = document.getElementById('span_result_content');        input.addEventListener('input', (e) => {            const content = contentHash.decode(e.target.value);            const codec = contentHash.getCodec(e.target.value);            span_result_codec.textContent = codec;            span_result_content.textContent = content;            div_result.style.display = "block"        });    </script></div><p>CID 作为 ContentHash 的方式对大部分人来说有些“昂贵”，特别是 Ethereum GasPrice 比较高的时候，但是对于 Vitalik 来说可能没有那么贵，而且可以省去运行 IPFS 节点维护 IPNS（见 可用性优化）私钥的麻烦，而且有大量的第三方主动帮忙 Pin Vitalik 的博客。所以对他来说是更优的选择。</p><p>另外 .bit、HNS 这些去中心化域名也支持类似的方式进行配置访问。</p><h2 id="7-可用性优化">7. 可用性优化</h2><p>我们引入了 IPNS 来优化访问链接，但是 IPNS 的默认传输广播机制是通过 DHT 进行的，对等节点会在 24 小时后遗忘 IPNS 记录。因此自己的 IPFS 节点会默认每 4 小时周期性地重新发布 IPNS 以防对等节点遗忘。所以一旦我们本地运行的 IPFS 实例关机超过 24 小时，那上面通过 IPNS 的几种访问方式便会失效。而且对等节点，比如上面公共 Gateway 的节点，在我们访问简单网页后，可能会缓存简单网页一段时间，但是 IPFS 的垃圾回收机制过不了多久就会删除一段时间内没被访问的对象。所以当我们的 IPFS 实例停机更长时间而且我们放在 IPFS 的文件没有很大热度，这些文件就会被网络遗忘，最初通过 CID 直接访问的方式也就失效了。以下几个方式可以优化可用性：</p><h3 id="7-1-云服务器运行-IPFS-实例">7.1. 云服务器运行 IPFS 实例</h3><p>部署在本地计算机的节点难免会关机，将节点部署到云服务器会比本地计算机运行得更稳定。具体步骤可以参考我的另一篇博客 <a href="/2023/02/02/ipfs-gateway/" title="IPFS Gateway 部署指南">IPFS Gateway 部署指南</a>。部署完成后你还需要将自己的文件上传到 Gateway，可以手动操作、自己构建简单的脚本通过 Gateway API 上传，如果相关文件托管在 Github，那也可以借助 <a href="https://github.com/marketplace/actions/upload-to-ipfs">Upload to IPFS</a> 这个 Github Action 实现自动化上传。当然别忘了在域名中配置 IPNS。</p><p>如果你有更高可用性要求，可以尝试 <a href="https://ipfscluster.io/">IPFS Cluster</a> 部署 IPFS 节点集群。</p><h3 id="7-2-4everland、Fleek-Pinner">7.2. 4everland、Fleek &amp; Pinner</h3><p><a href="https://4everland.io/">4everland</a> 提供了比较完善且方便的部署体验，支持从 IPFS CID 或者 Github 直接导入原始文件，分配 IPNS 并自动发布，也支持绑定 ENS。<a href="https://fleek.co/">Fleek</a> 功能类似。但是这些平台都一定程度上以牺牲去中心化为代价，比如 IPNS 对应的私钥便由平台创建，存在安全风险。与自己部署相比，有些类似将资产托管在交易所与自己创建钱包管理资产的区别。</p><p>相较上面两个提供完善的部署服务，还有一些只是提供文件托管服务，称为 Pinner，比如 <a href="https://www.infura.io">Infura</a>、<a href="https://www.pinata.cloud">Pinata</a>、<a href="https://web3.storage">Web3 Storage</a> 等。借助 <a href="https://github.com/ipfs-shipyard/ipfs-deploy">ipfs-deploy</a> 工具可以方便地将静态页面托管到这些服务，部署到 IPFS，ipfs-deploy 也可以辅助完成传统域名的 DNSLink IPFS CID 配置，但不支持 IPNS 和 ENS。</p><h3 id="7-3-Planet">7.3. Planet</h3><p><a href="https://www.planetable.xyz/">Planet</a> 是一个基于 IPFS 和 ENS 的免费且开源的工具用于创建，托管和关注去中心化 Web 内容。借助 Planet 客户端可以完成上文大部分工作。每一个关注你 Planet 的用户都会帮忙 Pin 一份你的内容，这样你的内容可用性就会变高。当然如果你初来乍到或者久久没有得到多人的关注，那想要自己的 Planet 能持久被访问，要不就一直保持 Planet 客户端运行，要不还是得借助自部署的 IPFS 节点或者 Pinner 以保持可用性。对于一个不喜欢上文中这么多复杂操作的普通用户而言，Planet 肯定是最优的选择。</p><h2 id="Reference">Reference</h2><ol><li><a href="https://eips.ethereum.org/EIPS/eip-1577">EIP-1577: contenthash field for ENS</a></li><li><a href="https://docs.ipfs.tech/concepts/ipns/">IPNS (InterPlanetary Name System) and Mutability | IPFS Docs</a></li><li><a href="https://dnslink.dev/">DNSLink Standard</a></li><li><a href="https://cid.ipfs.tech">CID Inspector | IPFS</a></li></ol>]]></content:encoded>
      
      
      
      <category domain="https://velih.de/tags/IPFS/">IPFS</category>
      
      
      <comments>https://velih.de/2023/02/02/ipfs-static-site/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>IPFS Gateway 部署指南</title>
      <link>https://velih.de/2023/02/02/ipfs-gateway/</link>
      <guid>https://velih.de/2023/02/02/ipfs-gateway/</guid>
      <pubDate>Thu, 02 Feb 2023 10:27:03 GMT</pubDate>
      
        
        
          
          
      <description></description>
          
        
      
      
      
      <content:encoded><![CDATA[<p>IPFS 官方还没有很完整的 Gateway 部署指南，而且 Gateway 也缺少 Authorization 支持，本文就是简单记录下 Gateway 的部署过程，分别使用 Nginx 与 Caddy 作为服务器软件，最终将会得到：</p><ul><li>基于 Docker 部署的 IPFS 实例；</li><li>支持 HTTPS 的 Gateway；</li><li>支持 HTTP Basic Authentication 的 API Server；</li></ul><p>在开始前，你需要提前准备以下几项内容：</p><ol><li>知道一些基本操作，或者会找相关的资料学习解决。比如如何安装 Docker Compose 等，我在此不会涉及太多这些内容。</li><li>一台云服务器主机。例如我在 Vultr 临时创建了一个系统为 Ubuntu 22.04 的实例用作演示，价格为 $6/月。</li><li>一个域名。例如我用来演示的域名托管在 Cloudflare 上。下文统一使用 your.domain 指代这个域名。小技巧：可以使用 Chrome 扩展 <a href="https://chrome.google.com/webstore/detail/findr/bidnaaogcagbdidehabnjfedabckhdgc/">FindR</a> 来替换 your.domain 成你自己的域名使得阅读与复制更加方便。</li></ol><h2 id="1-Docker-部署-IPFS">1. Docker 部署 IPFS</h2><p>首先在云服务器 Ubuntu 上安装好 docker 与 docker-compose，然后执行以下操作。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 创建并切换到工作目录</span></span><br><span class="line"><span class="built_in">mkdir</span> ipfs &amp;&amp; <span class="built_in">cd</span> ipfs</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 创建 docker-compose.yml</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;</span></span><br><span class="line"><span class="string">version: &#x27;3&#x27;</span></span><br><span class="line"><span class="string">services:</span></span><br><span class="line"><span class="string">  ipfs:</span></span><br><span class="line"><span class="string">    container_name: kubo</span></span><br><span class="line"><span class="string">    image: ipfs/kubo:latest</span></span><br><span class="line"><span class="string">    restart: unless-stopped</span></span><br><span class="line"><span class="string">    volumes:</span></span><br><span class="line"><span class="string">      - ./ipfs:/data/ipfs</span></span><br><span class="line"><span class="string">      - ./ipfs_fuse:/ipfs</span></span><br><span class="line"><span class="string">      - ./ipns_fuse:/ipns</span></span><br><span class="line"><span class="string">    environment:</span></span><br><span class="line"><span class="string">      - IPFS_PATH=/data/ipfs</span></span><br><span class="line"><span class="string">    ports:</span></span><br><span class="line"><span class="string">      - 4001:4001/tcp</span></span><br><span class="line"><span class="string">      - 4001:4001/udp</span></span><br><span class="line"><span class="string">      - 127.0.0.1:5001:5001</span></span><br><span class="line"><span class="string">      - 127.0.0.1:8080:8080</span></span><br><span class="line"><span class="string">&quot;</span> &gt; docker-compose.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 运行 docker-compose 版本的 IPFS 实例</span></span><br><span class="line">docker-compose up -d</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 检查是否成功</span></span><br><span class="line">curl localhost:8080/ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme</span><br></pre></td></tr></table></figure><p>现在 IPFS 实例已经部署完成了，现在我们修改一些 IPFS 的配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 进入 IPFS 实例的 shell</span></span><br><span class="line">docker <span class="built_in">exec</span> -it kubo /bin/sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 如果 IPFS 在日志中抱怨 system: cannot reserve inbound connection: resource limit exceeded 那可以尝试增加 ConnsInbound</span></span><br><span class="line">ipfs config --json Swarm.ResourceMgr.Limits.System.ConnsInbound 2048</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 配置 PublicGateway 域名，注意将 gateway.your.domain 替换成你自己的域名</span></span><br><span class="line">ipfs config --json Gateway.PublicGateways <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">    &quot;gateway.your.domain&quot;: &#123;</span></span><br><span class="line"><span class="string">      &quot;UseSubdomains&quot;: true,</span></span><br><span class="line"><span class="string">  &quot;InlineDNSLink&quot;: true,</span></span><br><span class="line"><span class="string">      &quot;Paths&quot;: [&quot;/ipfs&quot;, &quot;/ipns&quot;]</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  &#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 退出 shell，完成 IPFS 配置</span></span><br><span class="line"><span class="built_in">exit</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 重启 IPFS 实例，应用配置</span></span><br><span class="line">docker-compose restart</span><br></pre></td></tr></table></figure><p>然后，进行防火墙配置，我这里执行 <code>ufw disable</code> 关闭 UFW，改成使用云服务器提供的防火墙服务，你也可以直接使用系统内的防火墙。主要就是同时开启 IPv4 与 IPv6 的 TCP 22/80/443/4001 端口与 UDP 4001 端口，如下：</p><table><thead><tr><th>Action</th><th>Protocol</th><th>Port</th><th>Source</th></tr></thead><tbody><tr><td>accept</td><td>SSH</td><td>22</td><td>0.0.0.0/0,::/0</td></tr><tr><td>accept</td><td>TCP (HTTP)</td><td>80</td><td>0.0.0.0/0,::/0</td></tr><tr><td>accept</td><td>TCP (HTTPS)</td><td>443</td><td>0.0.0.0/0,::/0</td></tr><tr><td>accept</td><td>TCP</td><td>4001</td><td>0.0.0.0/0,::/0</td></tr><tr><td>accept</td><td>UDP</td><td>4001</td><td>0.0.0.0/0,::/0</td></tr><tr><td>drop</td><td>any</td><td>0 - 65535</td><td>0.0.0.0/0,::/0</td></tr></tbody></table><h2 id="2-DNS-配置">2. DNS 配置</h2><p>找到 Vultr 实例的 IP，比如我的分别为 IPv4: 149.28.140.214，IPv6: 2401:c080:1400:6016:5400:04ff:fe45:2010。那就在 your.domain 的 DNS 管理中添加以下几个记录，如果你是在 Cloudflare 中，暂时不要开启 Proxy：</p><table><thead><tr><th>Type</th><th>Name</th><th>Content</th></tr></thead><tbody><tr><td>A</td><td>gateway</td><td>149.28.140.214</td></tr><tr><td>A</td><td>*.ipfs.gateway</td><td>149.28.140.214</td></tr><tr><td>A</td><td>*.ipns.gateway</td><td>149.28.140.214</td></tr><tr><td>AAAA</td><td>gateway</td><td>2401:c080:1400:6016:5400:04ff:fe45:2010</td></tr><tr><td>AAAA</td><td>*.ipfs.gateway</td><td>2401:c080:1400:6016:5400:04ff:fe45:2010</td></tr><tr><td>AAAA</td><td>*.ipns.gateway</td><td>2401:c080:1400:6016:5400:04ff:fe45:2010</td></tr></tbody></table><h2 id="3-Nginx-作为服务器">3. Nginx 作为服务器</h2><p>Nginx 是常用的服务器工具，下面介绍 Nginx 作为 IPFS 的服务器的配置。</p><h3 id="3-1-Nginx-配置">3.1 Nginx 配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 安装 Nginx，在 Ubuntu 上可以使用</span></span><br><span class="line">apt install nginx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 添加 gateway 的 Nginx conf 配置</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;</span></span><br><span class="line"><span class="string">server &#123;</span></span><br><span class="line"><span class="string">listen 80;</span></span><br><span class="line"><span class="string">listen [::]:80;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">server_name gateway.your.domain;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">location /ipfs &#123;</span></span><br><span class="line"><span class="string">proxy_pass http://127.0.0.1:8080;</span></span><br><span class="line"><span class="string">proxy_set_header Host gateway.your.domain;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">location /ipns &#123;</span></span><br><span class="line"><span class="string">proxy_pass http://127.0.0.1:8080;</span></span><br><span class="line"><span class="string">proxy_set_header Host gateway.your.domain;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">location /api &#123;</span></span><br><span class="line"><span class="string">proxy_pass http://127.0.0.1:5001;</span></span><br><span class="line"><span class="string">proxy_set_header Host gateway.your.domain;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#x27;</span> &gt; /etc/nginx/conf.d/ipfsgateway.conf</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;</span></span><br><span class="line"><span class="string">server &#123;</span></span><br><span class="line"><span class="string">listen 80;</span></span><br><span class="line"><span class="string">listen [::]:80;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">server_name *.ipfs.gateway.your.domain;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">location / &#123;</span></span><br><span class="line"><span class="string">proxy_pass http://127.0.0.1:8080;</span></span><br><span class="line"><span class="string">proxy_set_header Host $host;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#x27;</span> &gt; /etc/nginx/conf.d/ipfsgateway_ipfs.conf</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;</span></span><br><span class="line"><span class="string">server &#123;</span></span><br><span class="line"><span class="string">listen 80;</span></span><br><span class="line"><span class="string">listen [::]:80;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">server_name *.ipns.gateway.your.domain;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">location / &#123;</span></span><br><span class="line"><span class="string">proxy_pass http://127.0.0.1:8080;</span></span><br><span class="line"><span class="string">proxy_set_header Host $host;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#x27;</span> &gt; /etc/nginx/conf.d/ipfsgateway_ipns.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 检查并应用 Nginx 配置</span></span><br><span class="line">nginx -t &amp;&amp; nginx -s reload</span><br></pre></td></tr></table></figure><p>访问 <a href="http://gateway.your.domain/ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme">http://gateway.your.domain/ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme</a> 查看 Nginx 是否配置成功。</p><h3 id="3-2-HTTPS-证书生成">3.2 HTTPS 证书生成</h3><p>我们借助 Certbot 帮忙生成 HTTPS 证书，因为我们使用通配符子域名，自动配置时需要完成 DNS 挑战。首先在 Cloudflare <a href="https://dash.cloudflare.com/profile/api-tokens">用户界面</a> 创建一个权限为 <strong>Zone:DNS:Edit</strong> 的 API Token，“Zone Resources” 选择现在所用的域名，将生成的 Token 按照格式 <code>dns_cloudflare_api_token = YOUR_API_TOKEN</code> 写入文件 <code>~/.secrets/certbot/cloudflare.ini</code>。 然后如下操作：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 调整权限</span></span><br><span class="line"><span class="built_in">chmod</span> 600 ~/.secrets/certbot/cloudflare.ini</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 安装 certbot</span></span><br><span class="line">snap install certbot --classic</span><br><span class="line">snap <span class="built_in">set</span> certbot trust-plugin-with-root=ok</span><br><span class="line">snap install certbot-dns-cloudflare</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 完成 DNS 挑战与 HTTPS 配置</span></span><br><span class="line">certbot --dns-cloudflare --dns-cloudflare-credentials ~/.secrets/certbot/cloudflare.ini --dns-cloudflare-propagation-seconds 20 \</span><br><span class="line"> --installer nginx \</span><br><span class="line"> -d gateway.your.domain \</span><br><span class="line"> -d *.ipfs.gateway.your.domain -d *.ipns.gateway.your.domain</span><br></pre></td></tr></table></figure><p>最后，修改 ipfsgateway.conf，为 /ipns, /ipfs 两个 location 添加 <code>proxy_set_header X-Forwarded-Proto &quot;https&quot;;</code>，</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">location /ipfs &#123;</span><br><span class="line">proxy_pass http://127.0.0.1:8080;</span><br><span class="line">proxy_set_header Host gateway.your.domain;</span><br><span class="line">proxy_set_header X-Forwarded-Proto &quot;https&quot;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">location /ipns &#123;</span><br><span class="line">proxy_pass http://127.0.0.1:8080;</span><br><span class="line">proxy_set_header Host gateway.your.domain;</span><br><span class="line">proxy_set_header X-Forwarded-Proto &quot;https&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后执行 <code>nginx -t &amp;&amp; nginx -s reload</code> 以生效，这样 Gateway 在需要重定向时会自动重定向为 HTTPS。现在测试下下面的链接：</p><ul><li><a href="https://gateway.your.domain/ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme">https://gateway.your.domain/ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme</a></li><li><a href="https://gateway.your.domain/ipns/vitalik.eth">https://gateway.your.domain/ipns/vitalik.eth</a></li></ul><h3 id="3-3-IPFS-API-Server-添加认证">3.3 IPFS API Server 添加认证</h3><p>默认的 IPFS API Server，不做认证，如果暴露在公网，则谁都可以访问，而且 IPFS 并没有提供相关的认证功能。所以我们在 Nginx 里为 API Server 添加 Basic Auth：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 安装相关工具</span></span><br><span class="line">apt install apache2-utils</span><br><span class="line"><span class="comment"># 2. 生成默认密码文件，your_username 换成你的用户名</span></span><br><span class="line">htpasswd -c /etc/nginx/.htpasswd your_username</span><br></pre></td></tr></table></figure><p>然后修改 Nginx 配置，为 /api 添加 auth_basic 配置。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">location /api &#123;</span><br><span class="line">    auth_basic &quot;Auth Required Area&quot;;</span><br><span class="line">    auth_basic_user_file /etc/nginx/.htpasswd;</span><br><span class="line">    proxy_pass http://127.0.0.1:5001;</span><br><span class="line">    proxy_set_header Host gateway.your.domain;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后执行 <code>nginx -t &amp;&amp; nginx -s reload</code> 以生效。然后可以测试如下命令，注意将 your_username 与 your_password 替换：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST <span class="string">&quot;https://gateway.your.domain/api/v0/cat?arg=/ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme&quot;</span> \</span><br><span class="line">-H <span class="string">&quot;Authorization: Basic <span class="subst">$(echo -n &#x27;your_username:your_password&#x27; | base64)</span>&quot;</span></span><br></pre></td></tr></table></figure><h2 id="4-Caddy-作为服务器">4. Caddy 作为服务器</h2><p>Caddy 能够自动生成 HTTPS 证书，且也可以实现 Basic Auth，所以这里整理下 Caddy 作为服务器的配置。</p><h3 id="4-1-构建带有额外组件的-Caddy-Docker-镜像">4.1 构建带有额外组件的 Caddy Docker 镜像</h3><p>和 Nginx 中使用 Certbot 生成证书类似，由于我们需要使用通配子域名，也要安装额外的组件，Caddy 原始镜像不提供这个功能，需要自行构建，新建 Dockerfile 以及 docker-compose.yml 如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换目录</span></span><br><span class="line"><span class="built_in">mkdir</span> caddy &amp;&amp; <span class="built_in">cd</span> caddy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加了 cloudflare dns 组件的 caddy Dockerfile</span></span><br><span class="line"><span class="built_in">echo</span> `</span><br><span class="line">FROM caddy:2.6.2-builder AS builder</span><br><span class="line"></span><br><span class="line">RUN xcaddy build \</span><br><span class="line">    --with github.com/caddy-dns/cloudflare</span><br><span class="line"></span><br><span class="line">FROM caddy:2.6.2</span><br><span class="line"></span><br><span class="line">COPY --from=builder /usr/bin/caddy /usr/bin/caddy</span><br><span class="line">` &gt; Dockerfile</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意：这里指定并会创建 caddy_network，用于之后共享给 IPFS 服务</span></span><br><span class="line"><span class="built_in">echo</span> `</span><br><span class="line">version: <span class="string">&quot;3&quot;</span></span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  caddy:</span><br><span class="line">    build: .</span><br><span class="line">    container_name: caddy</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">&quot;80:80&quot;</span></span><br><span class="line">      - <span class="string">&quot;80:80/udp&quot;</span></span><br><span class="line">      - <span class="string">&quot;443:443&quot;</span></span><br><span class="line">      - <span class="string">&quot;443:443/udp&quot;</span></span><br><span class="line">    volumes:</span><br><span class="line">      - ./Caddyfile:/etc/caddy/Caddyfile</span><br><span class="line">      - ./data/:/data/caddy/</span><br><span class="line">      - ./config/:/config/caddy</span><br><span class="line">    networks:</span><br><span class="line">      - caddynet</span><br><span class="line">      </span><br><span class="line">networks:</span><br><span class="line">  caddynet:</span><br><span class="line">    name: caddy_network</span><br><span class="line">` &gt; docker-compose.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建镜像</span></span><br><span class="line">docker-compose build</span><br></pre></td></tr></table></figure><p>然后在相同目录下创建 Caddyfile，注意替换其中的以下内容</p><ul><li>邮箱地址：用于证书生成</li><li>Cloudflare API Token：获取方法与 Nginx 配置中一致</li><li>Basic Auth 用户名和密码：用户名使用明文，密码可以在 caddy 服务启动后使用命令 <code>docker exec -it caddy caddy hash-password</code> 生成，见 <a href="https://caddyserver.com/docs/caddyfile/directives/basicauth">basicauth - Caddy Documentation</a></li><li>域名</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">auto_https ignore_loaded_certs</span><br><span class="line">email your@email.address</span><br><span class="line">acme_dns cloudflare your_dns_cloudflare_api_token</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">gateway.your.domain &#123;</span><br><span class="line">handle /ipfs/* &#123;</span><br><span class="line">reverse_proxy kubo:8080 &#123;</span><br><span class="line">header_up HOST gateway.your.domain</span><br><span class="line">header_up X-Forwarded-Proto &quot;https&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">handle /ipns/* &#123;</span><br><span class="line">reverse_proxy kubo:8080 &#123;</span><br><span class="line">header_up HOST gateway.your.domain</span><br><span class="line">header_up X-Forwarded-Proto &quot;https&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">handle /api/* &#123;</span><br><span class="line">reverse_proxy kubo:5001 &#123;</span><br><span class="line">header_up HOST gateway.your.domain</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">basicauth /api/* &#123;</span><br><span class="line">your_username your_password</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">*.ipfs.gateway.your.domain &#123;</span><br><span class="line">handle * &#123;</span><br><span class="line">reverse_proxy kubo:8080 &#123;</span><br><span class="line">header_up HOST &#123;host&#125;</span><br><span class="line">header_up X-Forwarded-Proto &quot;https&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">*.ipns.gateway.your.domain &#123;</span><br><span class="line">handle * &#123;</span><br><span class="line">reverse_proxy kubo:8080 &#123;</span><br><span class="line">header_up HOST &#123;host&#125;</span><br><span class="line">header_up X-Forwarded-Proto &quot;https&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在可以使用 <code>docker-compose up -d</code> 启动 caddy 服务。</p><h3 id="4-2-Caddy-访问-Kubo-服务">4.2 Caddy 访问 Kubo 服务</h3><p>要使 Caddy 在 Docker 实例中能够访问 Kubo 服务，需要让 Kubo 加入 Caddy 的网络，只需要在 Kubo 的 docker-compose.yml 中添加 Caddy 的网络如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">ipfs:</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">kubo</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">ipfs/kubo:latest</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">unless-stopped</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./ipfs:/data/ipfs</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./ipfs_fuse:/ipfs</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./ipns_fuse:/ipns</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">IPFS_PATH=/data/ipfs</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">4001</span><span class="string">:4001/tcp</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">4001</span><span class="string">:4001/udp</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:5001:5001</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:8080:8080</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ipfsnet</span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">ipfsnet:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">caddy_network</span></span><br><span class="line">    <span class="attr">external:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>然后使用 <code>docker-compose up -d --force-recreate</code> 重新创建 Kubo 服务即可。</p><h2 id="开启-Cloudflare-Proxy-的问题">开启 Cloudflare Proxy 的问题</h2><p>为了保护和加速网站的访问，首先你可以在 Cloudflare 为 gateway.your.domain 开启 Proxy。如果访问 Gateway 发生 <em>ERR_TOO_MANY_REDIRECTS(xxx redirected you too many times)</em> 错误，需要把域名的  SSL/TLS Encryption mode 配置从 <strong>Flexible</strong> 调整为 <strong>Full</strong>。</p><p>Cloudflare 免费支持通配符，且免费为 *.your.domain 这样的通配二级域名子域名提供 HTTPS 证书，但是本文 Gateway 场景中需要为 *.ipfs.gateway.your.domain 通配四级域名子域名提供 HTTPS 证书，在 Cloudflare 中需要订阅 Advanced Certificate Manager 或者 Business Plan 才能实现自动生成或者自主上传涵盖这种子域名的高级证书。</p><p>此时如果强制为 *.ipfs.gateway 或者 *.ipns.gateway 开启 Proxy，会提示 <em>This hostname is not covered by a certificate</em>，访问时也会出现 <em>ERR_SSL_VERSION_OR_CIPHER_MISMATCH(This site can’t provide a secure xxx uses an unsupported protocol.)</em> 错误。</p><p>这类功能确实属于高级功能，作为普通用户如果不愿意付费也没有关系，选择不开启 Proxy 至此也能完全正常使用了。也可以在 IPFS PublicGateways 配置时将 UseSubdomains 改为 <strong>false</strong>，这样可以禁用不受保护的 ipfs 与 ipns 子域名，且不再重定向，代价就是这样的 URL 路径违反了同源策略（Same-origin policy）会造成一些兼容性问题。</p><h2 id="Reference">Reference</h2><ol><li><a href="https://gist.github.com/NatoBoram/09d244ab02af16fecb62b917f7bee3c0">Hosting a public IPFS gateway</a></li><li><a href="https://docs.ipfs.tech/concepts/ipfs-gateway/">IPFS Gateway | IPFS Docs</a></li><li><a href="https://github.com/ipfs/kubo/blob/master/docs/config.md#gateway">Kubo Config - Gateway</a></li><li><a href="https://docs.nginx.com/nginx/admin-guide/security-controls/configuring-http-basic-authentication/">Restricting Access with HTTP Basic Authentication | NGINX Plus</a></li><li><a href="https://certbot-dns-cloudflare.readthedocs.io/en/stable/">certbot-dns-cloudflare’s Documentation</a></li><li><a href="https://developers.cloudflare.com/ssl/troubleshooting/too-many-redirects/">ERR_TOO_MANY_REDIRECTS · Cloudflare SSL/TLS docs</a></li><li><a href="https://developers.cloudflare.com/ssl/troubleshooting/version-cipher-mismatch/#multi-level-subdomains">ERR_SSL_VERSION_OR_CIPHER_MISMATCH · Cloudflare SSL/TLS docs</a></li></ol>]]></content:encoded>
      
      
      
      <category domain="https://velih.de/tags/IPFS/">IPFS</category>
      
      
      <comments>https://velih.de/2023/02/02/ipfs-gateway/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>BT 增强建议之进阶改进方案</title>
      <link>https://velih.de/2018/11/15/bt-advanced/</link>
      <guid>https://velih.de/2018/11/15/bt-advanced/</guid>
      <pubDate>Thu, 15 Nov 2018 11:45:00 GMT</pubDate>
      
        
        
          
          
      <description></description>
          
        
      
      
      
      <content:encoded><![CDATA[<p>本文是 BT 系列文章中的一篇，主要介绍 BEP 中剩下的改进方案，有需要的话可以先阅读博文 <a href="/2018/08/26/bt-overview/" title="BT 增强建议之概述">BT 增强建议之概述</a>。</p><h2 id="进阶改进方案">进阶改进方案</h2><p>本节点详细介绍几个比较重要的进阶改进方案。剩余的只作简单归纳。</p><h3 id="超级做种模式提高做种效率">超级做种模式提高做种效率</h3><p><a href="http://bittorrent.org/beps/bep_0016.html">BEP16 - Superseeding</a> 中起草的超级做种功能是一个来帮助初始做种者使用较少的流量来完成做种的算法。当一个做种客户端进入超级做种模式后，它将不会表现为一个标准的做种者，而是伪装成一个没有数据的正常 peer。当有其他 peer 连接时，它仅将一个从未发送过的片段发送给刚连接的 peer，在一个别的 peer 通知到该做种者这个片段前，做种者不会向刚才的 peer 发送新的片段，以此节约做种者的流量。<br>一般情况下，不建议使用超级种子模式。虽然它确实有助于更广泛地分发稀有数据，因为它限制了客户端可以下载的片段的选择，但也限制了这些客户端下载已经检索到的部分片段数据的能力。因此，超级种子模式仅推荐用于初始种子服务器。</p><h3 id="使用-Web-方式做种">使用 Web 方式做种</h3><p>WebSeed 在 BEP 中有两个增强建议：<a href="http://bittorrent.org/beps/bep_0019.html">BEP19 - HTTP/FTP Seeding (GetRight style)</a> 和 <a href="http://bittorrent.org/beps/bep_0017.html">BEP17 - Seeding (Hoffman-style)</a></p><p>BEP17 提供了一种通过 HTTP 协议做种以及从 HTTP 获取数据的方式。初始做种者主要在元数据文件中加入键 <code>httpseeds</code>，值为支持 HTTP Seeding 服务器地址列表，举例如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">d[&#x27;httpseeds&#x27;] = [ &#x27;http://www.site1.com/source1.php&#x27;,</span><br><span class="line">                   &#x27;http://www.site2.com/source2.php&#x27;  ]</span><br></pre></td></tr></table></figure><p>客户端通过以下方式访问 HTTP Seeding 服务器获取全部或者特定数据片段。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;url&gt;?info_hash=[hash]&amp;piece=[piece]&#123;&amp;ranges=[start]-[end]&#123;,[start]-[end]&#125;...&#125;</span><br></pre></td></tr></table></figure><p>BEP19 通告服务器地址的方式和 BEP17 差不多，但是键改为了 <code>url-list</code>。BEP19 的优点是能够处理任何可通过普通 HTTP 或 FTP 访问的文件，利用标准 HTTP 请求下载片段。BEP17 要求对服务器做适当修改，以支持 BEP17，这在互操作性方面是一个缺点，但它确实具有允许种子服务器更好地控制流量和避免带宽滥用的优势。</p><h3 id="私有种子加强数据分享隐私性">私有种子加强数据分享隐私性</h3><p>私有种子是在 <a href="http://bittorrent.org/beps/bep_0027.html">BEP27 - Private Torrents</a> 中描述的，通过在元数据信息总增加键值对 <code>private=1</code> 来标记种子为私有种子。客户端只能向私有种子对应的私有 Tracker 通告自身，而且只能与私有 Tracker 返回的 peer 建立连接。</p><p>当私有种子的 <code>announce-list</code> 中出现多个 Tracker 地址时，每个 peer 在一个时刻只能使用其中一个 Tracker，只有当 Tracker 出错时才可以切换 Tracker。在切换 Tracker 时，peer 必须断开所有与其他 peer 的连接，之后只能与新的 Tracker 提供的 peer 建立连接。这减轻了攻击者通过修改元数据文件中 <code>announce-list</code> 后发布新的元数据文件进行攻击带来的影响。</p><p>当种子为私有种子时，通过其他方式（包括 DHT, PEX, LSD 等）获取 peer 都会对“私有”进行破坏。但是不能避免攻击者通过猜测 peer 的 IP 与端口的方式找到 peer，进而产生连接。</p><h3 id="Merkle-Tree-数据结构优化元数据文件大小">Merkle Tree 数据结构优化元数据文件大小</h3><p>如果种子文件过大，对于提供种子文件下载的中心化服务器就会有较大压力。为了让元数据文件体积减小，一个有效的方法就是将每个片段的大小增加（上限是 2 Mb），同样大小的文件因此会产生更少的摘要数量。考虑到只有当一个片段被完全接受完成且验证摘要后，才能将之与其他 peer 进行交换，这意味着节点需要一段时间才能和其他 peer 进行交换。</p><p><a href="http://bittorrent.org/beps/bep_0030.html">BEP30 - Merkle hash torrent extension</a> 利用了 Merkle Tree 这种数据结构来优化元数据文件大小。该方案使用单一的 Merkle 哈希来替代摘要列表。Merkle 散列可用于通过分层方案验证整个内容文件以及各个块的完整性。它通过构建与数据相关的哈希树并仅需使用根哈希作为验证数据完整性的依据。</p><p>如图所示，P0-P12 代表片段 0-12，X 是为了树的完整而填充的零值片段，0-30 均表示哈希，其中 0 是根哈希。如果一个节点接受到了完整的片段 P8，那么该节点只需要额外通过一些途径知道 P8 的姊妹片段 P9 的哈希值，以及 P8 的所有叔块哈希（依次为 12，6，1）就可以验证 P8 的完整性。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">                                       0* = root hash</span><br><span class="line">                                    /     \</span><br><span class="line">                                /            \</span><br><span class="line">                            /                   \</span><br><span class="line">                        /                          \</span><br><span class="line">                    /                                 \</span><br><span class="line">                  1*                                     2</span><br><span class="line">                 / \                                    / \</span><br><span class="line">               /     \                                /     \</span><br><span class="line">             /         \                            /         \</span><br><span class="line">           /             \                        /             \</span><br><span class="line">         /                 \                    /                 \</span><br><span class="line">        3                   4                  5                   6* = uncle</span><br><span class="line">       / \                 / \                / \                 / \</span><br><span class="line">      /   \               /   \              /   \               /   \</span><br><span class="line">     /     \             /     \            /     \             /     \</span><br><span class="line">   7         8         9        10        11        12*       13        14 </span><br><span class="line">  / \       / \       / \       / \       / \       / \       / \       / \</span><br><span class="line">15   16   17   18   19   20   21   22   23   24   25   26   27   28   29   30</span><br><span class="line"></span><br><span class="line">P0   P1   P2   P3   P4   P5   P6   P7   P8*  P9*  P10  P11  P12   X    X    X</span><br><span class="line">= piece index                            =    =                   = filler hash </span><br><span class="line">                                         p    s                   </span><br><span class="line">                                         i    i                   </span><br><span class="line">                                         e    b                   </span><br><span class="line">                                         c    l</span><br><span class="line">                                         e    i</span><br><span class="line">                                              n</span><br><span class="line">                                              g</span><br></pre></td></tr></table></figure><p>原始资源发布者需要将元数据中的原本用来存储片段散列值的 <strong>pieces</strong> 键替换为存储根哈希的键 <strong>root hash</strong>。</p><p>支持 Merkle Tree 哈希方式的客户端需要同时支持扩展消息（见 <a href="/2018/08/30/bt-peer/" title="BT 增强建议之 Peer">BT 增强建议之 Peer</a>）来替代普通的 <strong>piece</strong> 消息来完成数据传输。用于传输数据的扩展消息类型是 <strong>Tr_hashpiece</strong> ，和其他扩展消息一样，这个消息也需要在 peer 间的扩展握手消息中声明。</p><p><strong>Tr_hashpiece</strong> 消息的负载内容如下：</p><ul><li>index：4 个字节，代表数据片段序号；</li><li>begin：4 个字节，代表当前当前数据子片段在整个片段中的偏移量；</li><li>hashlist length：4 个字节，代表哈希列表的长度</li><li>hashlist：哈希列表，包括片段自身哈希，姊妹片段哈希，以及各个叔片段哈希，最后是根哈希，只有当 begin 为 0 时，才需要传输 hashlist；</li><li>subpiece data：数据子片段；</li></ul><p>在 peer 接收完成某个数据片段的 <strong>Tr_hashpiece</strong> 消息后，它将根据 hashlist 中的哈希列表计算出的根哈希与原有的根哈希进行比对。如果匹配，所有哈希值都保存在该 peer 自己的 Merkle Tree 中，之后它们可以被传递给其他人。</p><p>需要注意的是，使用 Merkle Tree 的 Torrent 与使用散列值列表的 Torrent 即使它们的数据完全相同，但是由于 infohash 不一致，导致它们不在同一个 Swarm 中。另外一旦采用了 Merkle Tree 的方式，通过 WebSeed 来获取数据就变得不兼容。</p><h2 id="其他方案简述">其他方案简述</h2><ul><li><a href="http://www.bittorrent.org/beps/bep_0035.html">BEP35 - Torrent Signing</a>　利用对种子进行签名以增加下载安全性。</li><li><a href="http://bittorrent.org/beps/bep_0036.html">BEP36 - Torrent RSS feeds</a> 定义了 RSS 订阅种子的 feed 格式。</li><li><a href="http://bittorrent.org/beps/bep_0038.html">BEP38 - Finding Local Data Via Torrent File Hints</a> 则提出了粗略地检测用户本地是否已经存在全部或者部分即将下载的文件的方案。主要涉及在种子文件中添加 <code>similar</code> 或 <code>collections</code> 这两个键。前者表示可能与某个 infohash 共享部分数据，后者表示该种子文件所属的集合，属于同一集合的种子可能共享文件。</li><li><a href="http://bittorrent.org/beps/bep_0039.html">BEP39 - Updating Torrents Via Feed URL</a> 使用在 info 中的键 <code>update-url</code> 来表明用于更新该种子的链接地址，如果客户端请求该地址成功且得到一个种子文件，则需要下载该更新后的种子。</li><li><a href="http://bittorrent.org/beps/bep_0047.html">BEP47 - Padding files and extended file attributes</a> 在原始元数据描述文件信息的基础上增加了一些额外的属性。例如符号链接重复文件；为文件添加 padding 以使得下一个文件数据从片段边缘开始。</li><li><a href="http://bittorrent.org/beps/bep_0049.html">BEP49 - Distributed Torrent Feeds</a> 与 BEP36 提供的 RSS 订阅功能类似，但是通过 DHT 网络实现。</li></ul><h2 id="参考资料">参考资料</h2><ol><li><a href="https://github.com/webtorrent/webtorrent/issues/67">Implement Web (HTTP) Seeding (BEP17+BEP19) · Issue #67 · webtorrent/webtorrent</a></li></ol>]]></content:encoded>
      
      
      
      <category domain="https://velih.de/tags/BT/">BT</category>
      
      
      <comments>https://velih.de/2018/11/15/bt-advanced/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>BT 增强建议之 DHT</title>
      <link>https://velih.de/2018/11/12/bt-dht/</link>
      <guid>https://velih.de/2018/11/12/bt-dht/</guid>
      <pubDate>Mon, 12 Nov 2018 13:11:00 GMT</pubDate>
      
        
        
          
          
      <description></description>
          
        
      
      
      
      <content:encoded><![CDATA[<p>BitTorrent 使用 DHT 网路来存储 peer 信息，以实现去 Tracker 化的种子。此时，每个 peer 都成了一个 Tracker。网络基于 Kademlia 算法实现，使用 UDP 进行传输。</p><p>本文主要对 BT 中的 DHT 网络实现与在博文 <a href="/2018/11/08/dht-kademlia/" title="DHT 网络之 Kademlia 算法">DHT 网络之 Kademlia 算法</a> 中描述的 Kademlia 算法的区别进行总结。准确的说不能说是区别，而应该定义成实现细节，毕竟理论算法应用到实际时总需要因地制宜。</p><h2 id="实现细节点">实现细节点</h2><h3 id="key-value-对存储的内容">key-value 对存储的内容</h3><p>BT 使用 DHT 网络来实现去 Tracker 化，因此 peer 的信息就需要存储在 DHT 网络中，BT 中 peer 又是局限在某个 Torrent 文件中的。因此 key-value 对中 key 即 Torrent 文件的 infohash，正好 infohash 也是 160 比特长度的，value 为拥有该 infohash 文件的 peer 列表。</p><h3 id="K-桶实现细节">$K$ 桶实现细节</h3><p>首先 $K$ 桶中的节点有多种状态：如果一个节点在 15 分钟内回复过当前的节点的查询请求或者曾经回复过当前节点的查询请求同时在 15 分钟内有发送过查询请求给当前节点，则该节点相对于当前节点为 <em>Good 节点</em>；如果一个节点 15 分钟内未曾活动过，则成为 <em>Questionable 节点</em>；如果一个节点未相应当前节点的多次查询请求，则视为 <em>Bad 节点</em>。</p><p>当一个桶中节点数量已满（$K$ 的容量 $k$ 在 BT 中为 8）且都是 Good 节点，新的节点如果想要加入则直接被忽略。如果桶中有 Bad 节点，新的节点将会替代之。如果桶中有 Questionable 节点，则按照这些节点加入桶的时间进行 ping 请求，如果有节点不能被 ping 成功则新的节点将会取代之。</p><p>每个桶都会有一个<em>最近更新时间</em>标记来指示桶中节点的新鲜程度。如果一个桶中节点被 ping 成功了，或者有新的节点加入，或者一个节点被另一个替代了，这个时间会更新。如果一个桶最近更新时间已经过去 15 分钟，则需要进行一次桶刷新，方式和 Kademlia 中描述的一致。</p><h3 id="Peer-DHT-支持与否告知">Peer DHT 支持与否告知</h3><p>peer 通过在 handshake 握手消息中将 reserved_byte 的最后一比特设置为 1 来表示支持 DHT 网络。同样支持 DHT 网络的节点收到该握手消息后会发起一个 PORT 消息，type 为 9，负载为两个字节的 DHT 节点 UDP 端口。收到 PORT 消息的节点需要对改节点端口执行 ping 操作，如果对方响应了，则节点需要尝试将其加入到 $K$ 桶中。</p><h3 id="初始节点获取">初始节点获取</h3><p>去 Tracker 化的 Torrent 文件中是没有存储 Tracker 地址的 ”announce“ 键的。取而代之的是 ”nodes“ 键，nodes 中需要存储距离 key 最近的 $k$ 个节点地址或者存储一个 <em>Good 节点</em>，比如说产生这个 Torrent 的用户节点。不能将某些公共的节点加入到 Torrent 文件中，否则就变得不那么去 Tracker 化了。nodes 大概可以表示为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nodes = [[&quot;&lt;host&gt;&quot;, &lt;port&gt;], [&quot;&lt;host&gt;&quot;, &lt;port&gt;], ...]</span><br><span class="line">nodes = [[&quot;127.0.0.1&quot;, 6881], [&quot;your.router.node&quot;, 4804]]</span><br></pre></td></tr></table></figure><h3 id="RPC-消息">RPC 消息</h3><p>BT 使用 KRPC 来实现 Kademlia 节点间的 RPC 通信，KRPC 消息有三种消息类型：查询，响应，错误。对于 DHT 协议，有四种查询协议：ping，find_node，get_peers，announce_peer。</p><h4 id="KRPC-协议">KRPC 协议</h4><p>KRPC 协议是基于 UDP 和 bencode 编码的 RPC 协议。每条 KRPC 消息带有三个公共键值对以及其他因消息类型而异的键。三个公共的键是：</p><ul><li>”t“：值为字符串，代表 transaction ID。由发起 query 请求的节点生成，被请求节点需要在回复中返回。一般两个字节；</li><li>”y“：值为单字符，代表消息类型，是 q(query)、r(response)、e(error) 中的一个；</li><li>“v”：值为字符串，代表客户端版本 <a href="http://www.bittorrent.org/beps/bep_0020.html">BEP 20</a> 中定义，不一定存在这个键；</li></ul><p>每种消息会有自己额外的键：</p><h5 id="Query-消息">Query 消息</h5><ul><li>”q“：值为字符串，代表具体的方法类型；</li><li>”a“：值为字典，代表具体方法对应的参数字典；</li></ul><h5 id="Response-消息">Response 消息</h5><p>如果 Query 消息执行成功，则会返回该 Response 消息。</p><ul><li>”r“：值为字典，代表返回值字典；</li></ul><h5 id="Error-消息">Error 消息</h5><p>如果 Query 消息执行失败，则会返回该 Error 消息。</p><ul><li>”e“：值为列表，第一个元素代表错误码，第二个元素是错误消息；</li></ul><p>错误消息类型如下：</p><table><thead><tr><th>Code</th><th>Description</th></tr></thead><tbody><tr><td>201</td><td>Generic Error</td></tr><tr><td>202</td><td>Server Error</td></tr><tr><td>203</td><td>Protocol Error, such as a malformed packet, invalid arguments, or bad token</td></tr><tr><td>204</td><td>Method Unknown</td></tr></tbody></table><p>示例错误消息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">generic error = &#123;&quot;t&quot;:&quot;aa&quot;, &quot;y&quot;:&quot;e&quot;, &quot;e&quot;:[201, &quot;A Generic Error Ocurred&quot;]&#125;</span><br><span class="line">bencoded = d1:eli201e23:A Generic Error Ocurrede1:t2:aa1:y1:ee</span><br></pre></td></tr></table></figure><h4 id="DHT-Query-消息">DHT Query 消息</h4><h5 id="ping">ping</h5><p>用于检测一个节点是否工作，相当于 Kademlia 的 PING 调用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">arguments:  &#123;&quot;id&quot; : &quot;&lt;querying nodes id&gt;&quot;&#125;</span><br><span class="line"></span><br><span class="line">response: &#123;&quot;id&quot; : &quot;&lt;queried nodes id&gt;&quot;&#125;</span><br></pre></td></tr></table></figure><h5 id="find-node">find_node</h5><p>查找距离指定节点 ID 最近的节点 ID 信息，相当于 Kademlia 的 FIND_NODE 调用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">arguments:  &#123;&quot;id&quot; : &quot;&lt;querying nodes id&gt;&quot;, &quot;target&quot; : &quot;&lt;id of target node&gt;&quot;&#125;</span><br><span class="line"></span><br><span class="line">response: &#123;&quot;id&quot; : &quot;&lt;queried nodes id&gt;&quot;, &quot;nodes&quot; : &quot;&lt;compact node info&gt;&quot;&#125;</span><br></pre></td></tr></table></figure><p>“Compact node info” 列表中每个节点信息占用 26 字节，其中节点 ID 20 字节，IP 与 Port 占用 6 字节。</p><h5 id="get-peers">get_peers</h5><p>查找与指定 info_hash 相关的 peer 信息，相当于 Kademlia 的 FIND_VALUE 调用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">arguments:  &#123;&quot;id&quot; : &quot;&lt;querying nodes id&gt;&quot;, &quot;info_hash&quot; : &quot;&lt;20-byte infohash of target torrent&gt;&quot;&#125;</span><br><span class="line"></span><br><span class="line">response: &#123;&quot;id&quot; : &quot;&lt;queried nodes id&gt;&quot;, &quot;token&quot; :&quot;&lt;opaque write token&gt;&quot;, &quot;values&quot; : [&quot;&lt;peer 1 info string&gt;&quot;, &quot;&lt;peer 2 info string&gt;&quot;]&#125;</span><br><span class="line"></span><br><span class="line">or: &#123;&quot;id&quot; : &quot;&lt;queried nodes id&gt;&quot;, &quot;token&quot; :&quot;&lt;opaque write token&gt;&quot;, &quot;nodes&quot; : &quot;&lt;compact node info&gt;&quot;&#125;</span><br></pre></td></tr></table></figure><p>如果被请求节点有指定 info_hash 相关 peers 则以 values 为键的 “Compact IP-address/port info” 列表，否则，返回以 nodes 为键的 “Compact node info” 列表。响应中的 token 需要请求者在通过 announce_peer 向回复者宣告 peer 信息时携带。</p><h5 id="announce-peer">announce_peer</h5><p>宣告节点自身拥有特定 info_hash 的数据，并在某个端口进行下载，相当于 Kademlia 的 STORE 调用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">arguments:  &#123;&quot;id&quot; : &quot;&lt;querying nodes id&gt;&quot;,</span><br><span class="line">  &quot;implied_port&quot;: &lt;0 or 1&gt;,</span><br><span class="line">  &quot;info_hash&quot; : &quot;&lt;20-byte infohash of target torrent&gt;&quot;,</span><br><span class="line">  &quot;port&quot; : &lt;port number&gt;,</span><br><span class="line">  &quot;token&quot; : &quot;&lt;opaque token&gt;&quot;&#125;</span><br><span class="line"></span><br><span class="line">response: &#123;&quot;id&quot; : &quot;&lt;queried nodes id&gt;&quot;&#125;</span><br></pre></td></tr></table></figure><p>接受者需要校验 token 是否与之前它通过 get_peers 调用的响应回复给该请求者的一致。如果 implied_port 值为 1，表示 port 的值不可用，接受者需要将请求包的 UDP 源端口作为 port。</p><h2 id="BT-DHT-相关增强方案">BT DHT 相关增强方案</h2><h3 id="DHT-Scrape-帮助选择-Seeding-内容">DHT Scrape 帮助选择 Seeding 内容</h3><p>类似 <a href="http://bittorrent.org/beps/bep_0048.html">Tracker Scrape</a>，DHT 网络可以通过 <a href="http://bittorrent.org/beps/bep_0033.html">BEP33 - DHT Scrapes</a> 中定义的 DHT scrape 来了解某个 Swarm 中 peer 的大致情况，然后根据这个状态选择 seeding 队列中下一个 Swarm 进行做种。这种算法主要通过布隆过滤器（Bloom Filter）实现，布隆过滤器通常用于检索一个元素是否在一个集合中。但在 DHT scrape 中，作用所有不同。加入布隆过滤器中的是各个 peer 的 IP 的 sha1 值，可以根据过滤器中剩余的 0 比特数量来估算整个 Swarm 的规模。</p><h3 id="只读-DHT-节点">只读 DHT 节点</h3><p>在一些情况下，DHT 节点主动或被动地限制成为只读节点（<a href="http://bittorrent.org/beps/bep_0043.html">BEP43 - Read-only DHT Nodes</a> 中定义），比如位于 NAT 后且 hole punching 失败的节点，节点具有流量限制或者有流量计划，流量会影响节点的电量等等情况。</p><p>节点通过在每条向外发送的 DHT Query 消息中给出一个 <code>ro=1</code> 的键值对来表明自己为只读节点。成为只读节点后，不再响应其他节点的 Query 请求。其他节点知晓只读节点后也不会发送 Query 请求以减少网络流量。</p><h3 id="在-DHT-中存储任意数据">在 DHT 中存储任意数据</h3><p><a href="http://bittorrent.org/beps/bep_0044.html">BEP44 - Storing arbitrary data in the DHT</a> 中提供了一种在 DHT 中存储任意数据的方式。存储的数据可以是不可变数据也可以是可变数据，不可变数据的 key 是数据内容的 sha1 值，可变数据的 key 是用于签名数据的密钥对公钥。<a href="http://bittorrent.org/beps/bep_0046.html">BEP46 - Updating Torrents Via DHT Mutable Items</a> 则基于在 DHT 网络中存储可变数据而给出了一种用于更新 Torrent 的方法。<a href="http://bittorrent.org/beps/bep_0050.html">BEP50 - Publish/Subscribe Protocol</a> 实现了一种基于主题的发布订阅模式来向订阅特定主题的客户端发送更新后可变数据的协议。</p><h3 id="多个监听地址情况处理">多个监听地址情况处理</h3><p>某些客户端可能会监听多个公网单播 IP 地址，如果在这种情况下，该客户端仅使用一个节点 ID，则其他节点可能会因为多地址现象而对该节点 ID 进行清理。<a href="http://bittorrent.org/beps/bep_0045.html">BEP45 - Multiple-address operation for the BitTorrent DHT</a> 中给出了一些要求和建议：</p><ul><li>要求每个套接字地址必须具有不同的节点 ID，且它们的 XOR 距离要分得比较开，响应必须从收到相应请求的同一套接字地址发送；</li><li>建议节点应避免在单个IP地址上使用多个端口；</li></ul><h3 id="其他">其他</h3><p>和 DHT 相关的草案还有如对 IPv6 的支持（<a href="http://bittorrent.org/beps/bep_0032.html">BEP32 - BitTorrent DHT Extensions for IPv6</a>），DHT 网络安全（<a href="http://bittorrent.org/beps/bep_0042.html">BEP42 - DHT Security extension</a>），检索其他节点存储的 infohash 列表（<a href="http://bittorrent.org/beps/bep_0051.html">BEP51 - DHT Infohash Indexing</a>）等。</p><h2 id="参考资料">参考资料</h2><ol><li><a href="https://www.quora.com/%CE%BCTorrent-Whats-the-difference-between-the-status-Queued-Seed-and-Seeding">μTorrent: What’s the difference between the status “Queued Seed” and “Seeding”?</a></li></ol>]]></content:encoded>
      
      
      
      <category domain="https://velih.de/tags/BT/">BT</category>
      
      
      <comments>https://velih.de/2018/11/12/bt-dht/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>DHT 网络之 Kademlia 算法</title>
      <link>https://velih.de/2018/11/08/dht-kademlia/</link>
      <guid>https://velih.de/2018/11/08/dht-kademlia/</guid>
      <pubDate>Thu, 08 Nov 2018 03:29:00 GMT</pubDate>
      
      <description>&lt;p&gt;本文是论文 &lt;a href=&quot;http://www.scs.stanford.edu/~dm/home/papers/kpos.pdf&quot;&gt;Kademlia: A Peer-to-Peer Information System Based on the XOR Metric&lt;/a&gt; 的翻译。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>本文是论文 <a href="http://www.scs.stanford.edu/~dm/home/papers/kpos.pdf">Kademlia: A Peer-to-Peer Information System Based on the XOR Metric</a> 的翻译。</p><span id="more"></span><h1>Kademlia：一种基于 XOR 距离的 P2P 信息系统</h1><p>作者：Petar Maymounkov 以及 David Mazières</p><h2 id="Abstract（摘要）">Abstract（摘要）</h2><p>我们描述了一种在容易出错的环境下仍具有可证明的容错性和性能的 P2P 分布式散列表。我们的系统使用了一种基于 XOR 距离的新型拓扑来路由查询与定位节点的需求，该拓扑简化了算法及算法的证明。该拓扑有这样一个特点：每次信息交换都传递或者加强了（节点间）有效联系。系统根据这种联系来发送并行异步查询消息，从而做到容忍节点故障同时不对用户造成超时。</p><h2 id="Introduction（介绍）">Introduction（介绍）</h2><p>本论文描述 Kademlia —— 一个 P2P 分布式散列表（DHT）。Kademlia 有许多之前的 DHT 无法同时提供的理性功能。它最大限度地减少了节点必须发送的用于互相了解的配置消息数量。查找 Key 时附带自动传播配置信息。节点具有足够的认知与灵活性来通过低延迟路径路由查询。Kademlia 使用并行异步查询来避免来自失败节点的超时延迟。节点记录其他节点的存在以阻挡某些基本的拒绝服务攻击。最后，只要对运行时间进行简单的假设就可以对 Kademlia 的几个重要特性进行正式证明。</p><p>Kademlia 采用了许多 DHT 使用的基本方法。密钥使用不透明的 160 位空间，比如 SHA-1 散列。参与的计算机在 160 位密钥空间中都有一个节点 ID。<strong>key-value 键值对存储在那些 ID “接近” key 的节点上</strong>。最终，一个基于节点 ID 的路由算法使得任何节点可以通过给出的目标 key 有效地定位 key 附近的节点。</p><p>Kademlia 的众多优点得益于它创新地使用 XOR 来度量节点间的距离。XOR 是对称的，允许 Kademlia 接收来自那些拥有完全相同的路由表信息的节点的查询请求。像是 Chord 这样没有这种特性的系统就无法从查询请求中获取有用的路由信息。甚者，不对称会导致严格的路由表。在 Chord 中，每个节点必须存储？？？？？？？</p><p>为了定位接近特定 ID 的节点，Kademlia 自始至终仅使用一个路由算法。相反，其他系统使用一种算法来接近目标 ID，使用另一种算法来完成最后几跳。在现有的系统中，Kademlia 最像 Pastry 的第一阶段，虽然作者没有用这种方式描述，但是通过 Kademlia 的 XOR 距离发现目标 ID 的节点数可以减少一半。在 Pastry 的第二阶段，它将距离度量切换为 ID 间的数字差异。它还在复制中使用第二个数字差异度量。遗憾的是，第二个度量标准中相距较近的节点在第一个度量标准中则可能相差很远，以致在特定节点 ID 值处产生了不连续性，从而降低了性能，并使得对最坏情况行为的正式分析变得复杂。</p><h2 id="System-Description（系统描述）">System Description（系统描述）</h2><p>与其他 DHT 相同类似，Kademlia 给节点分配一个 160 位的透明 ID，并提供一个查询算法用以定位更加接近指定节点的节点，以对数级别收敛查询到目标节点。</p><p>Kademlia 高效地将节点作为一个二叉树的叶子节点，每个节点的位置取决于其 ID 的最短唯一前缀。图一展示了唯一前缀为 0011 的节点在树中的位置。对于任一给定的节点，我们将二叉树分为一系列连续的不包含该节点的子树。最高的子树由不包含该节点的整个二叉树的一半组成。接下来的子树由不包含该节点的剩余二叉树的一般组成。在图示中，节点 0011 的所有子树被圈出，按照高度由高到低排序，前缀分别是 0, 01, 000 以及 0010。</p><p><img src="kademlia-1.png" alt="图一：Kademlia 二叉树。黑色的点表示节点 0011··· 的位置；灰色的圈表示节点 0011··· 必须与之建立联系的子树。"></p><p>Kademlia 协议确保每个节点都知晓其每个子树中的至少一个节点。有了这个保证，任一节点都可以通过 ID 定位到另外的节点。图二展示了节点 0011 通过不断在子树中查询最佳它所知晓的最佳节点的方式最终找到目标节点 1110 的过程。</p><p><img src="kademlia-2.png" alt="图二：通过 ID 定位节点。前缀为 0011 的节点通过依次知晓与查询越来越近的节点从而找到前缀为 1110 的节点。图上方的线代表了 160 比特的 ID 空间，并且展示了查询到目标节点的整个过程。图的主体画出了节点 1110 发出的 RPC 消息，第一个 RPC 消息发送给 101，后续的 RPC 消息发送给前一个 RPC 消息返回的节点。"></p><p>本节的剩余部分补充了查找算法的具体细节。我们首先定义一个精确的概念来描述节点间的距离，让我们指出距离某个 key 最近的 k 个节点提供了可能。然后给出一个查询协议，即使没有节点与给定的 key 拥有相同的唯一前缀或者给定节点的一些子树是空的，这个协议仍然是可工作的。</p><h3 id="XOR-Metric（XOR-度量）">XOR Metric（XOR 度量）</h3><p>每个 Kademlia 节点都有一个 160 比特的节点 ID。节点 ID 目前只是随机的 160 位标识符，尽管它们同样可以像在 Chord 中那样构造。节点发送的每条消息都包含其节点ID，允许接收方在必要时记录发送方的存在。</p><p>键同样是 160 位标识符。为了给特定的节点分配 key-value 键值对，Kademlia 依赖两个标识符之间的距离的度量。给出两个 160 位的标识符 $x$ 和 $y$，Kademlia 将 $x$ 与 $y$ 的距离定义为 $x$ 与 $y$ 按位异或后的整数值，即 $d(x, y) = x \oplus y$。</p><p>我们首先注意到 XOR 运算是有效的，尽管属于非欧几里德距离。异或运算有以下性质：</p><ul><li>$$d(x, x) = 0$$</li><li>$$d(x, y)&gt;0, \text{ if } x \neq y$$</li><li>$$\forall x, y:d(x, y)=d(y, x)$$</li><li>$$d(x,y)+d(y,z) \geq d(x,z)$$</li><li>$$d(x,y) \oplus d(y,z) = d(x,z)$$</li><li>$$\forall a \geq 0, b \geq 0: a+b \geq a \oplus b$$</li></ul><p>接下来我们注意到异或度量刻画了基于二叉树的系统草图中隐含的距离概念。在 160 位 ID 完全填充的二叉树中，两个 ID 间距离大小是包含它们的最小子树的高度。当树未完全填满时，与 ID $x$ 最接近的节点是节点 ID 与 $x$ 共享最长公共前缀的节点。如果树中有空分支，则可能有多个叶子节点具有最长的公共前缀，在这种情况下，与 $x$ 最接近的叶子将变为离通过翻转 $x$ 中对应于树的空分支中的位得到的 $\widetilde{x}$ 最近的叶子。</p><p>类似于 Chord 算法的顺时针圆周度量，XOR 也是单向的。对于任意给定的点 $x$ 以及 $∆ &gt; 0$，仅存在一个点 $y$ 使得 $d(x, y) = ∆$。单向性保证了对于相同的 key，无论从哪个原点开始查询，都会沿着相同的路径进行收敛。这样，沿着查询路径缓存 key-value 键值对就能减轻存放热门 key 值节点的压力。类似于 Pastry 而不同于 Chord， XOR 拓扑是对称的。</p><h3 id="Node-State（节点状态）">Node State（节点状态）</h3><p>Kademlia 节点存储了其他节点联系人的信息以路由查询消息。对于每个 $0 \leq i &lt; 160$，每个节点构建一个（IP 地址，UDP 端口，节点 ID）的三元组列表用来存储与该节点相距 $[2^i$, $2^{i+1})$ 的节点。我们称之为 $K$ 桶。每个 $K$ 桶内节点根据节点最后可见时间进行排序，最早可见的放置在开头，最近可见的放置在末尾。对于较小的 $i$ 值，$K$ 桶通常是空的（因为不存在合适的节点）。对于较大的 $i$ 值，列表最大容量为 $k$，$k$ 是一个系统范围内的复制参数。仅当任意给定的 $k$ 个节点不会在一个小时内同时失效时，$k$ 值才有效，例如 $k = 20$。</p><p>当一个 Kademlia 节点收到任一来自其他节点的请求或者回复消息，它会根据发送者的节点 ID 更新 $K$ 桶。规则如下：</p><ul><li>如果发送节点已经存在接收方的 $K$ 桶中：<ul><li>接收方将发送节点移动到相应 $K$ 桶的尾部；</li></ul></li><li>如果发送节点并未存在接收方的 $K$ 桶中：<ul><li>如果 $K$ 桶中节点数量少于 $k$ 个，则直接将发送节点插入至 $K$ 桶尾部；</li><li>如果 $K$ 桶已满：<ul><li>如果最早可见的节点不能 ping 通，则移除该节点，然后将发送节点插入至 $K$ 桶尾部；</li><li>如果最早可见的节点可以 ping 通，则将该节点移动到尾部，然后丢弃发送节点；</li></ul></li></ul></li></ul><p>$K$ 桶高效地实现了 LRU 算法，只是活动的节点永远不会从列表中移除。这种对与旧联系人的偏好来自于我们的对于 Saroiu 等人从 Gnutella 网络收集的追踪数据的分析。图 3 展示了 Gnutella 节点随着当前时间的推移，额外在线一个小时的可能性。一个节点在线时间越长，它就越可能继续额外在线一个小时。通过保持最老的在线节点，$K$ 桶最大化了列表中节点在线的可能性。</p><p><img src="kademlia-3.png" alt="图三：额外保持一小时在线的可能性关于时间的函数。X 轴代表分钟，Y 轴表示保持在线 $x$ 分钟的节点继续保持在线到 $x + 60$ 分钟时刻的可能性"></p><p>$K$ 桶采用这样的更新策略的另一个优点在于可以抵挡特定的 DoS 攻击。攻击者不能使用新的节点泛洪系统来刷新节点的路由状态。只有当旧的节点离开了系统，Kademlia 才会插入新的节点。</p><h3 id="Kademlia-protocol（Kademlia-协议）">Kademlia protocol（Kademlia 协议）</h3><p>Kademlia 协议由四个 RPC 调用组成：<em>PING</em>, <em>STORE</em>, <em>FIND_NODE</em>, <em>FIND_VALUE</em>。</p><ul><li><em>PING</em> 用于探测一个节点是否在线。</li><li><em>STORE</em> 用于通知一个节点存储一个 key-value 对以便之后获取。</li><li><em>FIND_NODE</em> 使用一个 160 比特的 ID 作为参数。调用对象返回一个其知晓的距离目标 ID 最近的 $k$ 个节点信息 &lt;IP 地址，UDP 端口，节点 ID&gt; 三元组。这 $k$ 个三元组可能来自单个 $K$ 桶，也可能因为距离最近的 $K$ 桶未满而取自多个 $K$ 桶。在任何一种情况下，RPC 调用接收者必须返回 $k$ 个节点，除非该节点知晓节点总数小于 $k$ 个。</li><li><em>FIND_VALUE</em> 调用和 <em>FIND_NODE</em> 一样，不过当调用的接收者存有请求者所请求的键的时候，它将返回相应键的值。</li></ul><p>在所有的 RPC 中，接收者必须返回一个 160 比特的随机 RPC ID，以防止地址伪造（？）。可以将 PING 消息附加在 RPC 消息的回复中以确定发送者的网络地址。</p><h4 id="临近-ID-节点查找">临近 ID 节点查找</h4><p>Kademlia 节点需要实现的最重要的过程就是根据一个节点 ID 找到与它最近的 $k$ 个节点。我们称这个过程为 <em>节点查找</em>，Kademlia 使用递归完成这个工作。由查找需求的起始节点先从离目标节点 ID 最近的非空 $K$ 桶中取出 $α$ 个节点（如果 $K$ 桶中节点不足 $α$ 个，则从其他 $K$ 桶中取满 $α$ 个）。起始接地并行向这 $α$ 个节点发送 <em>FIND_NODE</em> RPC 调用。$α$ 是一个系统级参数，例如 3。</p><p>在递归调用阶段，初始节点根据 $α$ 个节点返回的节点列表再次发送 <em>FIND_NODE</em> 请求（递归调用在所有 $α$ 个节点完成返回前就可以开始）。起始节点从其他节点返回的大小为 $k$ 的节点列表中选出 $α$ 个之前没有查询过的节点，向它们发送 <em>FIND_NODE</em> RPC 调用。失败的节点将不再会纳入考虑范围。如果有一轮 <em>FIND_NODE</em> 调用中返回的所有节点都不比之前知晓的 $k$ 个节点更加接近，则当初始节点完成对最近的这个 $k$ 个节点的查询并得到响应之后，查询结束。当 $a=1$，查询算法在信息开销和故障节点的检查延迟上与 Chord 类似。但是 Kademlia 可以灵活地从 $k$ 个节点中选择任一一个发送请求以降低查询延迟。</p><h4 id="存储键值对与重新发布时间">存储键值对与重新发布时间</h4><p>上述查询过程实现了大部分的操作。为了存储一个 key-value 对，起始节点通过上述操作定位到 $k$ 个离 key 最近的节点，并向它们发送 <em>STORE</em> 调用。另外，每个节点会在需要的情况下重新发布 key-value 以使 key-value 持续存在。在 Kademlia 当前的应用中（文件分享），key-value 的原始发布者需要每个 24 小时重新进行发送。否则，key-value 将在发布 24 小时后失效，以限制系统中不可用的索引信息。对于其他的应用，比如数字证书或者用于值映射的加密哈希，更长的过期时间也许会更合适。</p><h4 id="查询键值对与过期时间">查询键值对与过期时间</h4><p>为了找到一个 key-value 对，节点发起一个节点查找以找到 ID 与 key 最接近的 $k$ 个节点。值查询使用的是 <em>FIND_VALUE</em> 调用而不是 <em>FIND_NODE</em> 调用。而且，如果任何一个节点返回了值，则这个过程立即结束。出于缓存的目的，一旦查找成功，发起节点将会将 key-value 存储至其知晓的相对 key 最近的，但是在查找过程中并没有返回值的节点。</p><p>由于拓扑是单向的，随后对于相同 key 的查找很可能在查询到最近的节点之前就命中存储在非最近节点中缓存。在某个 key 活跃度非常高的情况下，系统可能会将其存储在很多节点。为了避免这种过度存储，我们为 key-value 设置了过期时间，这个时间与节点 ID 相对于 key 的距离成指数反比。虽然简单的 LRU 策略会产生类似的生命周期分布，但是没有合适的方法去选择cache的大小，因为节点对于系统将要储存多少值没有先验知识。</p><h4 id="K-桶更新与加入网络">$K$ 桶更新与加入网络</h4><p>$K$ 桶会根据经过节点的请求而保持更新。为了解决因为某个特殊的 ID 段长时间没有查询的特殊情况，节点会刷新那些在过去一小时内没有过查询请求的 $K$ 桶。刷新就是随机选取一个处在当前 $K$ 桶范围的 ID，然后对其进行节点查询。</p><p>为了加入网络，一个节点 $u$ 必须要与一个已存在在网络中的节点 w 有联系。$u$ 将 w 插入到合适的 $K$ 桶中，随后 $u$ 对自己的 nodeID 进行一次节点查询，最后，$u$ 会联系到离它邻居更远的节点，然后更新相应的 $K$ 桶。在刷新过程中，$u$ 填充了自己的 $K$ 桶同时也将自己插入到其他节点的 $K$ 桶中。</p><h3 id="Routing-Table（路由表）">Routing Table（路由表）</h3><p>Kademlia 的基础路由表结构非常直观，但是需要对高度不平衡的树进行一些细节处理。路由表是一棵叶子节点为 $K$ 桶的二叉树。每个 $K$ 桶包含了一些具有公共前缀的 ID。$K$ 桶公共前缀就是其在二叉树中所处的位置。可见，每个 $K$ 桶覆盖了一部分 ID 空间，所有的 $K$ 桶集合无重叠地覆盖了整个 160 比特 ID 空间。</p><p>路由二叉树中的节点是按需动态分配的。图 4 表示了这一个过程。初始状态下，节点 $u$ 的路由树只有一个节点，一个 $K$ 桶覆盖了整个 ID 空间。当 $u$ 得到了一个新的联系人时，它将根据与新的联系人的距离，尝试将其插入到合适的 $K$ 桶中。插入的规则如下：</p><ul><li>如果 $K$ 桶未满，新的联系人就会被直接插入；</li><li>如果 $K$ 桶满了：<ul><li>如果 $K$ 桶的范围包括了 $u$ 自身的 ID，则 $K$ 桶将会一分为二，原 $K$ 桶中的 ID 重新分配到新的 $K$ 桶中，然后再尝试插入；</li><li>如果 $K$ 桶的范围不包括 $u$ 自身的 ID，新的联系人将直接被丢弃；（3）</li></ul></li></ul><p>在这样高度不平衡的二叉树中会出现一个问题，导致这种情况下并不会按照规则 3 进行插入。假设一个系统中，$u$ 是<strong>唯一</strong>一个 ID 以 000 开头的节点，同时有超过 $k$ 个 ID 以 001 开头的节点 $v_1,v_2…v_k…v_n$。对于每个节点 $v$ 的路由树，$u$ 都将会被插入到一个空 $K$ 桶中。但是由于按照规则 3， $u$ 的桶更新只会通知到 $u$ 的路由树所记录的所有 $v$ 中的 $k$ 个。为了避免剩余的 $v$ 无法得到 $u$ 的桶更新信息，Kademlia 节点通过拆分以保存了超过 $k$ 个的所有有效的节点，即使不是因为 $K$ 桶中包括了自身的 ID。图 5 展示了这种额外的拆分。当 $u$ 刷新了桶，所有前缀为 001 的节点都会知晓。</p><p><img src="kademlia-4.png" alt="图四：路由表随时间的演变。一开始，节点只有一个 $K$ 桶。随着 $K$ 桶被填充，包含节点 ID 的桶被不断一分为二。"></p><p><img src="kademlia-5.png" alt="图五：一个 ID 为 $00...00$ 的节点的宽松路由表。为了确保其知晓它周围最小子树（至少 $k$ 个节点）的所有联系人，这个路由表进行了额外的拆分。"></p><h3 id="Efficient-Key-Re-publishing（Key-的高效重发布）">Efficient Key Re-publishing（Key 的高效重发布）</h3><p>为了保证 key-value 对的持久存在，节点必须周期性重发布 key。否则，两种情况下可能导致对有效 key 的查询失败。</p><ul><li>一些获得 key-value 对的节点离开了网络</li><li>新的相比原始被发布过 key-value 对的节点 ID 更近的节点加入了网络</li></ul><p>在这两种情况下，拥有这个 key-value 对的节点需要将其重新发布到离 key 最近的 $k$ 个节点。</p><p>为了弥补节点离开网络的情况，节点每隔一个小时重新发布 key-value 对，一个直接的实现就是将会产生很多消息——每个存储这个 key-value 对的节点（至多 $k$ 个）间隔一小时会发起一次查询，然后向其他 $k-1$ 个节点发起 <em>STORE</em> 请求。这个重新发布操作可以大大简化。首先，当一个节点收到对某个 key-value 对的 <em>STORE</em> 调用，它假设这个 RPC 调用同样被发送给了另外 $k-1$ 个节点，这个节点在下一个小时不会再重新发布此 key-value 对。这保证了知道复制间隔不是完全同步的，每隔小时内只有一个节点会重新发布 key-value 对。</p><p>第二个优化在于在重新发布 key 之前避免进行节点查询。像上一节所说的，为了处理不平衡树，在必要的时候节点将会拆分 $K$ 桶来确保它对至少 $k$ 个节点的周围子树充分了解。如果节点在重新发布 key-value 之前更新了该 $k$ 节点子树的所有 $K$ 桶，它将自动获知距离给定 key 最近的 $k$ 个节点。对于这些 $K$ 桶的更新代价可以分摊给许多 key 的重新发布（平均而言，这样就降低了单个 key 重新发布时的代价）。</p><p>要搞清楚为什么在 $u$ 更新规模大于等于 $k$ 的子树的所有 $K$ 桶后不再需要节点查询了，需要分为两种情况。如果要被充发布的 key 在该子树的 ID 范围内，那么因为子树的规模至少为 $k$ 而且 $u$ 具有该子树的全部知识，显然 $u$ 肯定知道距离 key 的最近 $k$ 个节点。如果要被充发布的 key 在该子树的 ID 范围外，因为 $u$ 是 $k$ 个距离 key 最近的节点之一（否则 $u$ 不会存储关于该 key 的信息），显然所有距离该 key 比距离子树更近一些的 $K$ 桶中的元素都少于 $k$。因此，$u$ 将会知晓所有这些 $K$ 桶中的所有节点，再加上关于子树的知识，就可以得到距离该 key 最近的 $k$ 个节点。</p><p>当一个新节点加入网络，对于每个 key-vaule 对来说，如果该节点为其 $k$ 个最近节点之一，那么必须对其进行存储。网路中原有的节点同样可以通过其边缘子树的完整知识，知道哪些 key-value 对需要存储在该新增节点上。每个了解到新节点的节点都会发起 <em>STORE</em> 调用把相关的 key-value 对传送到新节点之上。为了避免重复的 STORE 调用 ，只有那些自身 ID 比其他节点 ID 更接近 key 的节点才会进行 key-value 对的传送。</p><h2 id="Sketch-of-Proof（待译）">Sketch of Proof（待译）</h2><p>待翻译</p><h2 id="Implementation-Notes（待译）">Implementation Notes（待译）</h2><p>待翻译</p><h2 id="Summary（总结）">Summary（总结）</h2><p>由于采用基于 XOR 度量的拓扑，Kademlia 是第一个结合了可证明的一致性，性能，低时延路由以及单向对称拓扑的点对点系统。Kademlia 还引入了并发参数 $α$，它允许人们在带宽中交换常数因子，以实现异步最低延迟路由选择和无延迟错误恢复。最后，Kademlia 是第一个利用节点故障与正常运行时间成反比关系这一事实的点对点系统。</p><h1>参考</h1><ol><li><a href="https://blog.csdn.net/hoping/article/details/5307320">Kademlia ：一种基于 XOR 度量的 P2P 信息系统</a></li><li><a href="http://www.huamo.online/2018/06/12/P2P%E7%BD%91%E7%BB%9C-Kademlia%E5%8D%8F%E8%AE%AE/">P2P网络–Kademlia协议</a></li></ol>]]></content:encoded>
      
      
      
      <category domain="https://velih.de/tags/Algorithm/">Algorithm</category>
      
      <category domain="https://velih.de/tags/%E7%BF%BB%E8%AF%91/">翻译</category>
      
      
      <comments>https://velih.de/2018/11/08/dht-kademlia/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>在 IPFS 上部署静态博客</title>
      <link>https://velih.de/2018/09/22/ipfs-blog/</link>
      <guid>https://velih.de/2018/09/22/ipfs-blog/</guid>
      <pubDate>Sat, 22 Sep 2018 13:12:00 GMT</pubDate>
      
        
        
          
          
      <description></description>
          
        
      
      
      
      <content:encoded><![CDATA[<p>本文已过时，见 <a href="/2023/02/02/ipfs-static-site/" title="IPFS 静态网站部署指南">IPFS 静态网站部署指南</a></p>]]></content:encoded>
      
      
      
      <category domain="https://velih.de/tags/IPFS/">IPFS</category>
      
      
      <comments>https://velih.de/2018/09/22/ipfs-blog/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>BT 增强建议之 Peer</title>
      <link>https://velih.de/2018/08/30/bt-peer/</link>
      <guid>https://velih.de/2018/08/30/bt-peer/</guid>
      <pubDate>Thu, 30 Aug 2018 11:14:00 GMT</pubDate>
      
        
        
          
          
      <description></description>
          
        
      
      
      
      <content:encoded><![CDATA[<p>本文是 BT 系列文章中的一篇，主要介绍 Peer 以及 Peer 间的通信，有需要的话可以先阅读博文 <a href="/2018/08/26/bt-overview/" title="BT 增强建议之概述">BT 增强建议之概述</a>。</p><h2 id="Peer-来源">Peer 来源</h2><p>在讲 Peer 间的通信前，先总结一下 Peer 的来源：</p><ol><li><strong>Magnet</strong>：磁力连接中有 <strong><a href="http://x.pe">x.pe</a></strong> 参数可以预设一些 Peer；</li><li><strong>Tracker</strong>：Tracker 服务器的作用就是提供 Peer；</li><li><strong>Local Service Discovery</strong>(<a href="http://bittorrent.org/beps/bep_0014.html">BEP14</a>)：通过对本地组播地址 <code>239.192.152.143:6771</code> 和 <code>[ff15::efc0:988f]:6771</code> 发出 info_hash 宣告来尝试获得响应，如果有响应，则添加为 Peer；</li><li><strong>Peer Exchange</strong>：通过 Peer 间的 <strong>Peer Exchange</strong> 扩展消息来与其他 Peer 交换 Peer，后面会详细提到；</li><li><strong>DHT</strong>：通过 DHT 网络获取；</li></ol><h2 id="协议概述">协议概述</h2><p>Peer 间的通信属于应用层协议，它使用的应用层协议可以是 TCP 或者 µTP。</p><p>Peer 间按照元数据中描述的文件片段索引（起始索引为 0）进行数据交换，当一个 peer 下载完成一个分片而且经过了通过了 hash 值的校验，它会通知它的所有 peer 自己拥有了这个片段。</p><p>Peer 连接的 Peer 会有一定上限数量，所有的 Peer 按照 <a href="http://bittorrent.org/beps/bep_0040.html">BEP40 - Canonical Peer Priority</a> 中定义的基于双方 IP 的 crc32-c 值的算法进行排序，选择这个值更小的若干 Peer 进行连接。</p><p>每个连接会包含两个状态位，choked or not（表示是否对对方 choked），interested or not（表示是否对对方的数据感兴趣），状态在连接建立时的初始值为 choked 以及 not interested。因为交互是双方的，一方不仅要存储自己给对方设定的状态，也要存储对方给自己设定的状态，因此实际上会有四个状态位（BEP 中表示只有两个状态位，但是由于主动与被动语态的复杂性以及考虑到实际源码的实现，这里引入成四个状态位，增加了一定的冗余，但便于写作，一定程度上也便于理解）。</p><p>假设 A，B 是在下载同一个资源的对等体。用 A.B 表示 peer A 中 A 与 B 的连接。所以 A 与 B 连接建立时，在 A 的内存空间中的保存的对于 B 的连接会有如下的状态：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">choked = <span class="literal">true</span>;</span><br><span class="line">interested = <span class="literal">false</span>;</span><br><span class="line">peer_choked = <span class="literal">true</span>;</span><br><span class="line">peer_interested = <span class="literal">false</span>;</span><br></pre></td></tr></table></figure><p>同样道理，B 中也会有类似的这样四个状态。且初始状态相同。只有当 A 的 <code>interested == true</code> 而且 <code>peer_choked == false</code> 时，A 才能向 B 索要数据。</p><p>对于 A 而言，有下面几种情况需要更新这一组状态：</p><ul><li>在收到 B 发来的 <strong>choke</strong>/<strong>unchoke</strong> 消息时，会更新 <code>peer_choked</code> 状态置为 true/false；</li><li>在收到 B 发来的 <strong>interested</strong>/<strong>notinterested</strong> 消息时，会更新 <code>peer_interested</code> 状态置为 true/false；</li><li>不断根据自己所拥有的分片与 B 拥有分片的状态（B 通过 <strong>bitfield</strong> 消息告知 A）更新 <code>interested</code> 状态，并发送 <strong>interested</strong>/<strong>notinterested</strong> 消息给 B；</li><li>不断根据 B 的传输表现（Choking 算法）来更新 <code>peer_choked</code> 状态，并发送 <strong>choke</strong>/<strong>unchoke</strong> 消息给 B；</li></ul><h2 id="消息类型">消息类型</h2><p><strong>handshake</strong> 是连接 peer 间连接建立后发送的第一个消息，主要用于通告 info_hash 与 peer_id：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| 19 (1) | &quot;BitTorrent protocol&quot; (19) | reserved_byte (8) | info_hash (20) | peer_id (20) |</span><br></pre></td></tr></table></figure><p><strong>keepalive</strong>，第一个字段为消息体长度，keepalive 消息长度体为 0：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| len (4) |</span><br></pre></td></tr></table></figure><p>除基础消息外的其他消息均有固定的格式如下：消息体长度 + 类型 + 负载。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| len (4) | type (1) | payload |</span><br></pre></td></tr></table></figure><p>可能的类型值有：</p><ul><li>0 - choke</li><li>1 - unchoke</li><li>2 - interested</li><li>3 - not interested</li><li>4 - have</li><li>5 - bitfield</li><li>6 - request</li><li>7 - piece</li><li>8 - cancel</li><li>20 - extend message</li></ul><p>其中 <strong>choke</strong>，<strong>unchoke</strong>，<strong>interested</strong>，<strong>not interested</strong> 消息没有负载。</p><p><strong>bitfield</strong> 消息仅在 handshake 后双方各发送一次，每个比特表示对应的分片是否完整。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| len (4) | 5 (1) | bitfield |</span><br></pre></td></tr></table></figure><p><strong>have</strong> 消息的负载是一个整型数字，peer 在一个分片下载完成并校验通过后发送该附带刚下载完成分片的索引的消息给其他 peer。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| len (4) | 4 (1) | index (4) |</span><br></pre></td></tr></table></figure><p><strong>request</strong> 消息结构如下，用于请求指定分片（index）的范围为 <code>[ offset, offset + length )</code> 的字节，length 一般为 2^14 (16 kiB)，超过则会关闭连接。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| len (4) | 6 (1) | index (4) | offset (4) | length (4) |</span><br></pre></td></tr></table></figure><p><strong>piece</strong> 消息用于回复 request 消息，即返回自身分片（index）的范围为 <code>[ offset, offset + length )</code> 的字节</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| len (4) | 7 (1) | index (4) | offset (4) | block (length) |</span><br></pre></td></tr></table></figure><p><strong>cancel</strong> 消息除了类型和 request 消息不同外，其他均与 request 一致，用于向 peer 取消之前发出的 request 请求。这是由于为了加快最后若干分片的下载速度，客户端会启用 <strong>Endgame</strong> 模式，这个模式下，peer 会向所有的 peer 请求相同的分片片段，当 peer 从某个 peer 获得所需的分片片段后，需要向剩余的 peer 发送 cancel 消息以减少不必要的传输。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| len (4) | 8 (1) | index (4) | offset (4) | length (4) |</span><br></pre></td></tr></table></figure><p>类型为 20 的是扩展消息。</p><h2 id="扩展消息">扩展消息</h2><p><a href="http://bittorrent.org/beps/bep_0010.html">BEP10 - Extension Protocol</a> 中定义了扩展消息。peer 通过将 handshake 消息的保留字节的右数第 20 个比特置为 1 来通告其他 peer 自身支持扩展消息。即可以通过判断表达式 <code>reserved_byte[5] &amp; 0x10</code> 来判断 peer 是否支持扩展消息。</p><p>扩展消息的基础结构如下，实际上相当于是类型为 20 的普通消息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| len (4) | 20 (1) | extended_messag_id (1) | payload |</span><br></pre></td></tr></table></figure><p>extended_messag_id 为 0 的消息是 <strong>Extend Handshake</strong> 消息。</p><h3 id="Extend-Handshake">Extend Handshake</h3><p>Extend Handshake 消息的有效载荷是一个 bencode 字典。字典中的所有键都是可选的，peer 需要忽略所有自己不支持的键。可选的键（还可以有更多）如下:</p><ul><li><strong>m</strong>：字典，表示支持的扩展消息，键是扩展消息名称，值是扩展消息的 id（与 extended_messag_id 对应）。peer 通过这个键通告其他 peer 自己支持的消息类型，且该 peer 之后发送其他的扩展消息就会使用在这里对应的 extended_messag_id。扩展消息名称的格式一般为 <code>客户端缩写_消息名称</code>，这样可以实现全网全局消息类型唯一（侧重实现）；而 extended_messag_id 则是自己客户端自己定义，在 m 字典中不重复即可（侧重索引），这样便可以做到单向通信唯一。</li><li><strong>p</strong>：整型，表示本地监听端口。帮助另一方了解自己的端口信息。连接的接收方是不需要发送这个扩展消息的，因为接收方的端口是已知的。（实际上 peer 间通信无论是基于 TCP 还是 µTP（UDP），接收方理论上都可以从传输层获得端口数据）。</li><li><strong>v</strong>：字符串，表示客户端的名称与版本，这个比 peer id 更可靠一些。</li><li><strong>yourip</strong>：字符串，表示在 peer 视角中对方 peer 的 IP，一般客户端通过此获取自己的公网 IP。</li><li><strong>ipv6</strong>：字符串，表示自身压缩格式的 IPv6 地址。可能对方 peer 更喜欢使用 IPv6 地址。</li><li><strong>ipv4</strong>：字符串，表示自身压缩格式的 IPv4 地址。可能对方 peer 更喜欢使用 IPv4 地址。</li><li><strong>reqq</strong>：整型，表示自身的在不丢弃消息情况下可以保留的未处理的消息数量。在 libtorrent 中这个值是 250。</li></ul><p>这个消息需要在普通 handshake 成功后立即发送，在连接的生命周期内这个 Extend Handshake 多次发送都是有效的，但实际实现中有可能被忽略。如果后续的 Extend Handshake 消息指定 m 字典中某些扩展的扩展 id 为 0，则表示禁用这些扩展。</p><h3 id="Metadata-Request-ut-metadata">Metadata Request(ut_metadata)</h3><p><a href="http://bittorrent.org/beps/bep_0009.html">BEP9 - Extension for Peers to Send Metadata Files</a> 中定义了磁力链接，同时也定义了用于从 Peer 获取元数据的扩展消息 <strong>UT Metadata</strong>。</p><p>如果一个 peer 的客户端支持 <strong>UT Metadata</strong> 消息，那么当该 peer 向其他 peer 发送 Extend Handshake 消息时，需要在字典 m 中加入 <strong>ut_metadata</strong> 这个键，同时保持其对应的消息 id 在 m 字典中唯一。特殊的是对于这个消息的支持还需要在 Extend Handshake 消息负载字典中加入一个键 <strong>metadata_size</strong>，表示元数据的字节数。</p><p><strong>UT Metadata</strong> 消息的负载也是一个 bencode 字典，有如下的键：</p><ul><li><strong>msg_type</strong>：整型，代表消息类型，可能的类型有：<ul><li><strong>request</strong>：0。请求类型，即请求序号为 <strong>piece</strong> 的 metadata 片段。请求类型的返回类型为 <strong>data</strong> 或者 <strong>reject</strong>。</li><li><strong>data</strong>：1。正常返回序号为 <strong>piece</strong> 的 metadata 片段。元数据会按照 16 kiB 大小切分，除了最后一片段，其余的都应该为 16 kiB 大小，序号也由此分割大小得来。元数据片段作为负载的一部分跟在整个字典后面，其并不使用 bencode 编码，但是长度需要计算在 <strong>len</strong> 中。</li><li><strong>reject</strong>：2。表示被请求的 peer 没有序号为 <strong>piece</strong> 的 metadata 片段。也有可能是一定时间内请求超过数量限制，为了防止洪泛攻击，直接表示拒绝。</li></ul></li><li><strong>piece</strong>：指定元数据的分片序号。</li><li><strong>total_size</strong>：仅在 <strong>data</strong> 类型消息中出现，和握手消息中的 <strong>metadata_size</strong> 语义一致。</li></ul><h3 id="Partial-Seeds">Partial Seeds</h3><p>这个扩展是为了让 BT 支持对 Partial Seeds（部分种子，<a href="http://bittorrent.org/beps/bep_0021.html">BEP21 - Extension for partial seeds</a>）的识别与进一步优化。部分种子就是资源不完整但是也不再进行下载的 peer。这种情况发生在多文件种子中，用户只设定下载一部分文件。</p><p>这个扩展不定义额外的扩展消息，但是在扩展握手消息的字典中加入一个键 <strong>upload_only</strong>，值为整型，如果 peer 对下载不感兴趣则需要讲此值置为 1。</p><p>在 Tracker 的 Scrape 请求回复中，定义了 <strong>complete</strong>, <strong>incomplete</strong> 以及 <strong>downloaded</strong> 三种状态的 peer。为了让其他 peer 可以通过 Tracker 知晓 Partial Seeds 的情况，扩展定义了在 Scrape 回复中加入类型 <strong>downloaders</strong>，表示处于活跃状态，未完成下载且仍然需要继续下载的 peer 数量，Partial Seed 的数量可以通过 <code>incomplete - downloaders</code> 得到。同时让要让 Tracker 知晓 peer 自身处于 Partial Seed 状态，则需要通过 <code>event=paused</code> 事件进行告知，且每次通告时都要发送该事件。</p><h3 id="Peer-Exchange-ut-pex">Peer Exchange(ut_pex)</h3><p>Peer Exchange(PEX) 用于在 peer 间交换 peer 列表。通过在 Extend Handshake 消息的 字典 m 中加入 <strong>ut_pex</strong> 这个消息名称来表明支持，同样道理，消息 id 在 m 字典中保持唯一即可。</p><p>PEX 消息的负载也是一个 bencode 字典，有如下的键：</p><ul><li><strong>added</strong>：当前连接的 IPv4 peer 压缩格式列表，告知对方进行添加</li><li><strong>added.f</strong>：当前连接的 IPv4 peer 标志位，每个 peer 一个字节</li><li><strong>added6</strong>：当前连接的 IPv6 peer 压缩格式列表，告知对方进行添加</li><li><strong>added6.f</strong>：当前连接的 IPv6 peer 压缩格式列表标志位</li><li><strong>dropped</strong>：过去断开连接的 IPv4 peer 压缩格式列表，告知对方进行删除</li><li><strong>dropped6</strong>：过去断开连接的 IPv6 peer 压缩格式列表，告知对方进行删除</li></ul><p>标志位定义如下：</p><ul><li>0x02：属于 seed 或者 partial seed</li><li>0x04：支持 uTP</li><li>0x01：prefers encryption, as indicated by e field in extension handshake</li><li>0x08：peer indicated ut_holepunch support in extension handshake</li><li>0x10：outgoing connection, peer is reachable</li></ul><h4 id="发送规则">发送规则</h4><ul><li>如果 peer 与某些 peer 断开连接，则需要需要在适当时候发送 PEX 消息，将断开连接的 peer 放在 dropped 中；</li><li>每分钟发送的 PEX 消息不能超过一条；</li><li>不需要在握手后立即发送 PEX 消息，在收集满一定的 peer 之后再发送效果更好；</li><li>添加或删除的 peer 列表中不能包括重复项，也不能在同一个 PEX 消息中删除添加的 peer；</li><li>除了最初的 PEX 消息之外，每条消息中添加的 peer 数量或者 删除的 peer 数量均不能超过 50 条；</li><li>added, added6, dropped, dropped6 四个键中至少需要有一个；</li><li>peer 可能会与严重违反这些规则的 peer 断开连接；</li></ul><h4 id="扩充-seed">扩充 seed</h4><p>每个 peer 会执行如下的执行一些规则来断开与部分 peer 的连接。比如</p><ol><li>在作种的时候会断开与 seed 和 partial seed 的连接；</li><li>根据 peer id 断开 IPv4 以及 IPv6 地址实际上属于同一个 peer 的一个连接，保留自己偏爱的地址家族连接；</li></ol><p>这样的策略下，在 seed 占主导地位的 swarm 中通过 PEX 传播的活跃 peer 会不足。类似地，在 IPv4 占主导的 swarm 中，只支持 IPv6 的 peer 将很难获得 IPv6 的 peer。这很大程度降低了 PEX 消息的有效性。</p><p>为了解决这些问题，如果一个 peer 连接到一个特定地址家族的 peer 少于25个，活跃度的要求就会放宽。因为一下原因导致连接断开的 peer 也会被保存下来，并有资格被发在 PEX 消息的 added 中：</p><ol><li>因为 peer id 相同而被断开的另一个地址家族的连接；</li><li>因缺乏兴趣而断开连接的 peer，比如对方是 seed/partial seed 或者对方拥有的分片不满足自己的需求；</li><li>因为超过本地资源限制而断开的连接，比如全局的连接上限；</li></ol><p>为了保证 peer 的有效性，因为这些原因添加到 added 中的 peer 只能通过 PEX 消息发送一次，发送完后必须从等待发送列表中删除。</p><h4 id="安全性">安全性</h4><p>通过 PEX 获得的 peer 应该视为不可信的。攻击者可能通多伪造 PEX 消息来攻击这个 swarm。攻击者也可能通过 PEX 消息诱导 BT 客户端对特定 IP 进行尝试连接而引发 DDoS 攻击。</p><p>为了缓解这些问题，peer 应该避免从单个 PEX 源获取其所有连接作为候选连接。应忽略具有不同的端口的重复 IP，还可以根据 peer 的优先级来进行（协议概述中提到）排序。</p><h2 id="快速扩展（Fast-Extension）">快速扩展（Fast Extension）</h2><p>另外还有类似扩展消息的快速扩展消息，通过将握手消息的 <code>reserved_byte[7] |= 0x04</code> 来通告支持快速扩展，这里只列出快速扩展消息的种类，具体协议格式可参见 <a href="http://bittorrent.org/beps/bep_0006.html">BEP06 - Fast Extension</a>。</p><ul><li><strong>Have All/Have None</strong>：来表示拥有所有分片或者未拥有任何分片，是 <strong>bitfield</strong> 消息的快速版本；</li><li><strong>Suggest Piece</strong>：建议其他 peer 下载某分片；</li><li><strong>Reject Request</strong>：拒绝 peer 对某个片段的请求；</li><li><strong>Allowed Fast</strong>：表示如果 peer 请求这个分片，即使它处于 choked 状态也会给它；</li><li><strong>lt Dont Have</strong>：在某些情况下（比如资源短缺，LRU Cache 过期）会导致 peer 不再拥有某个片段，则可以通过此消息告知其他 peer，该扩展定义在 <a href="http://bittorrent.org/beps/bep_0054.html">BEP54 - The lt_donthave extension</a> 中；</li></ul><h2 id="分片选择策略">分片选择策略</h2><p>选择一个好的分片下载顺序与否对下载性能有这很大影响。如果选择了一个差的分片下载选择算法，则某一时刻可能所有分片你都可以下载，但是之后就没有你想下载的分片了。BT 中执行一下策略：</p><h3 id="Strict-Priority（严格模式）">Strict Priority（严格模式）</h3><p>一旦请求了某个分片的子片段，那么就会在请求其他子片段之前请求该特定分片的剩余子片段，以尽量优先获得这个完整的分片。</p><h3 id="Rarest-First（稀有优先）">Rarest First（稀有优先）</h3><p>在选择接下来下载哪个分片时，peer 会选择最稀有的分片（自己没有这个分片，同时其他 peer 有，但是有这个分片的 peer 数量相对其他分片最少）进行下载。这个算法保证了不稀有的分片在之后仍然能被下载到，同时稀有的分片在逐渐变多。通过尽快复制最稀有的分片，减小了稀有分片在当前连接的 peer 中完全消失的可能性。</p><h3 id="Random-First-Piece（随机首分片）">Random First Piece（随机首分片）</h3><p>当下载开始时，不会使用稀有优先算法。开始时 peer 没有分片可以用于上传，所以最重要的是尽快得到一个完整的分片。稀有的分片往往只被某一个 peer 拥有，从这个 peer 处下载这个分片（分成多个子片段）将会慢于从多个 peer 处下载相同分片的不同子片段。出于这个原因，刚开始下载时，会随机选择一个分片进行下载，随后策略转为稀有优先。</p><h3 id="Endgame-Mode">Endgame Mode</h3><p>有时从一个 peer 请求某个分片会很慢，这在下载整个资源你的中途不会是一个问题（因为中途同时发生不少请求），但是这种情况可能会影响最终的即将下载完成阶段。当所有剩余的子片段都已经在向其他 peer 请求时，它会同时向所有的 peer 请求这些子片段。当某一个 peer 返回了一个子片段，就向剩余的 peer 发送 cancel 消息以节约带宽。在实践过程中，Endgame 模式持续时间非常短，所以浪费的带宽不多，而且使得资源的最后一部分下载非常快。</p><h2 id="Choking-算法">Choking 算法</h2><p>BT 没有中心化的资源分配，每个 peer 有责任去最大化自己的下载速率。Peer 执行一种变种 tit-fot-tat 策略，从与自己相连的 peer 处下载分片，并选择合适的 peer 进行上传，对其他 peer 进行 choke。choke 表现为拒绝上传，但下载仍可继续，同时连接被保持不销毁，在 choke 结束后连接不需要重建。Choking 算法对于 BT 来说不是必须的，但是如果需要有一个好的下载性能是非常重要的。一个好的 choking 算法需要利用好所有的资源，提供好的上传给其他 peer，同时惩罚那些只下载不上传的 peer。</p><p>BT 中使用的变种 tit-fot-tat 策略是囚徒困境的应用，博主 youxu 的文章 <a href="https://blog.youxu.info/2008/12/31/tit-for-tac-and-p2p-software/">P2P客户端的策略和奇妙的对策论</a> 对这此有着很通俗易懂的解释。</p><p>对于某个 peer 的 Choking 算法 可以描述如下：</p><ol><li><strong>Choking Algorithm</strong>：每 T 时间选择合适的 k 个 peer 进行 unchoke，选择的标准为过去 S 时间 peer 的下载速率；</li><li><strong>Optimistic Unchoking</strong>：每 nT 时间，随机选择一个 peer 进行 unchoke，以尝试发现更优质的 peer；</li><li><strong>Anti-snubbing</strong>：如果 mT 时间内没有从某个 peer 处获取到一个分片，则认为被 <strong>snubbed</strong> 了，对其进行 choke；</li><li><strong>Upload Only</strong>：当一个 peer 下载完成了，即成为了一个 seed，则只进行上传，不再下载。peer 会选择那些该 peer 对其有较高上传速率的 peer 进行上传。</li></ol><p>实际实现中 T = 10s, k = 7, S = 20s, n = 3, m = 6。</p><h2 id="参考资料">参考资料</h2><ol><li><a href="https://forum.utorrent.com/topic/90069-question-about-canonical-peer-priority/">Question About Canonical Peer Priority</a></li><li><a href="https://superuser.com/a/562970">What do Flags and Reqs mean in uTorrent? - Super User</a></li></ol>]]></content:encoded>
      
      
      
      <category domain="https://velih.de/tags/BT/">BT</category>
      
      
      <comments>https://velih.de/2018/08/30/bt-peer/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>BT 增强建议之 Tracker</title>
      <link>https://velih.de/2018/08/27/bt-tracker/</link>
      <guid>https://velih.de/2018/08/27/bt-tracker/</guid>
      <pubDate>Sun, 26 Aug 2018 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description></description>
          
        
      
      
      
      <content:encoded><![CDATA[<p>本文是 BT 系列文章中的一篇，主要介绍 Tracker 服务器的工作原理，有需要的话可以先阅读博文<a href="/2018/08/26/bt-overview/" title="BT 增强建议之概述">BT 增强建议之概述</a>。</p><p>P2P 是 peer-to-peer 的缩写，为了让网络中的一个 Peer 如何才能找到另外志同道合的 Peer，Tracker 扮演着至关重要的月老作用。Tracker 是一个 HTTP 或者 UDP 服务器，作用是帮助 peer 找到其他拥有相同资源的 peer。</p><p>后来有了 DHT 网络之后，Tracker 的作用逐渐弱化，但是 Tracker 代表的这种中心化一定程度上相对 DHT 代表的去中心化效率还是比较高的。如同在概述前言中所说的一样，”过时“的技术某些情况下是会“复活&quot;的，所以了解一下 Tracker 的工作原理并不是坏事。</p><h2 id="HTTP-Tracker">HTTP Tracker</h2><p>HTTP Tracker 处理的来自 peer 的 GET 请求包括以下参数：</p><ul><li><strong>info_hash</strong>：即需要下载的资源的 torrent 文件的 info 部分的 SHA1 值，或者磁力链接中的 xt 值。</li><li><strong>peer_id</strong>：标示这个客户端的字符串，一般会包含客户端的版本信息以及随机数据（<a href="http://www.bittorrent.org/beps/bep_0020.html">BEP20 - Peer ID Conventions</a>）。</li><li><strong>ip</strong>：可选，peer 的 IP。</li><li><strong>port</strong>：可选，peer 监听的端口，一般是 6881。理论上 Tracker 应该需要对这个 ip 和 port 的组合进行 NAT 检查。</li><li><strong>uploaded</strong>：该资源至今为止的上传字节数。</li><li><strong>downloaded</strong>：该资源至今为止的下载字节数。</li><li><strong>left</strong>：该资源剩余未完成下载的字节数。</li><li><strong>event</strong>：可选，当前资源下载状态，可以是<code>started</code>，<code>completed</code>，<code>stopped</code>，每次发生状态变化时进行通告。</li></ul><p>这个请求的回复是使用 bencode 编码的字典，有如下的键：</p><ul><li><strong>failure reason</strong>：字符串，如果请求失败就会有这个键，表示失败的原因，另外 <a href="http://www.bittorrent.org/beps/bep_0031.html">BEP31 - Failure Retry Extension</a> 中定义了一个 <strong>retry in</strong> 字段来告知发起请求的 peer 重试间隔分钟数，或者永远不进行重试。如果成功就会有以下两个键。</li><li><strong>interval</strong>：整型，告知 peer 之后进行 GET 请求的时间间隔，但是如果 peer 的状态发生变化或者需要从 Tracker 获取更多的 peer 就会不管这个时间间隔限制而直接重新请求。</li><li><strong>peers</strong>：列表，每个子项都是字典，字典的键分别为 <strong>id</strong>，<strong>ip</strong>，<strong>port</strong>，分别与 GET 请求中的 peer_id，ip，port 含义一致，用于唯一确定每个其他 peer。</li></ul><p>在 HTTP Tracker 的 URL 上进行适当的改造可以得到 Scrape URL（在 <a href="http://www.bittorrent.org/beps/bep_0048.html">BEP48 - Tracker Protocol Extension: Scrape</a> 中提出）。通过请求 Scrape URL 可以得到指定 info_hash 的当前 peers 的大致统计信息，包括处于活跃状态且已完成下载（<strong>complete</strong>）的 peer 数量、处于活跃状态但未完成下载（<strong>incomplete</strong>）的 peer 数量、曾经完成过下载（<strong>downloaded</strong>）的 peer 数量。支持同时请求多个 info_hash 。这些数据帮助 peer 决定是否应该执行 Tracker GET 请求，从而一定程度上减小 HTTP Tracker 服务器的压力。</p><p>而 UDP 本身比 HTTP 消耗更小些，且直接实现了 Scrape 请求。</p><h2 id="UDP-Tracker">UDP Tracker</h2><p>由于 HTTP 是基于 TCP 的，连接的打开和关闭会带来一定损耗。这种类似的发现服务使用 UDP 可以大大降低 Tracker 服务器的压力。<a href="http://www.bittorrent.org/beps/bep_0015.html">BEP15 - UDP Tracker Protocol</a> 提出了基于 UDP 的 Tracker 方案。</p><p>为了防止 UDP Flood 攻击，peer 与 UDP Tracker 的通信会首先通过 <strong>connect</strong> 动作进行类似 TCP 的三次握手，约定一个 connection_id，之后所有的动作都会使用这个 connection_id。<strong>announce</strong> 动作可以向 UDP Tracker 完成类似对 HTTP Tracker 的 GET 请求。使用 <strong>scrape</strong> 动作完成类似对 HTTP Tracker 的 Scrape 请求。如果出现错误，Tracker 会触发 <strong>error</strong> 动作。</p><p>GET 请求如果需要扩展参数只需要在请求的 URL 中增加相关的参数即可，在 UDP Tracker 中，实现这种增加参数的可扩展性则需要另外想办法。<a href="http://www.bittorrent.org/beps/bep_0041.html">BEP41 - UDP Tracker Protocol Extensions</a> 对于其实现方案举了一个这样的例子：一个 Tracker 服务器想要提高它的运行效率而限制其所能服务的 info_hash，他们考虑在在 peer 对 Tracker 的 URL 中加入一个 auth 字段，即该 info_hash 的签名，这样的情况下，Tracker 可以通过 Torrent 或者 Magnet 发布这个带有 info_hash 签名的 Tracker URL，peer 对该 Tracker 的请求时带上该签名，Tracker 就可以验证这个签名是否与 info_hash 相匹配以及这个 info_hash 是否在其服务的范围，从而实现限制。</p><p>比如 Tracker 在一个 Magnet 中附加的 tr 参数如下，auth 字段就是指的 info_hash 的示例签名：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">udp://tracker.example.com:80/?auth=0xA0B1C</span><br></pre></td></tr></table></figure><p>实现 BEP41 方案后的客户端在对 UDP Tracker 发起 <strong>announce</strong> 请求动作时，会在包体尾部添加如下字节：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0x2, 0xC, &#x27;/&#x27;, &#x27;？&#x27;, &#x27;a&#x27;, &#x27;u&#x27;, &#x27;t&#x27;, &#x27;h&#x27;, &#x27;=&#x27;, &#x27;A&#x27;, &#x27;0&#x27;, &#x27;B&#x27;, &#x27;1&#x27;, &#x27;C&#x27;, 0x1, 0x1, 0x0</span><br></pre></td></tr></table></figure><p><code>0x2</code> 表示附加的选项类型是 <strong>URLData</strong>，这个选项会紧跟着两个参数，<code>0xC</code> 表示后面的内容长度为 12，后续的 12 字节就是 URLData 的内容；<code>0x1</code> 表示附加的选项类型是 <strong>NOP</strong> ,即填充字节，连续两个 <code>0x1</code> 表示填充两个字节，<code>0x0</code> 表示附加的选项类型是 <strong>EndOfOptions</strong>，即结束标志。最后三个选项不是必须的，这里加入他们只是说明有这些选项。</p><p>当然这里例子在 HTTP Tracker 中也容易实现，但是 UDP Tracker 有着更好的网络优化。</p><h2 id="Tracker-相关增强方案">Tracker 相关增强方案</h2><p>BEP 中还有不少改进提案是针对 Tracker 的：</p><h3 id="Torrent-文件多-Tracker-支持">Torrent 文件多 Tracker 支持</h3><p>Torrent 文件中 <strong>announce</strong> 字段只支持定义一个 Tracker，<a href="http://www.bittorrent.org/beps/bep_0012.html">BEP12 - Multitracker Metadata Extension</a> 中提出了让 Torrent 携带多个 Tracker 的方案。<br>在 Torrent 文件根节点增加一个键 <strong>announce-list</strong>，这里简易的表示为 <strong>/announce-list</strong>，之后在 Torrent 中增加键时也会简易地表示成这样。如果 Torrent 文件中有 <strong>announce-list</strong>，则会忽略 <strong>announce</strong>。<strong>announce-list</strong> 是一个列表，<em><strong>列表的每个子项是都是一个子项是 Tracker URL 的列表</strong></em>。之所以是一个子项为列表的列表的原因在 BEP12 中有详细的介绍与举例。此处不详细展开。</p><h3 id="DNS-辅助纠正-Tracker-地址">DNS 辅助纠正 Tracker 地址</h3><p>考虑到部分种子中的 Tracker 服务器可能变更服务端口或者讲 HTTP 服务改为 UDP 服务。<a href="http://www.bittorrent.org/beps/bep_0034.html">BEP34 - DNS Tracker Preferences</a> 一种基于 DNS 的解决方案。<br>如果客户端发现自己所请求的 Tracker 没有相应，则可以查询相应域名的 DNS TXT 记录。如果有 TXT 记录是以 ”BITTORRENT“ 开头，则可以对这个 Tracker 地址进行纠正。这类 TXT 记录有以下几种类型：</p><ul><li>“BITTORRENT”：表明该主机不再运行任何 Tracker 服务。</li><li>“BITTORRENT DENY ALL”：和前一个一致，但是表意更加明显。</li><li>“BITTORRENT UDP:1337 TCP:80”：表示这个主机运行两个 Tracker 服务，分别时在 UDP 端口 1337 和 TCP 端口 80 上，且优先建议使用 UDP 端口。</li></ul><p>以下是一个相关的 TXT 记录查询过程，这个主机在多个 UDP 端口上运行了 Tracker 服务：</p><figure class="highlight shell"><figcaption><span>dig txt</span><a href="/downloads/code/bt_dig_dns_txt.txt">view raw</a></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">dig 9.rarbg.to txt</span></span><br><span class="line">;; QUESTION SECTION:</span><br><span class="line">;9.rarbg.to.                    IN      TXT</span><br><span class="line"></span><br><span class="line">;; ANSWER SECTION:</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     &quot;BITTORRENT UDP:2710&quot;</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     &quot;BITTORRENT UDP:2720&quot;</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     &quot;BITTORRENT UDP:2730&quot;</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     &quot;BITTORRENT UDP:2740&quot;</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     &quot;BITTORRENT UDP:2750&quot;</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     &quot;BITTORRENT UDP:2770&quot;</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     &quot;BITTORRENT UDP:2780&quot;</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     &quot;BITTORRENT UDP:2790&quot;</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     &quot;BITTORRENT UDP:2800&quot;</span><br><span class="line"></span><br><span class="line">;; Query time: 207 msec</span><br><span class="line">;; SERVER: 1.1.1.1#53(1.1.1.1)</span><br><span class="line">;; WHEN: Sat Aug 25 05:46:02 CST 2018</span><br><span class="line">;; MSG SIZE  rcvd: 327</span><br></pre></td></tr></table></figure><h3 id="Tracker-返回公网-IP">Tracker 返回公网 IP</h3><p><a href="http://www.bittorrent.org/beps/bep_0024.html">BEP24 - Tracker Returns External IP</a> 通过在 GET 请求的返回中（UDP 也适用，下同）增加一个 <strong>external ip</strong> 字段来告知发起请求的 peer 自身的公网 IP。[Todo:客户端需要知道自己的公网 IP 做什么用暂时还不太清楚…ff]<br>通过 peer 间的 yourip 扩展消息也可以获得自身的公网 IP。</p><h3 id="Tracker-返回压缩-peer-列表">Tracker 返回压缩 peer 列表</h3><p><a href="http://www.bittorrent.org/beps/bep_0023.html">BEP23 - Tracker Returns Compact Peer Lists</a> 提出了一种压缩 GET 请求返回中 peers 字段值的方式以在一定程度上减小 Tracker 服务器的流量压力。<br>这种方案的返回值中 peers 字段不再是一个列表，而是一个字符串，它由代表每个 peer 的六个字节（4 个字节用于 IP 地址，2 个字节用于端口）拼接而成。去除了 peer_id 这个字段，事实证明没有这个字段也没什么关系。<br>Peer 通过在 GET 请求中增加 <strong>compact</strong> 参数来告知 Tracker 服务器自己更喜欢什么格式，0 为原始格式，1 为压缩格式。但是 Tracker 不一定会接受这个参数的建议，所以客户端仍然需要同时支持两种格式。</p><h3 id="IPv6-支持">IPv6 支持</h3><p><a href="http://www.bittorrent.org/beps/bep_0007.html">BEP7 - IPv6 Tracker Extension</a> 提供了优化 Tracker 对 IPv6 支持的方案。<br>通过在 GET 请求中增加 <strong>ipv6</strong> 参数或者 <strong>ipv4</strong> 参数来告知 Tracker 服务器自己的相应 IP 版本的地址，如果在这两个字段中没有端口信息，那么将 <strong>port</strong> 字段作为端口。如果 Tracker compact 格式返回 peer 列表，那么它会在回复中增加 <strong>peers6</strong> 字段以返回使用 IPv6 的 peer，每个 peer 占用 18 字节。编码方式与 peers 字段一致。</p><h2 id="参考资料">参考资料</h2>]]></content:encoded>
      
      
      
      <category domain="https://velih.de/tags/BT/">BT</category>
      
      
      <comments>https://velih.de/2018/08/27/bt-tracker/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>BT 增强建议之 Metadata：Torrent 与 Magnet</title>
      <link>https://velih.de/2018/08/26/bt-metadata/</link>
      <guid>https://velih.de/2018/08/26/bt-metadata/</guid>
      <pubDate>Sun, 26 Aug 2018 14:00:00 GMT</pubDate>
      
        
        
          
          
      <description></description>
          
        
      
      
      
      <content:encoded><![CDATA[<p>本文是 BT 系列文章中的一篇，主要介绍种子文件结构与磁力链接的原理，有需要的话可以先阅读博文 <a href="/2018/08/26/bt-overview/" title="BT 增强建议之概述">BT 增强建议之概述</a>。</p><p>在磁力链接出现前，BT 下载的第一步就是获取 Torrent（种子）文件。种子文件中包含了资源的最关键信息 —— Metadata（元数据）。Magnet（磁力链接）的引入则省去了获取种子文件这一步，但是仍然需要元数据，只是改为从 Peer 处获取。有了元数据后，才能知道整个资源的概况，继而进行下载。</p><h2 id="Torrent">Torrent</h2><h3 id="文件结构">文件结构</h3><p>种子文件使用 bencode 进行编码，整个文件是一个字典。有下列主要的 key（value 中，整型值的单位均为字节，字符串默认使用 UTF-8 编码）：</p><ul><li><strong>announce</strong>：字符串。Tracker 的 URL 地址，此处仅能定义一个 Tracker。</li><li><strong>info</strong>：字典。资源的元数据，可以有如下子字段：<ul><li><strong>length</strong>：整型。如果有该字段，则代表种子为单文件种子，代表该文件的大小。</li><li><strong>files</strong>：列表，子项类型为字典。如果有该字段，则代表种子为多文件种子。一个种子只能为单文件种子或者多文件种子，因此 <strong>files 字段和上述 length 字段只能选其中之一</strong>。files 字典的字段包括：<ul><li><strong>length</strong>：整型。代表该文件的大小。</li><li><strong>path</strong>：列表，子项类型为字符串。子目录名称列表，最后一项为文件名，因此该列表长度至少需要为 1。</li></ul></li><li><strong>name</strong>：字符串。如果是单个文件的种子，那么这个字段表示该文件的文件名，否则表示多个文件存储的根目录。</li><li><strong>piece length</strong>：整型。为了方便传输与节点间交换数据，文件被分片，这个字段代表每个片段的大小，除了最后一片可能会被截断，这个值一般为 2 的幂次。</li><li><strong>pieces</strong>：字符串。实际内容为分片的 SHA1 值列表。每个 SHA1 值占用 160 比特。</li></ul></li></ul><h3 id="举例">举例</h3><h4 id="单文件种子">单文件种子</h4><p>这是一个单文件种子文件的 JSON 化结构示意，文件 debian-503-amd64-CD-1.iso 被分成大小为 256 KiB 的 $\left(\lceil\frac{length}{piece length}\rceil = 2588\right)$ 片。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;announce&quot;</span><span class="punctuation">:</span> <span class="string">&quot;http://bttracker.debian.org:6969/announce&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;info&quot;</span><span class="punctuation">:</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;debian-503-amd64-CD-1.iso&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;piece length&quot;</span><span class="punctuation">:</span> <span class="number">262144</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;length&quot;</span><span class="punctuation">:</span> <span class="number">678301696</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;pieces&quot;</span><span class="punctuation">:</span> &lt;binary SHA1 hashes&gt;</span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h4 id="多文件种子">多文件种子</h4><p>这个一个包含两个文件的种子的示例。相对于单文件种子，它使用了 files 字段取代了 length 字段。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;announce&quot;</span><span class="punctuation">:</span> <span class="string">&quot;http://tracker.site1.com/announce&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;info&quot;</span><span class="punctuation">:</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;directoryName&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;piece length&quot;</span><span class="punctuation">:</span> <span class="number">262144</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;files&quot;</span><span class="punctuation">:</span></span><br><span class="line">        <span class="punctuation">[</span></span><br><span class="line">            <span class="punctuation">&#123;</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;111.txt&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span> <span class="attr">&quot;length&quot;</span><span class="punctuation">:</span> <span class="number">111</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;222.txt&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span> <span class="attr">&quot;length&quot;</span><span class="punctuation">:</span> <span class="number">222</span><span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;pieces&quot;</span><span class="punctuation">:</span> &lt;binary SHA1 hashes&gt;</span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h2 id="Magnet">Magnet</h2><h3 id="MAGNET-URI-Project">MAGNET-URI Project</h3><p>提到 Magnet（磁力链接）大家都会想到 BT，但是磁力链接不是因为 BT 而诞生的，也不止用于 BT，事实上磁力链接的来自 <a href="http://magnet-uri.sourceforge.net/">MAGNET-URI Project</a> 这个项目：</p><blockquote><p>MAGNET is a work-in-progress URI specification, and collection of standard practices/implementing code to allow a website to seamlessly integrate with features made available by local utility programs. In one way, it could be thought of as a vendor- and project-neutral generalization of the “freenet:” and “ed2k:” URI-schemes used by the Freenet and EDonkey2000 peer-to-peer networks, respectively.</p><footer><strong>Gordon Mohr</strong><cite><a href="http://magnet-uri.sourceforge.net/magnet-draft-overview.txt">magnet-uri.sourceforge.net/magnet-draft-overview.txt</a></cite></footer></blockquote><p>磁力链接是一个统一的规范，它希望这种 P2P 的链接都可以以按照这个规范展示，这样的话当用户在网页上点击磁力链接的时候，就可以磁力链接的参数（<code>xt</code>，下文会提及）“召唤”合适的客户端。它先被 eDonkey（电驴）推动，电驴链接理论上可以被转换成磁力链接。转换过程大致如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ed2k://|file|&lt;name&gt;|&lt;file-size&gt;|&lt;ed2k-hash&gt;|/</span><br><span class="line">magnet:?xt=urn:ed2k:&lt;ed2k-hash&gt;&amp;xl=&lt;file-size&gt;&amp;dn=&lt;name&gt;</span><br></pre></td></tr></table></figure><p>然而，这个 MAGNET-URI Project 后来应该没有被推动下去，甚至连电驴自己的客户端都没有支持 ed2k 的 magnet 格式。直到后来在 BT 中大放异彩，导致现在狭义上的磁力链接就是指 BT 中使用的磁力链接。</p><h3 id="BT-中的磁力链接">BT 中的磁力链接</h3><p>BT 中的磁力链接大概有这两种格式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">v1: magnet:?xt=urn:btih:&lt;info-hash&gt;&amp;dn=&lt;name&gt;&amp;tr=&lt;tracker-url&gt;&amp;x.pe=&lt;peer-address&gt;</span><br><span class="line">v2: magnet:?xt=urn:btmh:&lt;tagged-info-hash&gt;&amp;dn=&lt;name&gt;&amp;tr=&lt;tracker-url&gt;&amp;x.pe=&lt;peer-address&gt;</span><br></pre></td></tr></table></figure><p>根据 <a href="https://zh.wikipedia.org/wiki/%E7%BB%9F%E4%B8%80%E8%B5%84%E6%BA%90%E5%AE%9A%E4%BD%8D%E7%AC%A6">URL 的定义</a>，<code>magnet</code> 前缀表示这个链接是磁力链接，<code>？</code> 后表示为 GET 模式查询参数列表，参数使用 <code>&amp;</code> 符号隔开。BT 磁力链接的参数如下:</p><ul><li><strong>xt</strong>：表示包含文件散列函数值的 URN，这是唯一一个必选参数，可能的 URN 类型有：<ul><li><strong>btih</strong>：表示 Torrent 文件 info 部分的 SHA1 值，可以是 Hex 编码或者 Base32 编码形式。</li><li><strong>btmh</strong>：表示 Torrent 文件 info 部分的 HEX 编码 <a href="https://github.com/multiformats/multihash">multihash</a> 值，multihash 是由创造 IPFS  的 Protocal Lab 的项目，用于编码多种 hash 函数的 hash 结果。<strong>btmh 可以和 btih 同时存在，这个应该和 <a href="https://security.googleblog.com/2017/02/announcing-first-sha1-collision.html">SHA1 被破解</a>相关——有 btmh 中使用其他 hash 函数得到的 hash 值加上原来的 SHA1 值就可以做到兼容，同时检测碰撞。</strong></li></ul></li><li><strong>dn</strong>：表示建议显示的文件名。</li><li><strong>tr</strong>：表示 Tracker的 URL，如果有多个 Tracker,则会有多个 <code>tr</code> 参数。</li><li><strong><a href="http://x.pe">x.pe</a></strong>：表示 Peer 的，格式为 <code>hostname:port</code>，<code>ipv4-literal:port</code> 或者 <code>[ipv6-literal]:port</code>，这些 Peer 可以被添加到 Peer 列表中用于获取元数据以及后续的文件片段获取。实际上 Magnet 链接中定义了一个通用的参数 <code>xt</code> 用于指定类似 <code>x.pe</code> 所表示的 P2P 连接，但是由于没有合适的 URI 标识符分配给 BT（比如电驴有 ed2k），所以 BT 使用了这个参数，而不是 <code>xt</code>。</li><li><strong>so</strong>：定义在 <a href="http://www.bittorrent.org/beps/bep_0053.html">BEP53 - Magnet URI extension - Select specific file indices for download</a> 中，用于指定下载特定文件，比如 <code>so=0,2,4,6-8</code> 表示下载 files 列表中索引为 0,2,4,6,7,8 的这六个文件。</li></ul><p>有了磁力链接，客户端就可以向 Peer 请求 Torrent 文件的 info 部分了，获取完成后就相当于拥有了 Torrent 文件，也就是有了完整的元数据，继而可以下载资源。</p><h2 id="参考资料">参考资料</h2><ol><li><a href="https://en.wikipedia.org/wiki/Torrent_file#Draft_extensions">Wikipedia - Torrent file</a></li><li><a href="http://marquisdegeek.com/code_bencode.php">Online Torrent File Decoder</a></li><li><a href="http://magnet2torrent.me/">Online Magnet Link to Torrent File converter</a></li><li><a href="https://en.wikipedia.org/wiki/Magnet_URI_scheme">Wikipedia - Magnet URI scheme</a></li><li><a href="https://stackoverflow.com/questions/4913343/what-is-the-difference-between-uri-url-and-urn">Stack Overflow - What is the difference between URI, URL and URN?</a></li></ol>]]></content:encoded>
      
      
      
      <category domain="https://velih.de/tags/BT/">BT</category>
      
      
      <comments>https://velih.de/2018/08/26/bt-metadata/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>BT 增强建议之概述</title>
      <link>https://velih.de/2018/08/26/bt-overview/</link>
      <guid>https://velih.de/2018/08/26/bt-overview/</guid>
      <pubDate>Sun, 26 Aug 2018 09:00:00 GMT</pubDate>
      
        
        
          
          
      <description></description>
          
        
      
      
      
      <content:encoded><![CDATA[<p>在版权意识愈渐加强的今天，BT 流量占全球流量的比重不断下降，这种 P2P 技术的应用在<a href="http://www.donews.com/article/detail/4805/11133.html">逐渐衰落</a>，但是</p><ul><li>“技术无罪”——纵然据说爱因斯坦也曾对“把原子弹送到了疯子手里”感到后悔。</li><li>“个体重复系统发育”：<blockquote><p>技术的变化会导致某些思想过时并迅速消失，这种情形经常发生。但是，技术的另一种变化还可能使某些思想再次复活。</p><footer><strong>Andrew Tanenbaum</strong><cite>现代操作系统</cite></footer></blockquote></li></ul><h2 id="总目录">总目录</h2><p>下面进入正题。一个使用 BT 进行下载的过程可以简短地描述如下：</p><p>当你获取了一个<strong>磁力链接</strong>或者<strong>种子文件</strong>，使用 BT 客户端打开文件确认下载后，客户端就成为了一个 Peer，客户端通过连接 <strong>Tracker</strong> 服务器或者 <strong>DHT</strong> 网络寻找到其他拥有所需要文件分片的 Peer，从这些 Peer 中下载资源分片，同时客户端也上传数据给其他来索要自己所拥有分片的 Peer，以此反复，直到下载完成。</p><p>搞清楚这个下载过程中到底发生了什么事情就是记录这个系列文章的目的所在。整个学习过程以 BT 增强建议 <a href="http://www.bittorrent.org/beps/bep_0000.html">BEP</a> 为主要参考，同时适当参考 <a href="https://github.com/atomashpolskiy/bt">BT 的一个 Java 版本实现源码</a>。</p><p>整个系列分为：</p><ul><li><a href="/2018/08/26/bt-overview/" title="BT 增强建议之概述">BT 增强建议之概述</a>：主要介绍 BEP 与 Bencode 编码</li><li><a href="/2018/08/26/bt-metadata/" title="BT 增强建议之 Metadata：Torrent 与 Magnet">BT 增强建议之 Metadata：Torrent 与 Magnet</a>：Torrent 种子文件结构与 Magnet 磁力链接的原理</li><li><a href="/2018/08/27/bt-tracker/" title="BT 增强建议之 Tracker">BT 增强建议之 Tracker</a>：作为 Peer 间桥梁的 Tracker 服务器的工作原理</li><li><a href="/2018/08/30/bt-peer/" title="BT 增强建议之 Peer">BT 增强建议之 Peer</a>： Peer 间的通信的过程以及以牙还牙策略</li><li>DHT：使得 BT 网络脱离 Tracker，实现完全去中心化<ul><li><a href="/2018/11/08/dht-kademlia/" title="DHT 网络之 Kademlia 算法">DHT 网络之 Kademlia 算法</a></li><li><a href="/2018/11/12/bt-dht/" title="BT 增强建议之 DHT">BT 增强建议之 DHT</a></li></ul></li><li><a href="/2018/11/15/bt-advanced/" title="BT 增强建议之进阶改进方案">BT 增强建议之进阶改进方案</a>：BEP 中提出的一些进阶改进方案</li></ul><p>用于保证 BT 高速下载时其他应用低时延网络通信的传输层协议 <strong>µTP</strong> 已在独立的博文 <a href="/2018/08/04/%C2%B5tp/" title="µTP 协议 —— 对 BEP29 的简要理解">µTP 协议 —— 对 BEP29 的简要理解</a> 中介绍。</p><p>这个系列将尽可能涵盖所有的 BEP。下面的表格显示了章节与 BEP 的引用关系，因此在每篇文章的参考资料中将不在列举相关 BEP。</p><h2 id="BEP">BEP</h2><p>BEP（BitTorrent Enhancement Proposal）是 BitTorrent 社区用于改进 BitTorrent 的技术文档，可以视为一种开发方式。一个<a href="http://www.bittorrent.org/beps/bep_0002.html">规范</a>的 BEP 被提出后可能经历如下的几个过程，但是目前只有 Final，Accepted，Draft，Deferred 四种状态的 BEP。<br><img src="bep_possible_paths.png" alt="BEP 可能经历的过程"><br>同时 Bittorrent 和 Python 还有个相似的共同点，他们的最初设计者都<strong>曾经</strong>是自己项目的终身仁慈独裁者（Benevolent Dictator For Life，<a href="https://en.wikipedia.org/wiki/Benevolent_dictator_for_life">BDFL</a>）。例如 <a href="http://www.bittorrent.org/beps/bep_1000.html">BEP1000 - Pending Standards Track Documents</a> 中提到的 BEP13 - Protocol Encryption 一直没能提交就和 BitTorrent 的作者 Bram Cohen 反对 BT 流量加密相关。</p><ul><li>2018年7月，Guido van Rossum 宣布不再担任 Python 社区的 BDFL。</li><li>2018年8月，在自己一手创办的公司被波场收购后，Bram Cohen 表示自己已经离开了 Bittorrent，<a href="https://chia.net/">目前在做数字货币相关的工作</a>。</li></ul><h2 id="Bencode">Bencode</h2><p>bencode 是 BT 协议在传输数据过程中广泛采用的一种编码格式。主要支持以下四种数据类型的编码：</p><ul><li><strong>String</strong>：十进制字符串占用字节数 + ‘:’ + 字符串。例如 “spam”会被编码成“4:spam”</li><li><strong>Integer</strong>：‘i’ + 十进制整形数字 + ‘e’。除 0 之外，不能以 0 开头。例如：i3e、i-3e</li><li><strong>List</strong>：使用字符 ‘l’ 和 ‘e’ 进行界定，中间是其他元素。例如 <em>l4:spami:-42ee</em> 代表列表 <em>[spam, -42]</em></li><li><strong>Dictionary</strong>：使用字符 ‘d’ 和 ‘e’ 进行界定，中间是每个键值对元素,而且所有键为字符串类型并按字典顺序排列。例如 <em>d3:cow3:moo4:spam4:eggse</em> 代表字典 <em>{cow: moo, spam: eggs}</em></li></ul><h2 id="参考资料">参考资料</h2><ol><li><a href="https://github.com/bittorrent/bittorrent.org">BEP - Github</a></li><li><a href="https://en.wikipedia.org/wiki/BitTorrent_protocol_encryption">Wikipedia - BitTorrent protocol encryption</a></li><li><a href="http://cdmd.cnki.com.cn/Article/CDMD-10614-2010234919.htm">BT流量识别技术的研究</a></li><li><a href="http://pcedu.pconline.com.cn/960/9603584_all.html">谈eD2k和电驴的兴衰</a></li><li><a href="https://tech.slashdot.org/story/18/08/20/0457247/bittorrent-founder-bram-cohen-has-left-the-company">Slashdot - BitTorrent Founder Bram Cohen Has Left the Company</a></li></ol>]]></content:encoded>
      
      
      
      <category domain="https://velih.de/tags/BT/">BT</category>
      
      
      <comments>https://velih.de/2018/08/26/bt-overview/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>µTP 协议 —— 对 BEP29 的简要理解</title>
      <link>https://velih.de/2018/08/04/%C2%B5tp/</link>
      <guid>https://velih.de/2018/08/04/%C2%B5tp/</guid>
      <pubDate>Sat, 04 Aug 2018 09:05:00 GMT</pubDate>
      
        
        
          
          
      <description></description>
          
        
      
      
      
      <content:encoded><![CDATA[<p>在 <a href="/2018/07/20/tcp/" title="TCP 温故知新">TCP 温故知新</a>中回顾了 TCP，而这篇文章主要讲用于 BT 网络的基于 UDP 的运输层协议 µTP，同时顺便回顾 UDP。下面的内容更多是基于对 <a href="http://www.bittorrent.org/beps/bep_0029.html">BEP29</a> 的理解。</p><h2 id="名字探究">名字探究</h2><p>µTP 的主要文档 BEP29 的创建于 2009 年，姑且认为这也是设计完成的大致时间，µTP 在 uTorrent 的 1.8 中首次加入（2009 年）这个事实也佐证了这点。它的设计者包括：</p><ul><li><a href="https://en.wikipedia.org/wiki/Ludvig_Strigeus">Ludvig Strigeus</a>（μTorrent 作者，BitTorrent 公司 2006 年收购 μTorrent，目前在 Spotify 工作）</li><li>Greg Hazel</li><li><a href="https://www.linkedin.com/in/shalunov">Stanislav Shalunov</a>（µTP 中的拥塞算法 <a href="https://tools.ietf.org/html/rfc6817">LEDBAT</a> 主要作者，后来还创造了可以脱离现有蜂窝网络使用的 IM 应用 <a href="https://www.opengarden.com/firechat.html">FireChat</a> —— 它被多次用到”占中”这样的公民运动中）</li><li>Arvid Norberg（libtorrent 开发者，目前在 <a href="https://blockstream.com/">Blockstream</a> 工作）</li><li>Bram Cohen（BitTorrent 作者）</li></ul><h2 id="设计原因">设计原因</h2><p>在过去多年前，如果使用 BT 进行下载热门资源的话可以感受到到速度飞快，但是同时带来的问题就是如果想要同时看在线视频就会带来卡顿。问题在于 DSL 和 modem 的往往有一个和它们的发送速率不成比例的发送缓冲区，不成比例到可以容纳几秒钟的数据量。而 BT 往往会与许多 peer 建立 TCP 连接，在 TCP 将带宽均匀地分配到每个连接的前提下，BT 就占用了较多的带宽，但是其他诸如浏览网页、即时通讯这些场景的优先级实际上应该要比 BT 传输更高些，但是因为 BT 和 物理层的这种特性导致了其他服务有延迟，影响了使用 BT 时其他服务的体验。<br>  µTP 通过将 modem 的缓冲队列的大小作为一个控制因子来调整发送速率，当队列过大时，将会放慢发送速度。这种策略使得 BT 在没有竞争的情况下可以充分利用上传带宽，在有大量其他流量的情况下则放慢发送速率。<br>  上述时 Bittorrent 文档中的说法，但是实际上 µTP 是基于包的延时的，而不是基于队列大小的。而且 µTP 具体对拥塞算法 LEDBAT 的实现有与在 IETF 互联网草案 <a href="https://tools.ietf.org/html/rfc6817">RFC 6817</a> 中的描述有所区别（这里的实现指 C++ 版本的 <a href="https://github.com/bittorrent/libutp">libutp</a>，各个版本的实现不完全一致）。</p><h2 id="UDP-和-µTP-首部">UDP 和 µTP 首部</h2><p>为了方便与 TCP 做简单的对比，把 UDP 的首部（前四个字节）与 µTP 的首部（剩余部分）放在了一个图中示意。从 UDP 首部字段数量皆可以发现 UDP 协议相对 TCP 协议是如此简单，以至于我们w可以将 TCP 协议看成是类似 µTP 协议一样的基于 UDP 协议的运输层协议。<br><img src="udp_utp_header.png" alt="UDP Header And µTP Header"></p><h3 id="UDP-首部">UDP 首部</h3><ul><li><strong>源 / 目端口（Source / Destination port）</strong>：用于确认通信进程双方。源端口是可选的，如果设置了源端口，则接收方将其视为回复端口。如果不需要回复就不需要设置；</li><li><strong>总长度（Length）</strong>：定义了 UDP 用户数据报的总长度，包括首部和数据。TCP 首部中是没有所谓“报文段总长度”的字段的，长度可以通过 IP 层的长度减去 IP 首部长度计算所得，所以一定程度上时冗余的，可以参考 Stack OverFlow 上的<a href="https://stackoverflow.com/a/16748680/5091903">相关讨论</a>；</li><li><strong>校验和（Checksum）</strong>：用于对整个用户数据报的校验，通过 IP 位首部与和用户数据报计算得到；</li></ul><p>可见 UDP 首部的这些字段在理论上可以是 TCP 首部字段的子集。因此我们可以粗略地讲 <strong>TCP 是基于 UDP 的传输层协议。</strong><br>UDP 服务是一个“尽力而为”的服务，它<strong>没有流量控制</strong>，<strong>只能通过校验和进行差错控制，丢包不会知晓，也不会重传</strong>，也<strong>没有拥塞控制</strong>。</p><h3 id="µTP-首部">µTP 首部</h3><ul><li><strong>version</strong>：版本号，现在为 1，<a href="https://github.com/boundary/wireshark/blob/master/epan/dissectors/packet-bt-utp.c">还有一个原始版本号 0 存在</a></li><li><strong>connection_id</strong>：用于标记连接。<a href="http://www.calvinneo.com/2017/12/05/libutp%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/#utp-context%E7%9A%84%E6%88%90%E5%91%98">这个字段是必须的么?</a>；</li><li><strong>timestamp_microseconds</strong>：发送数据包的时间，和计算延迟时间，rtt 相关；</li><li><strong>timestamp_difference_microseconds</strong>：当前时间和上一次收到的包中的 timestamp_microseconds 之差；</li><li><strong>wnd_size</strong>：表示另一端建议的窗口大小，相当于 TCP 中的接收窗口；</li><li><strong>extension</strong>：代表第一个扩展的类型，0 表示没有扩展，1 表示 Selective ACKs（选择确认扩展）。</li><li><strong>type</strong>：数据包的类型。可以有：<ul><li>ST_DATA  = 0：承载有效数据的数据包；</li><li>ST_FIN   = 1：终止连接。是通信单方发送的最后一个包，类似于 TCP 的 FIN 标记。但是发送 ST_FIN 的一方还是会等待可能丢失或者失序到达的包，即使收到了对方的 ST_FIN 包；</li><li>ST_STATE = 2：用于报告状态，传输一个没有数据的 ACK。和 TCP 中未携带数据的 ACK 包一样，它不消耗序号；</li><li>ST_RESET = 3：强制重置连接。类似 TCP 的 RST 标记。</li><li>ST_SYN   = 4：发起连接。类似 TCP 的 SYN 标记。发起方会随机一个 connection_id ID 用于给接收方后续的回复使用。然后发起方之后的包中传输的 connection_id 为 ID + 1；</li></ul></li><li><strong>seq_nr</strong>：表示这个数据包的序号。注意和 TCP 中代表字号号的序号有所不同。初始序号同样也是随机生成。</li><li><strong>ack_nr</strong>：表示最后收到的数据包的seq_nr；</li></ul><h2 id="连接过程">连接过程</h2><p>图示为一次在 qBittorrent 中对一个种子开始 BT 下载二十秒左右后停止下载时，与其中一个 peer 的交互过程。<br><img src="wireshark.png" alt="连接过程（以 connection_id 为 8671 和 8672 的这一个过程为例）"></p><h2 id="丢包">丢包</h2><p>和丢包处理有一个和窗口相关的变量需要先进行说明：</p><ul><li><em><strong>max_window</strong></em>：定义了未被确认的字节的上限，相当与 TCP 中的拥塞窗口；</li><li><em><strong>wnd_size</strong></em>：同首部中的 wnd_size，和 TCP 中相同，实际的发送窗口大小为 <code>min(max_windows, wnd_size)</code>；</li><li><em><strong>cur_window</strong></em>：表示当前未被确认的字节的数量；</li></ul><p>当需要发送数据包时，仅当 <code>cur_window + packet_size &lt;= min(max_windows, wnd_size)</code> 成立，这个数据包才能被发送。</p><ul><li>当序号为 <code>seq_nr - cur_window</code> 的数据包（发送队列中年龄最大的未被确认的数据包，下一个理论上需要被确认的就是它）没有被确认，但是已经有至少三个序号大于它的数据包通过 Selective ACK 被确认，那么这个数据包被认为是丢失了。</li><li>如果 <code>ack_nr + 1</code> 这个包已经发送了，而收到三个重复的 <code>ack_nr</code> 的 ACK，那么 <code>ack_nr + 1</code>这个包被认为是丢失了。</li></ul><p>如果检测到丢包，那么拥塞窗口 <strong>max_window</strong> 大小减半。</p><h2 id="超时">超时</h2><p>µTP 的超时计时和 TCP 中 RTO 计时器不太一样，RTO 计时器主要用于对 ACK 的计时，但是　µTP 的计时器则是指接收任何数据包超时时间，如果超时时间内没有任何数据包到达则超时，如果超时，则 <strong>packet_size</strong> 和 <strong>max_window</strong> 将都会被设置为最小数据包大小（150 字节）。 <strong>（疑问？：packet_size 的调整策略是什么）</strong></p><h3 id="超时时间的计算">超时时间的计算</h3><p>每当收到一个数据包的 ACK，就会更新往返时间（不考虑重传的包），往返时间用于计算超时时间。先说明下相关的变量：</p><ul><li><em><strong>rtt</strong></em>：往返时间；</li><li><em><strong>rtt_var</strong></em>：往返时间差异；</li><li><em><strong>packet_rtt</strong></em>：当前收到 ACK 对应的包的往返时间，即当前时间减去这个包发送时的时间，即首部中的 timestamp 字段记录的值。</li><li><em><strong>timeout</strong></em>：超时时间；</li></ul><p>通过以下公式更新 rtt：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">delta = rtt - packet_rtt</span><br><span class="line">rtt_var += (abs(delta) - rtt_var) / 4;</span><br><span class="line">rtt += (packet_rtt - rtt) / 8;</span><br></pre></td></tr></table></figure><p>正常情况下通过 rtt 计算得到 timeout（第一次由于没有 rtt，timeout 使用初始值 1000 ms，）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">timeout = max(rtt + rtt_var * 4, 500);</span><br></pre></td></tr></table></figure><p>如果遇到超时，则 timeout 翻倍。</p><h2 id="拥塞控制">拥塞控制</h2><p>在<strong>丢包</strong>和<strong>超时</strong>部分已经涉及到拥塞窗口的调整了。µTP 的拥塞控制可以理解为一种基于延迟的负反馈拥塞控制，通过延迟的变化控制窗口大小的变化，达到拥塞控制目的。计算窗口大小过程中的相关常量和变量的定义如下：</p><ul><li><em><strong>CONTROL_TARGET</strong></em>：µTP 所能接收的上行缓冲延迟，现在是 100 ms；</li><li><em><strong>base_delay</strong></em>：两分钟内的收到的数据包的最低延迟；</li><li><em><strong>our_delay</strong></em>：当前的数据包延迟；</li><li><em><strong>off_target</strong></em>：实际延迟和目标延迟的差距。即<code>CONTROL_TARGET - our_delay</code>；</li><li><em><strong>outstanding_packet</strong></em>：已经被发送但是未被确认的数据包；</li></ul><p>具体计算过程如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">delay_factor = off_target / CCONTROL_TARGET;</span><br><span class="line">window_factor = outstanding_packet / max_window;</span><br><span class="line">scaled_gain = MAX_CWND_INCREASE_PACKETS_PER_RTT * delay_factor * window_factor;</span><br><span class="line"></span><br><span class="line">max_window += scaled_gain;</span><br></pre></td></tr></table></figure><p>当 <code>off_target &gt; 0</code> 时，当前包的延迟时间比设定的还小一些，那么窗口会缩小，发送速率就会放慢；反之，窗口增加，速率加快。</p><h2 id="参考资料">参考资料</h2><ol><li><a href="http://www.bittorrent.org/beps/bep_0029.html">BitTorrent Enhancement Proposal 29 - µTorrent transport protocol</a></li><li><a href="https://tools.ietf.org/html/rfc6817">RFC 6817 - Low Extra Delay Background Transport (LEDBAT)</a></li><li><a href="http://www.calvinneo.com/2017/12/05/libutp%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/">Calvin’s Marbles - libutp源码简析</a></li></ol>]]></content:encoded>
      
      
      
      <category domain="https://velih.de/tags/BT/">BT</category>
      
      <category domain="https://velih.de/tags/Network/">Network</category>
      
      
      <comments>https://velih.de/2018/08/04/%C2%B5tp/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>TCP 温故知新</title>
      <link>https://velih.de/2018/07/20/tcp/</link>
      <guid>https://velih.de/2018/07/20/tcp/</guid>
      <pubDate>Thu, 19 Jul 2018 16:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;生产环境遇到些网络问题，知对 TCP 协议还是有些生疏，在此复习记录。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>生产环境遇到些网络问题，知对 TCP 协议还是有些生疏，在此复习记录。</p><span id="more"></span><h2 id="协议">协议</h2><h3 id="报文段格式">报文段格式</h3><p>TCP 协议报文段主要由<strong>首部（Header）</strong> 与<strong>数据（Data）</strong> 两部分组成。在计算校验和是还会加上虚拟的伪首部。此处主要说明首部的组成。<br><img src="tcp_header.png" alt="图 1 TCP Header (From: WikiPedia)"><br>TCP 在网络模型中属于运输层，用于提供进程与进程间的字节流通信服务，因此需要<strong>源 / 目端口（Source / Destination port）</strong> 以确定通信双方进程。使用<strong>序号（Sequence number，seq）</strong> 表明本报文段第一个数据字节的编号，初始序号由双方在 TCP 连接建立时随机生成。使用<strong>确认号（Acknowledgment number，ack）</strong> 表示接受方期望从发送方接受的字节编号。<strong>数据偏移量（Data Offset）</strong> 顾名思义报文段数据开始字节处的偏移量，即 TCP header 的长度，由于选项的存在，首部长度的范围是 20～60 Bytes，但是该字段只有 4 Bits，因此该字段指出首部长度有多少个 4 Bytes。接下来的 3 Bits 被<strong>保留（Reserved）</strong> 。随后会讨论 9 个<strong>标志位（Flags）</strong>。<strong>窗口大小（Window Size）</strong> 定义了接受方的接受窗口大小，由接受方决定，然后告知发送方。在计算<strong>校验和（Checksum）</strong> 时需要加上伪首部，伪首部的内容包括源目 IP 地址，TCP 报文段长度等。如果 URG 标志位被设定了，那<strong>紧急指针（Urgent pointer）</strong> 用于指示紧急数据最后一个字节在报文段数据部分中的偏移量。最后的 40 Bytes 留给<strong>选项（Options）</strong>。</p><h3 id="Flags">Flags</h3><ul><li><strong>URG</strong>：为 1 表示数据中有紧急数据。这个标记比较少见，可以找到的一些应用有：<a href="https://stackoverflow.com/questions/24476458/understanding-tcp-urg-flag">FTP</a>，<a href="http://packetlife.net/blog/2011/mar/2/tcp-flags-psh-and-urg/">Telnet</a>；</li><li><strong>ACK</strong>：为 1 表示确认号字段有效；</li><li><strong>PSH</strong>：为 1 表示有推送数据，这个字段主要完成<a href="http://packetlife.net/blog/2011/mar/2/tcp-flags-psh-and-urg/">两个功能</a>：发送方应用层提醒 TCP 需要立即发送数据；接受方 TCP 需要将收到的数据立即提交给应用层；</li><li><strong>RST</strong>：为 1 表示出现严重差错。可能需要重现创建 TCP 连接。还可以用于拒绝非法的报文段和拒绝连接请求；</li><li><strong>SYN</strong>：为 1 表示这是连接请求或是连接接受请求，用于创建连接和使顺序号同步；</li><li><strong>FIN</strong>：为 1 表示发送方没有数据要传输了，要求释放连接；</li></ul><h2 id="阶段">阶段</h2><p>TCP 连接可以分为三个阶段：建立连接，传输数据，终止连接。可以用一个有限状态机表示：<br><img src="tcp_connection.png" alt="图 2 TCP 连接 (From: Computer Networks)图中（A/B）这样的文字表示“收到A后执行B，A与B可以是标志位或者指令”深实线表示 Client 的行为，深虚线表示 Server 的行为，浅色线表示特殊行为"><br>下面结合一个用 Rust 写的 Echo Server 与抓包工具 Wireshark 来演示这三个过程。代码如下：</p><figure class="highlight rust"><figcaption><span>Echo Server</span><a href="/downloads/code/echo_server.rs">view raw</a></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> std::net::{TcpListener, TcpStream};</span><br><span class="line"><span class="keyword">use</span> std::thread;</span><br><span class="line"><span class="keyword">use</span> std::io::Read;</span><br><span class="line"><span class="keyword">use</span> std::io::Write;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">main</span>() {</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">listener</span> = TcpListener::<span class="title function_ invoke__">bind</span>(<span class="string">&quot;::1:9999&quot;</span>).<span class="title function_ invoke__">unwrap</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> <span class="variable">stream</span> <span class="keyword">in</span> listener.<span class="title function_ invoke__">incoming</span>() {</span><br><span class="line">        <span class="keyword">match</span> stream {</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>(stream) =&gt; {</span><br><span class="line">                thread::<span class="title function_ invoke__">spawn</span>(|| {</span><br><span class="line">                    <span class="title function_ invoke__">handle_client</span>(stream);</span><br><span class="line">                });</span><br><span class="line">            }</span><br><span class="line">            <span class="title function_ invoke__">Err</span>(_) =&gt; {</span><br><span class="line">                <span class="built_in">println!</span>(<span class="string">&quot;Error&quot;</span>);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">handle_client</span>(<span class="keyword">mut</span> stream: TcpStream) {</span><br><span class="line">    <span class="keyword">loop</span> {</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">read</span> = [<span class="number">0</span>; <span class="number">1024</span>];</span><br><span class="line">        <span class="keyword">match</span> stream.<span class="title function_ invoke__">read</span>(&amp;<span class="keyword">mut</span> read) {</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>(n) =&gt; {</span><br><span class="line">                <span class="keyword">if</span> n == <span class="number">0</span> {</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                }</span><br><span class="line">                stream.<span class="title function_ invoke__">write</span>(&amp;read[<span class="number">0</span>..n]).<span class="title function_ invoke__">unwrap</span>();</span><br><span class="line">            }</span><br><span class="line">            <span class="title function_ invoke__">Err</span>(err) =&gt; {</span><br><span class="line">                <span class="built_in">panic!</span>(err);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure><p>Echo Server 启动之后使用 telnet 工具连接至服务器，与服务器交互两次，即回显两次字符串，然后从退出 telnet。抓到的包截图如下：<br><img src="wireshark.png" alt="图 3 Wireshark 抓包"></p><p>在下面的表述中，客户端表示在这一阶段先发起请求的一方，服务端表示在这一阶段先接受请求的一方。在 TCP 中，服务端和客户端之间可以进行双向通信，他们可以理解为对等的，在连接建立后，实际上没有服务端和客户端的区别。</p><h3 id="建立连接">建立连接</h3><p>前三个包代表了建立连接的过程，分为三步，大多数情况下就如同抓包所示，称为<strong>三次握手（3-way handshake）</strong>。图 2 中还画出了双方同时打开连接与连接复位这两种比较少见的情景。</p><ol><li>客户端发送给服务端一个 <strong>SYN</strong> 报文，用以告知服务端初始序号为 0（此处的 Seq 经过 Wireshark 的处理，变成了相对值），然后客户端进入 <em><strong>SYN_SENT</strong></em> 状态。</li><li>服务器收到 1 中报文后，发给客户端一个 <strong>SYN + ACK</strong> 报文，告知客户端初始序号为 0，且接下来期望从客户端收到的序号 Ack 为 1。服务端进入 <em><strong>SYN_RCVD</strong></em> 状态。可见 <strong>SYN 报文消耗了一个序号</strong>。</li><li>客户端给服务端回复 <strong>ACK</strong> 报文，进入 <em><strong>ESTABLISHED</strong></em> 状态，服务端在收到这个报文连接建立完成。可见 <strong>ACK 报文在不携带数据的情况下不消耗序号</strong>。</li></ol><h3 id="传输数据">传输数据</h3><p>图 3 中 P17～P20 与 P72～P74 分别展示了两次交互过程。以第二次交互为例：</p><ol><li>P72 中，客户端将想要回显字符串发送给服务端，告知服务器这个报文段的数据首字节序号为 8，并且希望从服务端收到的下一个序号是 8。</li><li>服务端将回显的字符串与对 P72 的确认一起发送给客户端。P72 的长度为 9，因此报文段中数据的序号范围为 [8,17)，因此在 P73 中 Ack 为 17。</li><li>客户端确认 P73。</li></ol><p>需要注意的是，这两次交互有所区别：第一次交互时，服务端先返回了一个确认给客户端，然后再额外发送一条携带回显内容的报文段。但是第二次交互时省略了单独的确认。</p><h3 id="终止连接">终止连接</h3><p>根据“广大博主”写作的文章与<a href="https://www.zhihu.com/question/50646354">问答网站的讨论</a>以及各种面经，基本一致认为，终止连接通常被成为<strong>四次挥手（4-way termination）</strong>，即通信双方会有四次交互，但是如图 2 所示，也存在<strong>三次挥手</strong>的可能性，且我本地的多次抓包也如图 3 一致——均为三次挥手，且无一例外。下面对四次挥手进行分析，三次挥手可以被其概括：</p><ol><li>客户端发起终止连接，发出一个 <strong>FIN</strong> 报文给服务端，假设该报文的 Seq 为 X，Ack 为 Y。然后客户端进入 <em><strong>FIN_WAIT1</strong></em> 状态，除重传 FIN 报文与发送 ACK 确认之外，不再发送应用数据给服务端。</li><li>服务端收到 FIN 报文段后先回复一个 <strong>ACK</strong> 报文，进入 <em><strong>CLOSE_WAIT</strong></em> 状态，该报文的 Seq 为 Y，Ack 为 X+1。</li><li>客户端在收到 FIN 的 ACK 之后进入 <em><strong>FIN_WAIT2</strong></em> 状态。此时服务端还可以继续将未发送完的应用数据发送给客户端。</li><li>服务端发送完数据后发送一条 <strong>FIN</strong> 报文，进入 <em><strong>LAST_ACK</strong></em> 状态，该报文的 Seq 为 Y+K，Ack 为 X+1。</li><li>客户端收到服务端的 FIN 后，发送最后的 <strong>ACK</strong> 报文给服务器，然后进入 <em><strong>TIME_WAIT</strong></em> 状态。如果在 2MSL（最大报文段寿命，通常为30～60s）后客户端没再次收到 FIN 报文，则进入 <em><strong>CLOSED</strong></em> 状态，否则重发 ACK 报文进行重试。</li><li>服务端在收到 ACK 报文后进入 <em><strong>CLOSED</strong></em> 状态。</li></ol><p>三次挥手表现为步骤 2～4 合并为一步，即同时发送对客户端 FIN 的 ACK 报文与 服务端自己的 FIN 报文。这条 <strong>FIN+ACK</strong> 报文的 Seq 为 Y，Ack 为 X+1。</p><p>至于在什么情景下出现三次握手或者四次握手，大多数的观点认为先收到 FIN 报文的一方还需要向上层应用询问是否仍然有数据需要发送，因为要等待上层的回复，所以“为何不早点把对 FIN 的 ACK 发出去呢？！”而且立即 Ack 能防止对方重传 FIN。但是有没有存在不需要询问上层或者不需要立即回复 Ack 的可能，就如同传输数据出现的情况一样，这些应该与 TCP 的具体实现相关，目前能力与精力有限，还有待对 <a href="https://github.com/torvalds/linux/blob/master/net/ipv4/tcp_output.c">Linux TCP 实现源码</a>进行阅读。</p><h2 id="滑动窗口">滑动窗口</h2><p>滑动窗口是 TCP 中用于实现诸如 ACK 确认、流量控制、拥塞控制的承载结构。如图所示:<br><img src="sliding_window.png" alt="图 4 滑动窗口"><br>先将 TCP 看作是简单的单向通信，则发送方有一个发送窗口，接收方有一个接收窗口。正如图中所示，传输的是报文段，窗口大小的单位是字节。两个窗口中<strong>白色区域</strong>为空白位置，等待被应用层或者网络层填满；<strong>灰色区域</strong>是已经发送但是还没有接受到确认的字节；<strong>粉色区域</strong>在发送窗口中表示等待被发送的字节，在接收窗口汇总表示等待交付的字节。<br>发送窗口的大小为接受方通过首部中窗口大小字段告知的接收窗口大小 rwnd 和之后会讲到的拥塞窗口的大小 cwnd 两者中的较小值，即 <code>min(rwnd , cwnd)</code>。接收窗口大小是接收方可用缓存空间大小，为 <code>rwnd = 缓存大小 - 准备交付的字节数</code>。</p><h2 id="流量控制">流量控制</h2><p>流量控制用于平衡生产者产生数据与消费者消耗数据的速度。TCP 中的流量控制实现的主要途径是不断调整发送窗口的大小实现。发送 TCP 一旦发现发送发送窗口满了就会对发送进程进行反馈。接受方根据之前从发送方收到的数据量和服务器已经消耗的数据量得到自身接收窗口的大小，将这个值告知发送方，发送方根据收到的窗口大小调整自身窗口大小。<br>还有正对通信双方产生数据小或者消费数据慢产生糊涂窗口综合征时，有其他方面的流量控制。当发送方数据量相对于首部小很多的报文很多时，可以使用 <strong>Nagle 算法</strong>减少这种小报文量。当接受方消耗数据很慢时，每次告知发送方的窗口大小会比较小，也可能产生很多小报文，此时可以使用 <strong>Clark 解决方法</strong>或者进行<strong>推迟确认</strong>。关于这几种方案的分析及具体的使用情景可以参考 dog520 大神的这篇文章——<a href="https://blog.csdn.net/dog250/article/details/21303679">再次谈谈 TCP 的 Nagle 算法与 TCP_CORK 选项</a>。</p><h2 id="差错控制">差错控制</h2><p>差错控制用于描述 TCP 在发送或者接受到报文段发生异常时的行为，其主要表现在如下几个方面：</p><ol><li><strong>校验和</strong>：在接受方，如果收到的报文段未通过校验和校验，则立即丢弃，反之，则通过<strong>确认规则</strong>（下面马上提及）进行确认；</li><li><strong>重传</strong>：在发送方，如果一个报文段重传超时计时器（RTO）超时，即在 RTO 时间之后仍然未收到 ACK，则立即重传未被确认的最小的报文段；如果收到四个相同的的 ACK ，则立即重传下一个报文段；</li></ol><h3 id="确认规则">确认规则</h3><ol><li>当接受方向发送方发送数据报文段时，必须<strong>捎带</strong> ACK；</li><li>当接受方没有数据要发送时，但是收到一个<strong>按序到达</strong>的报文，同时前一个报文段也已经确认过了，那么接收方就推迟发送确认报文段，直到另一个报文段到达或者延迟一段时间以减少 ACK 报文量；</li><li>当所期望的报文段到达，且前一个<strong>按序到达</strong>的报文还未被确认，则立即 ACK（ACK 的序号仍然是下一个正常期望的序号，下同）；</li><li>当序号比期望的大的报文段（<strong>失序</strong>报文段）到达，则立即 ACK，且存储该报文段；</li><li>当<strong>丢失</strong>的报文段到达时，则立即 ACK；</li><li>当<strong>重复</strong>的报文段到达时，则丢弃，且立即 ACK；</li></ol><h2 id="拥塞控制">拥塞控制</h2><p>拥塞控制是为了避免因为网络受限导致网络不能按照发送方产生的数据的速度将报文段交付给接受方。与流量控制考察的对象是通信双方不同，拥塞控制的考察对象是通信双方间的网络。拥塞控制的方式表现在发送方的拥塞窗口的变化，从而控制发送方的数据发送快慢。TCP 最初使用的拥塞策略称为 <strong>TCP Tahoe and Reno</strong>。</p><h3 id="Tahoe-and-Reno">Tahoe and Reno</h3><p>这个拥塞策略主要分为慢启动、拥塞避免、拥塞检测三个阶段。</p><h4 id="慢启动">慢启动</h4><p>假设接收窗口大小远大于拥塞窗口，且不考虑延迟确认。拥塞窗口大小从一个最大报文长度 MSS （连接建立时通过 TCP 选项告知）开始，之后每当有一个报文段被确认，拥塞窗口就增大一个 MSS。在这样的策略下，慢启动阶段的拥塞窗口大小呈指数增长。即从 <code>1 -&gt; 2 -&gt; 4 -&gt; 8</code>。当到达慢启动门限时，就进入拥塞避免阶段。</p><h4 id="拥塞避免">拥塞避免</h4><p>拥塞避免阶段拥塞窗口大小继续增加，但是速度放慢，改成当整个窗口大小的报文段都被确认后，窗口大小才增加一个 MSS。表现为 <code>8 -&gt; 9 -&gt; 10 -&gt; 11</code>，呈现线性增长。</p><h4 id="拥塞检测">拥塞检测</h4><p>如果拥塞发生了，因为发生在网络中路由器出现丢包现象，在接受方处的表现为出现以下两种情况，并做出对应的反应：</p><ol><li><p>RTO 计时器超时。这说明网络拥塞的可能性较大，TCP 做出较强烈的反应：<br>a. 把慢启动门限值调整为当前窗口大小的一半；<br>b. 把 cwnd 重新设置为 1 MSS；<br>c. 重新进入慢启动阶段；</p></li><li><p>收到四个相同的 ACK；说明出现拥塞的可能性较小，但是出现了丢包，TCP 做出较弱的反应，Reno 算法表现为快恢复（Fast recovery）：<br>a. 把慢启动门限值调整为当前窗口大小的一半；<br>b. 把 cwnd 重新设置为慢启动门限值；<br>c. 重新进入拥塞避免阶段；</p></li></ol><p>图示如下：<br><img src="congestion_control_example.png" alt="拥塞控制示例"><br>Tahoe 算法与 Reno （Tahoe 的改进版本）的区别在于收到四个相同 ACK 时，Tahoe 算法的策略和 RTO 计时器超时时一致。</p><h3 id="其他拥塞策略">其他拥塞策略</h3><p>拥塞控制策略只需要在发送方实现即可，不需要接受方的参与，因此可以仅在发送方部署一套算法。现在 TCP 网络上的算法也在不断<a href="https://en.wikipedia.org/wiki/TCP_congestion_control">改进</a>，涌现出诸如 <a href="http://www4.ncsu.edu/~rhee/export/bitcp/cubic-paper.pdf"><strong>TCP CUBIC</strong></a>、<a href="https://ai.google/research/pubs/pub45646"><strong>TCP BBR</strong></a> 这样的算法。</p><h2 id="TCP-中的计时器">TCP 中的计时器</h2><h3 id="重传计时器">重传计时器</h3><p>重传计时器的超时时间为 RTO，RTO 主要根据测量所得的报文段往返时间 RTTm计算而来，计算过程如下：</p><p>首先计算平滑 RTT，即RTTs：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RTTs = RTTm // 第一次测量</span><br><span class="line">RTTs = (1 - α)RTTs + αRTTm // 随后的测量</span><br></pre></td></tr></table></figure><p>然后计算 RTT 的偏差 RTTd：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RTTd = RTTm / 2 // 第一次测量</span><br><span class="line">RTTd = (1 - β)RTTd + β|RTTs - RTTm| // 随后的测量</span><br></pre></td></tr></table></figure><p>重传超时 RTO 的计算如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RTO = 6s // 原始值</span><br><span class="line">RTO = RTTs + 4RTTd // 第一次测量后</span><br></pre></td></tr></table></figure><p>任意时刻只有一个 RTT 在进行测量，当重传发生时会影响 RTT 的测量，根据 <strong>Karn 算法</strong>，TCP 忽略重传报文的 RTT，而对于重传的报文，RTO 值为原报文的两倍，如果发生第二次重传，则为四倍，以此类推。</p><h3 id="持续计时器">持续计时器</h3><p>当接受方发送窗口值为 0 的报文段之后，后来因为接收窗口增加需要通告接窗口为非 0，但是通告的 ACK 丢失，这会导致发送方一直等待非 0 窗口通告，导致死锁。持续计时器就是接受方在收到 0 窗口通告后启用，如果超时则发送探测报文，促使接受方重传 ACK。</p><h3 id="Keep-Alive-计时器">Keep-Alive 计时器</h3><p>Keep-Alive 计时器用于防止 TCP 连接长时间空闲，每当收到对方的报文段，这个计时器就复位。这个计时器的超时时间通常可以通过接口进行设定。</p><h3 id="Time-Wait-计时器">Time-Wait 计时器</h3><p>Time-Wait 计时器对最后的 FIN 进行确认时启动的超时计时器。如果在时常为 2MSL 的计时器超时前再次收到 FIN，则重传 ACK，否则连接彻底关闭。</p><h2 id="传输层的未来">传输层的<a href="https://blog.apnic.net/2017/12/12/internet-protocols-changing/">未来</a></h2><p><a href="https://www.chromium.org/quic">QIUC</a> 了解一下下？</p><h2 id="参考资料">参考资料</h2><ol><li><a href="https://book.douban.com/subject/5386194/">TCP/IP 协议族 第四版</a></li><li><a href="https://book.douban.com/subject/5344443/">Andrew S.Tanenbaum - Computer Networks 5th</a></li><li><a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol">WikiPedia - Transmission Control Protocol</a></li><li><a href="https://en.wikipedia.org/wiki/TCP_congestion_contro">WikiPedia - TCP congestion control</a></li><li><a href="http://packetlife.net/blog/2011/mar/2/tcp-flags-psh-and-urg/">TCP Flags: PSH and URG</a></li><li><a href="https://www.nada.kth.se/kurser/kth/2D1392/05/lectures/lecture_4.pdf">KTH - Internetworking Lecture 4</a></li><li><a href="https://blog.csdn.net/dog250/article/details/81256550">一个 TCP FIN_WAIT2 状态细节引发的感慨</a></li></ol>]]></content:encoded>
      
      
      
      <category domain="https://velih.de/tags/Network/">Network</category>
      
      
      <comments>https://velih.de/2018/07/20/tcp/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
