<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>闲云孤鹤</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://0ranga.com/"/>
  <updated>2020-07-18T07:11:02.020Z</updated>
  <id>https://0ranga.com/</id>
  
  <author>
    <name>VelihDzen</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>BT 增强建议之进阶改进方案</title>
    <link href="https://0ranga.com/2018/11/15/bt-advanced/"/>
    <id>https://0ranga.com/2018/11/15/bt-advanced/</id>
    <published>2018-11-15T11:45:00.000Z</published>
    <updated>2020-07-18T07:11:02.020Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>本文是 BT 系列文章中的一篇，主要介绍 BEP 中剩下的改进方案，有需要的话可以先阅读博文 <a href="/2018/08/26/bt-overview/" title="BT 增强建议之概述">BT 增强建议之概述</a>。</p><h2 id="进阶改进方案"><a href="#进阶改进方案" class="headerlink" title="进阶改进方案"></a>进阶改进方案</h2><p>本节点详细介绍几个比较重要的进阶改进方案。剩余的只作简单归纳。</p><h3 id="超级做种模式提高做种效率"><a href="#超级做种模式提高做种效率" class="headerlink" title="超级做种模式提高做种效率"></a>超级做种模式提高做种效率</h3><p><a href="http://bittorrent.org/beps/bep_0016.html" target="_blank" rel="noopener">BEP16 - Superseeding</a> 中起草的超级做种功能是一个来帮助初始做种者使用较少的流量来完成做种的算法。当一个做种客户端进入超级做种模式后，它将不会表现为一个标准的做种者，而是伪装成一个没有数据的正常 peer。当有其他 peer 连接时，它仅将一个从未发送过的片段发送给刚连接的 peer，在一个别的 peer 通知到该做种者这个片段前，做种者不会向刚才的 peer 发送新的片段，以此节约做种者的流量。<br>一般情况下，不建议使用超级种子模式。虽然它确实有助于更广泛地分发稀有数据，因为它限制了客户端可以下载的片段的选择，但也限制了这些客户端下载已经检索到的部分片段数据的能力。因此，超级种子模式仅推荐用于初始种子服务器。</p><h3 id="使用-Web-方式做种"><a href="#使用-Web-方式做种" class="headerlink" title="使用 Web 方式做种"></a>使用 Web 方式做种</h3><p>WebSeed 在 BEP 中有两个增强建议：<a href="http://bittorrent.org/beps/bep_0019.html" target="_blank" rel="noopener">BEP19 - HTTP/FTP Seeding (GetRight style)</a> 和 <a href="http://bittorrent.org/beps/bep_0017.html" target="_blank" rel="noopener">BEP17 - Seeding (Hoffman-style)</a></p><p>BEP17 提供了一种通过 HTTP 协议做种以及从 HTTP 获取数据的方式。初始做种者主要在元数据文件中加入键 <code>httpseeds</code>，值为支持 HTTP Seeding 服务器地址列表，举例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">d[&apos;httpseeds&apos;] = [ &apos;http://www.site1.com/source1.php&apos;,</span><br><span class="line">                   &apos;http://www.site2.com/source2.php&apos;  ]</span><br></pre></td></tr></table></figure><p>客户端通过以下方式访问 HTTP Seeding 服务器获取全部或者特定数据片段。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;url&gt;?info_hash=[hash]&amp;piece=[piece]&#123;&amp;ranges=[start]-[end]&#123;,[start]-[end]&#125;...&#125;</span><br></pre></td></tr></table></figure><p>BEP19 通告服务器地址的方式和 BEP17 差不多，但是键改为了 <code>url-list</code>。BEP19 的优点是能够处理任何可通过普通 HTTP 或 FTP 访问的文件，利用标准 HTTP 请求下载片段。BEP17 要求对服务器做适当修改，以支持 BEP17，这在互操作性方面是一个缺点，但它确实具有允许种子服务器更好地控制流量和避免带宽滥用的优势。</p><h3 id="私有种子加强数据分享隐私性"><a href="#私有种子加强数据分享隐私性" class="headerlink" title="私有种子加强数据分享隐私性"></a>私有种子加强数据分享隐私性</h3><p>私有种子是在 <a href="http://bittorrent.org/beps/bep_0027.html" target="_blank" rel="noopener">BEP27 - Private Torrents</a> 中描述的，通过在元数据信息总增加键值对 <code>private=1</code> 来标记种子为私有种子。客户端只能向私有种子对应的私有 Tracker 通告自身，而且只能与私有 Tracker 返回的 peer 建立连接。</p><p>当私有种子的 <code>announce-list</code> 中出现多个 Tracker 地址时，每个 peer 在一个时刻只能使用其中一个 Tracker，只有当 Tracker 出错时才可以切换 Tracker。在切换 Tracker 时，peer 必须断开所有与其他 peer 的连接，之后只能与新的 Tracker 提供的 peer 建立连接。这减轻了攻击者通过修改元数据文件中 <code>announce-list</code> 后发布新的元数据文件进行攻击带来的影响。</p><p>当种子为私有种子时，通过其他方式（包括 DHT, PEX, LSD 等）获取 peer 都会对“私有”进行破坏。但是不能避免攻击者通过猜测 peer 的 IP 与端口的方式找到 peer，进而产生连接。</p><h3 id="Merkle-Tree-数据结构优化元数据文件大小"><a href="#Merkle-Tree-数据结构优化元数据文件大小" class="headerlink" title="Merkle Tree 数据结构优化元数据文件大小"></a>Merkle Tree 数据结构优化元数据文件大小</h3><p>如果种子文件过大，对于提供种子文件下载的中心化服务器就会有较大压力。为了让元数据文件体积减小，一个有效的方法就是将每个片段的大小增加（上限是 2 Mb），同样大小的文件因此会产生更少的摘要数量。考虑到只有当一个片段被完全接受完成且验证摘要后，才能将之与其他 peer 进行交换，这意味着节点需要一段时间才能和其他 peer 进行交换。</p><p><a href="http://bittorrent.org/beps/bep_0030.html" target="_blank" rel="noopener">BEP30 - Merkle hash torrent extension</a> 利用了 Merkle Tree 这种数据结构来优化元数据文件大小。该方案使用单一的 Merkle 哈希来替代摘要列表。Merkle 散列可用于通过分层方案验证整个内容文件以及各个块的完整性。它通过构建与数据相关的哈希树并仅需使用根哈希作为验证数据完整性的依据。</p><p>如图所示，P0-P12 代表片段 0-12，X 是为了树的完整而填充的零值片段，0-30 均表示哈希，其中 0 是根哈希。如果一个节点接受到了完整的片段 P8，那么该节点只需要额外通过一些途径知道 P8 的姊妹片段 P9 的哈希值，以及 P8 的所有叔块哈希（依次为 12，6，1）就可以验证 P8 的完整性。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">                                       0* = root hash</span><br><span class="line">                                    /     \</span><br><span class="line">                                /            \</span><br><span class="line">                            /                   \</span><br><span class="line">                        /                          \</span><br><span class="line">                    /                                 \</span><br><span class="line">                  1*                                     2</span><br><span class="line">                 / \                                    / \</span><br><span class="line">               /     \                                /     \</span><br><span class="line">             /         \                            /         \</span><br><span class="line">           /             \                        /             \</span><br><span class="line">         /                 \                    /                 \</span><br><span class="line">        3                   4                  5                   6* = uncle</span><br><span class="line">       / \                 / \                / \                 / \</span><br><span class="line">      /   \               /   \              /   \               /   \</span><br><span class="line">     /     \             /     \            /     \             /     \</span><br><span class="line">   7         8         9        10        11        12*       13        14 </span><br><span class="line">  / \       / \       / \       / \       / \       / \       / \       / \</span><br><span class="line">15   16   17   18   19   20   21   22   23   24   25   26   27   28   29   30</span><br><span class="line"></span><br><span class="line">P0   P1   P2   P3   P4   P5   P6   P7   P8*  P9*  P10  P11  P12   X    X    X</span><br><span class="line">= piece index                            =    =                   = filler hash </span><br><span class="line">                                         p    s                   </span><br><span class="line">                                         i    i                   </span><br><span class="line">                                         e    b                   </span><br><span class="line">                                         c    l</span><br><span class="line">                                         e    i</span><br><span class="line">                                              n</span><br><span class="line">                                              g</span><br></pre></td></tr></table></figure><p>原始资源发布者需要将元数据中的原本用来存储片段散列值的 <strong>pieces</strong> 键替换为存储根哈希的键 <strong>root hash</strong>。</p><p>支持 Merkle Tree 哈希方式的客户端需要同时支持扩展消息（见 <a href="/2018/08/30/bt-peer/" title="BT 增强建议之 Peer">BT 增强建议之 Peer</a>）来替代普通的 <strong>piece</strong> 消息来完成数据传输。用于传输数据的扩展消息类型是 <strong>Tr_hashpiece</strong> ，和其他扩展消息一样，这个消息也需要在 peer 间的扩展握手消息中声明。</p><p><strong>Tr_hashpiece</strong> 消息的负载内容如下：</p><ul><li>index：4 个字节，代表数据片段序号；</li><li>begin：4 个字节，代表当前当前数据子片段在整个片段中的偏移量；</li><li>hashlist length：4 个字节，代表哈希列表的长度</li><li>hashlist：哈希列表，包括片段自身哈希，姊妹片段哈希，以及各个叔片段哈希，最后是根哈希，只有当 begin 为 0 时，才需要传输 hashlist；</li><li>subpiece data：数据子片段；</li></ul><p>在 peer 接收完成某个数据片段的 <strong>Tr_hashpiece</strong> 消息后，它将根据 hashlist 中的哈希列表计算出的根哈希与原有的根哈希进行比对。如果匹配，所有哈希值都保存在该 peer 自己的 Merkle Tree 中，之后它们可以被传递给其他人。</p><p>需要注意的是，使用 Merkle Tree 的 Torrent 与使用散列值列表的 Torrent 即使它们的数据完全相同，但是由于 infohash 不一致，导致它们不在同一个 Swarm 中。另外一旦采用了 Merkle Tree 的方式，通过 WebSeed 来获取数据就变得不兼容。</p><h2 id="其他方案简述"><a href="#其他方案简述" class="headerlink" title="其他方案简述"></a>其他方案简述</h2><ul><li><a href="http://www.bittorrent.org/beps/bep_0035.html" target="_blank" rel="noopener">BEP35 - Torrent Signing</a>　利用对种子进行签名以增加下载安全性。</li><li><a href="http://bittorrent.org/beps/bep_0036.html" target="_blank" rel="noopener">BEP36 - Torrent RSS feeds</a> 定义了 RSS 订阅种子的 feed 格式。</li><li><a href="http://bittorrent.org/beps/bep_0038.html" target="_blank" rel="noopener">BEP38 - Finding Local Data Via Torrent File Hints</a> 则提出了粗略地检测用户本地是否已经存在全部或者部分即将下载的文件的方案。主要涉及在种子文件中添加 <code>similar</code> 或 <code>collections</code> 这两个键。前者表示可能与某个 infohash 共享部分数据，后者表示该种子文件所属的集合，属于同一集合的种子可能共享文件。</li><li><a href="http://bittorrent.org/beps/bep_0039.html" target="_blank" rel="noopener">BEP39 - Updating Torrents Via Feed URL</a> 使用在 info 中的键 <code>update-url</code> 来表明用于更新该种子的链接地址，如果客户端请求该地址成功且得到一个种子文件，则需要下载该更新后的种子。</li><li><a href="http://bittorrent.org/beps/bep_0047.html" target="_blank" rel="noopener">BEP47 - Padding files and extended file attributes</a> 在原始元数据描述文件信息的基础上增加了一些额外的属性。例如符号链接重复文件；为文件添加 padding 以使得下一个文件数据从片段边缘开始。</li><li><a href="http://bittorrent.org/beps/bep_0049.html" target="_blank" rel="noopener">BEP49 - Distributed Torrent Feeds</a> 与 BEP36 提供的 RSS 订阅功能类似，但是通过 DHT 网络实现。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://github.com/webtorrent/webtorrent/issues/67" target="_blank" rel="noopener">Implement Web (HTTP) Seeding (BEP17+BEP19) · Issue #67 · webtorrent/webtorrent</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
    
      <category term="BT" scheme="https://0ranga.com/tags/BT/"/>
    
  </entry>
  
  <entry>
    <title>BT 增强建议之 DHT</title>
    <link href="https://0ranga.com/2018/11/12/bt-dht/"/>
    <id>https://0ranga.com/2018/11/12/bt-dht/</id>
    <published>2018-11-12T13:11:00.000Z</published>
    <updated>2020-07-18T07:11:02.020Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>BitTorrent 使用 DHT 网路来存储 peer 信息，以实现去 Tracker 化的种子。此时，每个 peer 都成了一个 Tracker。网络基于 Kademlia 算法实现，使用 UDP 进行传输。</p><p>本文主要对 BT 中的 DHT 网络实现与在博文 <a href="/2018/11/08/dht-kademlia/" title="DHT 网络之 Kademlia 算法">DHT 网络之 Kademlia 算法</a> 中描述的 Kademlia 算法的区别进行总结。准确的说不能说是区别，而应该定义成实现细节，毕竟理论算法应用到实际时总需要因地制宜。</p><h2 id="实现细节点"><a href="#实现细节点" class="headerlink" title="实现细节点"></a>实现细节点</h2><h3 id="key-value-对存储的内容"><a href="#key-value-对存储的内容" class="headerlink" title="key-value 对存储的内容"></a>key-value 对存储的内容</h3><p>BT 使用 DHT 网络来实现去 Tracker 化，因此 peer 的信息就需要存储在 DHT 网络中，BT 中 peer 又是局限在某个 Torrent 文件中的。因此 key-value 对中 key 即 Torrent 文件的 infohash，正好 infohash 也是 160 比特长度的，value 为拥有该 infohash 文件的 peer 列表。</p><h3 id="K-桶实现细节"><a href="#K-桶实现细节" class="headerlink" title="$K$ 桶实现细节"></a>$K$ 桶实现细节</h3><p>首先 $K$ 桶中的节点有多种状态：如果一个节点在 15 分钟内回复过当前的节点的查询请求或者曾经回复过当前节点的查询请求同时在 15 分钟内有发送过查询请求给当前节点，则该节点相对于当前节点为 <em>Good 节点</em>；如果一个节点 15 分钟内未曾活动过，则成为 <em>Questionable 节点</em>；如果一个节点未相应当前节点的多次查询请求，则视为 <em>Bad 节点</em>。</p><p>当一个桶中节点数量已满（$K$ 的容量 $k$ 在 BT 中为 8）且都是 Good 节点，新的节点如果想要加入则直接被忽略。如果桶中有 Bad 节点，新的节点将会替代之。如果桶中有 Questionable 节点，则按照这些节点加入桶的时间进行 ping 请求，如果有节点不能被 ping 成功则新的节点将会取代之。</p><p>每个桶都会有一个<em>最近更新时间</em>标记来指示桶中节点的新鲜程度。如果一个桶中节点被 ping 成功了，或者有新的节点加入，或者一个节点被另一个替代了，这个时间会更新。如果一个桶最近更新时间已经过去 15 分钟，则需要进行一次桶刷新，方式和 Kademlia 中描述的一致。</p><h3 id="Peer-DHT-支持与否告知"><a href="#Peer-DHT-支持与否告知" class="headerlink" title="Peer DHT 支持与否告知"></a>Peer DHT 支持与否告知</h3><p>peer 通过在 handshake 握手消息中将 reserved_byte 的最后一比特设置为 1 来表示支持 DHT 网络。同样支持 DHT 网络的节点收到该握手消息后会发起一个 PORT 消息，type 为 9，负载为两个字节的 DHT 节点 UDP 端口。收到 PORT 消息的节点需要对改节点端口执行 ping 操作，如果对方响应了，则节点需要尝试将其加入到 $K$ 桶中。</p><h3 id="初始节点获取"><a href="#初始节点获取" class="headerlink" title="初始节点获取"></a>初始节点获取</h3><p>去 Tracker 化的 Torrent 文件中是没有存储 Tracker 地址的 ”announce“ 键的。取而代之的是 ”nodes“ 键，nodes 中需要存储距离 key 最近的 $k$ 个节点地址或者存储一个 <em>Good 节点</em>，比如说产生这个 Torrent 的用户节点。不能将某些公共的节点加入到 Torrent 文件中，否则就变得不那么去 Tracker 化了。nodes 大概可以表示为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nodes = [[&quot;&lt;host&gt;&quot;, &lt;port&gt;], [&quot;&lt;host&gt;&quot;, &lt;port&gt;], ...]</span><br><span class="line">nodes = [[&quot;127.0.0.1&quot;, 6881], [&quot;your.router.node&quot;, 4804]]</span><br></pre></td></tr></table></figure><h3 id="RPC-消息"><a href="#RPC-消息" class="headerlink" title="RPC 消息"></a>RPC 消息</h3><p>BT 使用 KRPC 来实现 Kademlia 节点间的 RPC 通信，KRPC 消息有三种消息类型：查询，响应，错误。对于 DHT 协议，有四种查询协议：ping，find_node，get_peers，announce_peer。</p><h4 id="KRPC-协议"><a href="#KRPC-协议" class="headerlink" title="KRPC 协议"></a>KRPC 协议</h4><p>KRPC 协议是基于 UDP 和 bencode 编码的 RPC 协议。每条 KRPC 消息带有三个公共键值对以及其他因消息类型而异的键。三个公共的键是：</p><ul><li>”t“：值为字符串，代表 transaction ID。由发起 query 请求的节点生成，被请求节点需要在回复中返回。一般两个字节；</li><li>”y“：值为单字符，代表消息类型，是 q(query)、r(response)、e(error) 中的一个；</li><li>“v”：值为字符串，代表客户端版本 <a href="http://www.bittorrent.org/beps/bep_0020.html" target="_blank" rel="noopener">BEP 20</a> 中定义，不一定存在这个键；</li></ul><p>每种消息会有自己额外的键：</p><h5 id="Query-消息"><a href="#Query-消息" class="headerlink" title="Query 消息"></a>Query 消息</h5><ul><li>”q“：值为字符串，代表具体的方法类型；</li><li>”a“：值为字典，代表具体方法对应的参数字典；</li></ul><h5 id="Response-消息"><a href="#Response-消息" class="headerlink" title="Response 消息"></a>Response 消息</h5><p>如果 Query 消息执行成功，则会返回该 Response 消息。</p><ul><li>”r“：值为字典，代表返回值字典；</li></ul><h5 id="Error-消息"><a href="#Error-消息" class="headerlink" title="Error 消息"></a>Error 消息</h5><p>如果 Query 消息执行失败，则会返回该 Error 消息。</p><ul><li>”e“：值为列表，第一个元素代表错误码，第二个元素是错误消息；</li></ul><p>错误消息类型如下：</p><table><thead><tr><th>Code</th><th>Description</th></tr></thead><tbody><tr><td>201</td><td>Generic Error</td></tr><tr><td>202</td><td>Server Error</td></tr><tr><td>203</td><td>Protocol Error, such as a malformed packet, invalid arguments, or bad token</td></tr><tr><td>204</td><td>Method Unknown</td></tr></tbody></table><p>示例错误消息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">generic error = &#123;&quot;t&quot;:&quot;aa&quot;, &quot;y&quot;:&quot;e&quot;, &quot;e&quot;:[201, &quot;A Generic Error Ocurred&quot;]&#125;</span><br><span class="line">bencoded = d1:eli201e23:A Generic Error Ocurrede1:t2:aa1:y1:ee</span><br></pre></td></tr></table></figure><h4 id="DHT-Query-消息"><a href="#DHT-Query-消息" class="headerlink" title="DHT Query 消息"></a>DHT Query 消息</h4><h5 id="ping"><a href="#ping" class="headerlink" title="ping"></a>ping</h5><p>用于检测一个节点是否工作，相当于 Kademlia 的 PING 调用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">arguments:  &#123;&quot;id&quot; : &quot;&lt;querying nodes id&gt;&quot;&#125;</span><br><span class="line"></span><br><span class="line">response: &#123;&quot;id&quot; : &quot;&lt;queried nodes id&gt;&quot;&#125;</span><br></pre></td></tr></table></figure><h5 id="find-node"><a href="#find-node" class="headerlink" title="find_node"></a>find_node</h5><p>查找距离指定节点 ID 最近的节点 ID 信息，相当于 Kademlia 的 FIND_NODE 调用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">arguments:  &#123;&quot;id&quot; : &quot;&lt;querying nodes id&gt;&quot;, &quot;target&quot; : &quot;&lt;id of target node&gt;&quot;&#125;</span><br><span class="line"></span><br><span class="line">response: &#123;&quot;id&quot; : &quot;&lt;queried nodes id&gt;&quot;, &quot;nodes&quot; : &quot;&lt;compact node info&gt;&quot;&#125;</span><br></pre></td></tr></table></figure><p>“Compact node info” 列表中每个节点信息占用 26 字节，其中节点 ID 20 字节，IP 与 Port 占用 6 字节。</p><h5 id="get-peers"><a href="#get-peers" class="headerlink" title="get_peers"></a>get_peers</h5><p>查找与指定 info_hash 相关的 peer 信息，相当于 Kademlia 的 FIND_VALUE 调用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">arguments:  &#123;&quot;id&quot; : &quot;&lt;querying nodes id&gt;&quot;, &quot;info_hash&quot; : &quot;&lt;20-byte infohash of target torrent&gt;&quot;&#125;</span><br><span class="line"></span><br><span class="line">response: &#123;&quot;id&quot; : &quot;&lt;queried nodes id&gt;&quot;, &quot;token&quot; :&quot;&lt;opaque write token&gt;&quot;, &quot;values&quot; : [&quot;&lt;peer 1 info string&gt;&quot;, &quot;&lt;peer 2 info string&gt;&quot;]&#125;</span><br><span class="line"></span><br><span class="line">or: &#123;&quot;id&quot; : &quot;&lt;queried nodes id&gt;&quot;, &quot;token&quot; :&quot;&lt;opaque write token&gt;&quot;, &quot;nodes&quot; : &quot;&lt;compact node info&gt;&quot;&#125;</span><br></pre></td></tr></table></figure><p>如果被请求节点有指定 info_hash 相关 peers 则以 values 为键的 “Compact IP-address/port info” 列表，否则，返回以 nodes 为键的 “Compact node info” 列表。响应中的 token 需要请求者在通过 announce_peer 向回复者宣告 peer 信息时携带。</p><h5 id="announce-peer"><a href="#announce-peer" class="headerlink" title="announce_peer"></a>announce_peer</h5><p>宣告节点自身拥有特定 info_hash 的数据，并在某个端口进行下载，相当于 Kademlia 的 STORE 调用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">arguments:  &#123;&quot;id&quot; : &quot;&lt;querying nodes id&gt;&quot;,</span><br><span class="line">  &quot;implied_port&quot;: &lt;0 or 1&gt;,</span><br><span class="line">  &quot;info_hash&quot; : &quot;&lt;20-byte infohash of target torrent&gt;&quot;,</span><br><span class="line">  &quot;port&quot; : &lt;port number&gt;,</span><br><span class="line">  &quot;token&quot; : &quot;&lt;opaque token&gt;&quot;&#125;</span><br><span class="line"></span><br><span class="line">response: &#123;&quot;id&quot; : &quot;&lt;queried nodes id&gt;&quot;&#125;</span><br></pre></td></tr></table></figure><p>接受者需要校验 token 是否与之前它通过 get_peers 调用的响应回复给该请求者的一致。如果 implied_port 值为 1，表示 port 的值不可用，接受者需要将请求包的 UDP 源端口作为 port。</p><h2 id="BT-DHT-相关增强方案"><a href="#BT-DHT-相关增强方案" class="headerlink" title="BT DHT 相关增强方案"></a>BT DHT 相关增强方案</h2><h3 id="DHT-Scrape-帮助选择-Seeding-内容"><a href="#DHT-Scrape-帮助选择-Seeding-内容" class="headerlink" title="DHT Scrape 帮助选择 Seeding 内容"></a>DHT Scrape 帮助选择 Seeding 内容</h3><p>类似 <a href="http://bittorrent.org/beps/bep_0048.html" target="_blank" rel="noopener">Tracker Scrape</a>，DHT 网络可以通过 <a href="http://bittorrent.org/beps/bep_0033.html" target="_blank" rel="noopener">BEP33 - DHT Scrapes</a> 中定义的 DHT scrape 来了解某个 Swarm 中 peer 的大致情况，然后根据这个状态选择 seeding 队列中下一个 Swarm 进行做种。这种算法主要通过布隆过滤器（Bloom Filter）实现，布隆过滤器通常用于检索一个元素是否在一个集合中。但在 DHT scrape 中，作用所有不同。加入布隆过滤器中的是各个 peer 的 IP 的 sha1 值，可以根据过滤器中剩余的 0 比特数量来估算整个 Swarm 的规模。</p><h3 id="只读-DHT-节点"><a href="#只读-DHT-节点" class="headerlink" title="只读 DHT 节点"></a>只读 DHT 节点</h3><p>在一些情况下，DHT 节点主动或被动地限制成为只读节点（<a href="http://bittorrent.org/beps/bep_0043.html" target="_blank" rel="noopener">BEP43 - Read-only DHT Nodes</a> 中定义），比如位于 NAT 后且 hole punching 失败的节点，节点具有流量限制或者有流量计划，流量会影响节点的电量等等情况。</p><p>节点通过在每条向外发送的 DHT Query 消息中给出一个 <code>ro=1</code> 的键值对来表明自己为只读节点。成为只读节点后，不再响应其他节点的 Query 请求。其他节点知晓只读节点后也不会发送 Query 请求以减少网络流量。</p><h3 id="在-DHT-中存储任意数据"><a href="#在-DHT-中存储任意数据" class="headerlink" title="在 DHT 中存储任意数据"></a>在 DHT 中存储任意数据</h3><p><a href="http://bittorrent.org/beps/bep_0044.html" target="_blank" rel="noopener">BEP44 - Storing arbitrary data in the DHT</a> 中提供了一种在 DHT 中存储任意数据的方式。存储的数据可以是不可变数据也可以是可变数据，不可变数据的 key 是数据内容的 sha1 值，可变数据的 key 是用于签名数据的密钥对公钥。<a href="http://bittorrent.org/beps/bep_0046.html" target="_blank" rel="noopener">BEP46 - Updating Torrents Via DHT Mutable Items</a> 则基于在 DHT 网络中存储可变数据而给出了一种用于更新 Torrent 的方法。<a href="http://bittorrent.org/beps/bep_0050.html" target="_blank" rel="noopener">BEP50 - Publish/Subscribe Protocol</a> 实现了一种基于主题的发布订阅模式来向订阅特定主题的客户端发送更新后可变数据的协议。</p><h3 id="多个监听地址情况处理"><a href="#多个监听地址情况处理" class="headerlink" title="多个监听地址情况处理"></a>多个监听地址情况处理</h3><p>某些客户端可能会监听多个公网单播 IP 地址，如果在这种情况下，该客户端仅使用一个节点 ID，则其他节点可能会因为多地址现象而对该节点 ID 进行清理。<a href="http://bittorrent.org/beps/bep_0045.html" target="_blank" rel="noopener">BEP45 - Multiple-address operation for the BitTorrent DHT</a> 中给出了一些要求和建议：</p><ul><li>要求每个套接字地址必须具有不同的节点 ID，且它们的 XOR 距离要分得比较开，响应必须从收到相应请求的同一套接字地址发送；</li><li>建议节点应避免在单个IP地址上使用多个端口；</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>和 DHT 相关的草案还有如对 IPv6 的支持（<a href="http://bittorrent.org/beps/bep_0032.html" target="_blank" rel="noopener">BEP32 - BitTorrent DHT Extensions for IPv6</a>），DHT 网络安全（<a href="http://bittorrent.org/beps/bep_0042.html" target="_blank" rel="noopener">BEP42 - DHT Security extension</a>），检索其他节点存储的 infohash 列表（<a href="http://bittorrent.org/beps/bep_0051.html" target="_blank" rel="noopener">BEP51 - DHT Infohash Indexing</a>）等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://www.quora.com/%CE%BCTorrent-Whats-the-difference-between-the-status-Queued-Seed-and-Seeding" target="_blank" rel="noopener">μTorrent: What’s the difference between the status “Queued Seed” and “Seeding”?</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
    
      <category term="BT" scheme="https://0ranga.com/tags/BT/"/>
    
  </entry>
  
  <entry>
    <title>DHT 网络之 Kademlia 算法</title>
    <link href="https://0ranga.com/2018/11/08/dht-kademlia/"/>
    <id>https://0ranga.com/2018/11/08/dht-kademlia/</id>
    <published>2018-11-08T03:29:00.000Z</published>
    <updated>2020-07-18T07:11:02.021Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>本文是论文 <a href="http://www.scs.stanford.edu/~dm/home/papers/kpos.pdf" target="_blank" rel="noopener">Kademlia: A Peer-to-Peer Information System Based on the XOR Metric</a> 的翻译。</p><a id="more"></a><h1 id="Kademlia：一种基于-XOR-距离的-P2P-信息系统"><a href="#Kademlia：一种基于-XOR-距离的-P2P-信息系统" class="headerlink" title="Kademlia：一种基于 XOR 距离的 P2P 信息系统"></a>Kademlia：一种基于 XOR 距离的 P2P 信息系统</h1><p>作者：Petar Maymounkov 以及 David Mazières</p><h2 id="Abstract（摘要）"><a href="#Abstract（摘要）" class="headerlink" title="Abstract（摘要）"></a>Abstract（摘要）</h2><p>我们描述了一种在容易出错的环境下仍具有可证明的容错性和性能的 P2P 分布式散列表。我们的系统使用了一种基于 XOR 距离的新型拓扑来路由查询与定位节点的需求，该拓扑简化了算法及算法的证明。该拓扑有这样一个特点：每次信息交换都传递或者加强了（节点间）有效联系。系统根据这种联系来发送并行异步查询消息，从而做到容忍节点故障同时不对用户造成超时。</p><h2 id="Introduction（介绍）"><a href="#Introduction（介绍）" class="headerlink" title="Introduction（介绍）"></a>Introduction（介绍）</h2><p>本论文描述 Kademlia —— 一个 P2P 分布式散列表（DHT）。Kademlia 有许多之前的 DHT 无法同时提供的理性功能。它最大限度地减少了节点必须发送的用于互相了解的配置消息数量。查找 Key 时附带自动传播配置信息。节点具有足够的认知与灵活性来通过低延迟路径路由查询。Kademlia 使用并行异步查询来避免来自失败节点的超时延迟。节点记录其他节点的存在以阻挡某些基本的拒绝服务攻击。最后，只要对运行时间进行简单的假设就可以对 Kademlia 的几个重要特性进行正式证明。</p><p>Kademlia 采用了许多 DHT 使用的基本方法。密钥使用不透明的 160 位空间，比如 SHA-1 散列。参与的计算机在 160 位密钥空间中都有一个节点 ID。<strong>key-value 键值对存储在那些 ID “接近” key 的节点上</strong>。最终，一个基于节点 ID 的路由算法使得任何节点可以通过给出的目标 key 有效地定位 key 附近的节点。</p><p>Kademlia 的众多优点得益于它创新地使用 XOR 来度量节点间的距离。XOR 是对称的，允许 Kademlia 接收来自那些拥有完全相同的路由表信息的节点的查询请求。像是 Chord 这样没有这种特性的系统就无法从查询请求中获取有用的路由信息。甚者，不对称会导致严格的路由表。在 Chord 中，每个节点必须存储？？？？？？？</p><p>为了定位接近特定 ID 的节点，Kademlia 自始至终仅使用一个路由算法。相反，其他系统使用一种算法来接近目标 ID，使用另一种算法来完成最后几跳。在现有的系统中，Kademlia 最像 Pastry 的第一阶段，虽然作者没有用这种方式描述，但是通过 Kademlia 的 XOR 距离发现目标 ID 的节点数可以减少一半。在 Pastry 的第二阶段，它将距离度量切换为 ID 间的数字差异。它还在复制中使用第二个数字差异度量。遗憾的是，第二个度量标准中相距较近的节点在第一个度量标准中则可能相差很远，以致在特定节点 ID 值处产生了不连续性，从而降低了性能，并使得对最坏情况行为的正式分析变得复杂。</p><h2 id="System-Description（系统描述）"><a href="#System-Description（系统描述）" class="headerlink" title="System Description（系统描述）"></a>System Description（系统描述）</h2><p>与其他 DHT 相同类似，Kademlia 给节点分配一个 160 位的透明 ID，并提供一个查询算法用以定位更加接近指定节点的节点，以对数级别收敛查询到目标节点。</p><p>Kademlia 高效地将节点作为一个二叉树的叶子节点，每个节点的位置取决于其 ID 的最短唯一前缀。图一展示了唯一前缀为 0011 的节点在树中的位置。对于任一给定的节点，我们将二叉树分为一系列连续的不包含该节点的子树。最高的子树由不包含该节点的整个二叉树的一半组成。接下来的子树由不包含该节点的剩余二叉树的一般组成。在图示中，节点 0011 的所有子树被圈出，按照高度由高到低排序，前缀分别是 0, 01, 000 以及 0010。</p><p><img src="kademlia-1.png" alt="图一：Kademlia 二叉树。黑色的点表示节点 0011··· 的位置；灰色的圈表示节点 0011··· 必须与之建立联系的子树。"></p><p>Kademlia 协议确保每个节点都知晓其每个子树中的至少一个节点。有了这个保证，任一节点都可以通过 ID 定位到另外的节点。图二展示了节点 0011 通过不断在子树中查询最佳它所知晓的最佳节点的方式最终找到目标节点 1110 的过程。</p><p><img src="kademlia-2.png" alt="图二：通过 ID 定位节点。前缀为 0011 的节点通过依次知晓与查询越来越近的节点从而找到前缀为 1110 的节点。图上方的线代表了 160 比特的 ID 空间，并且展示了查询到目标节点的整个过程。图的主体画出了节点 1110 发出的 RPC 消息，第一个 RPC 消息发送给 101，后续的 RPC 消息发送给前一个 RPC 消息返回的节点。"></p><p>本节的剩余部分补充了查找算法的具体细节。我们首先定义一个精确的概念来描述节点间的距离，让我们指出距离某个 key 最近的 k 个节点提供了可能。然后给出一个查询协议，即使没有节点与给定的 key 拥有相同的唯一前缀或者给定节点的一些子树是空的，这个协议仍然是可工作的。</p><h3 id="XOR-Metric（XOR-度量）"><a href="#XOR-Metric（XOR-度量）" class="headerlink" title="XOR Metric（XOR 度量）"></a>XOR Metric（XOR 度量）</h3><p>每个 Kademlia 节点都有一个 160 比特的节点 ID。节点 ID 目前只是随机的 160 位标识符，尽管它们同样可以像在 Chord 中那样构造。节点发送的每条消息都包含其节点ID，允许接收方在必要时记录发送方的存在。</p><p>键同样是 160 位标识符。为了给特定的节点分配 key-value 键值对，Kademlia 依赖两个标识符之间的距离的度量。给出两个 160 位的标识符 $x$ 和 $y$，Kademlia 将 $x$ 与 $y$ 的距离定义为 $x$ 与 $y$ 按位异或后的整数值，即 $d(x, y) = x \oplus y$。</p><p>我们首先注意到 XOR 运算是有效的，尽管属于非欧几里德距离。异或运算有以下性质：</p><ul><li>$$d(x, x) = 0$$</li><li>$$d(x, y)&gt;0, \text{ if } x \neq y$$</li><li>$$\forall x, y:d(x, y)=d(y, x)$$</li><li>$$d(x,y)+d(y,z) \geq d(x,z)$$</li><li>$$d(x,y) \oplus d(y,z) = d(x,z)$$</li><li>$$\forall a \geq 0, b \geq 0: a+b \geq a \oplus b$$</li></ul><p>接下来我们注意到异或度量刻画了基于二叉树的系统草图中隐含的距离概念。在 160 位 ID 完全填充的二叉树中，两个 ID 间距离大小是包含它们的最小子树的高度。当树未完全填满时，与 ID $x$ 最接近的节点是节点 ID 与 $x$ 共享最长公共前缀的节点。如果树中有空分支，则可能有多个叶子节点具有最长的公共前缀，在这种情况下，与 $x$ 最接近的叶子将变为离通过翻转 $x$ 中对应于树的空分支中的位得到的 $\widetilde{x}$ 最近的叶子。</p><p>类似于 Chord 算法的顺时针圆周度量，XOR 也是单向的。对于任意给定的点 $x$ 以及 $∆ &gt; 0$，仅存在一个点 $y$ 使得 $d(x, y) = ∆$。单向性保证了对于相同的 key，无论从哪个原点开始查询，都会沿着相同的路径进行收敛。这样，沿着查询路径缓存 key-value 键值对就能减轻存放热门 key 值节点的压力。类似于 Pastry 而不同于 Chord， XOR 拓扑是对称的。</p><h3 id="Node-State（节点状态）"><a href="#Node-State（节点状态）" class="headerlink" title="Node State（节点状态）"></a>Node State（节点状态）</h3><p>Kademlia 节点存储了其他节点联系人的信息以路由查询消息。对于每个 $0 \leq i &lt; 160$，每个节点构建一个（IP 地址，UDP 端口，节点 ID）的三元组列表用来存储与该节点相距 $[2^i$, $2^{i+1})$ 的节点。我们称之为 $K$ 桶。每个 $K$ 桶内节点根据节点最后可见时间进行排序，最早可见的放置在开头，最近可见的放置在末尾。对于较小的 $i$ 值，$K$ 桶通常是空的（因为不存在合适的节点）。对于较大的 $i$ 值，列表最大容量为 $k$，$k$ 是一个系统范围内的复制参数。仅当任意给定的 $k$ 个节点不会在一个小时内同时失效时，$k$ 值才有效，例如 $k = 20$。</p><p>当一个 Kademlia 节点收到任一来自其他节点的请求或者回复消息，它会根据发送者的节点 ID 更新 $K$ 桶。规则如下：</p><ul><li>如果发送节点已经存在接收方的 $K$ 桶中：<ul><li>接收方将发送节点移动到相应 $K$ 桶的尾部；</li></ul></li><li>如果发送节点并未存在接收方的 $K$ 桶中：<ul><li>如果 $K$ 桶中节点数量少于 $k$ 个，则直接将发送节点插入至 $K$ 桶尾部；</li><li>如果 $K$ 桶已满：<ul><li>如果最早可见的节点不能 ping 通，则移除该节点，然后将发送节点插入至 $K$ 桶尾部；</li><li>如果最早可见的节点可以 ping 通，则将该节点移动到尾部，然后丢弃发送节点；</li></ul></li></ul></li></ul><p>$K$ 桶高效地实现了 LRU 算法，只是活动的节点永远不会从列表中移除。这种对与旧联系人的偏好来自于我们的对于 Saroiu 等人从 Gnutella 网络收集的追踪数据的分析。图 3 展示了 Gnutella 节点随着当前时间的推移，额外在线一个小时的可能性。一个节点在线时间越长，它就越可能继续额外在线一个小时。通过保持最老的在线节点，$K$ 桶最大化了列表中节点在线的可能性。</p><p><img src="kademlia-3.png" alt="图三：额外保持一小时在线的可能性关于时间的函数。X 轴代表分钟，Y 轴表示保持在线 $x$ 分钟的节点继续保持在线到 $x + 60$ 分钟时刻的可能性"></p><p>$K$ 桶采用这样的更新策略的另一个优点在于可以抵挡特定的 DoS 攻击。攻击者不能使用新的节点泛洪系统来刷新节点的路由状态。只有当旧的节点离开了系统，Kademlia 才会插入新的节点。</p><h3 id="Kademlia-protocol（Kademlia-协议）"><a href="#Kademlia-protocol（Kademlia-协议）" class="headerlink" title="Kademlia protocol（Kademlia 协议）"></a>Kademlia protocol（Kademlia 协议）</h3><p>Kademlia 协议由四个 RPC 调用组成：<em>PING</em>, <em>STORE</em>, <em>FIND_NODE</em>, <em>FIND_VALUE</em>。</p><ul><li><em>PING</em> 用于探测一个节点是否在线。</li><li><em>STORE</em> 用于通知一个节点存储一个 key-value 对以便之后获取。</li><li><em>FIND_NODE</em> 使用一个 160 比特的 ID 作为参数。调用对象返回一个其知晓的距离目标 ID 最近的 $k$ 个节点信息 &lt;IP 地址，UDP 端口，节点 ID&gt; 三元组。这 $k$ 个三元组可能来自单个 $K$ 桶，也可能因为距离最近的 $K$ 桶未满而取自多个 $K$ 桶。在任何一种情况下，RPC 调用接收者必须返回 $k$ 个节点，除非该节点知晓节点总数小于 $k$ 个。</li><li><em>FIND_VALUE</em> 调用和 <em>FIND_NODE</em> 一样，不过当调用的接收者存有请求者所请求的键的时候，它将返回相应键的值。</li></ul><p>在所有的 RPC 中，接收者必须返回一个 160 比特的随机 RPC ID，以防止地址伪造（？）。可以将 PING 消息附加在 RPC 消息的回复中以确定发送者的网络地址。</p><h4 id="临近-ID-节点查找"><a href="#临近-ID-节点查找" class="headerlink" title="临近 ID 节点查找"></a>临近 ID 节点查找</h4><p>Kademlia 节点需要实现的最重要的过程就是根据一个节点 ID 找到与它最近的 $k$ 个节点。我们称这个过程为 <em>节点查找</em>，Kademlia 使用递归完成这个工作。由查找需求的起始节点先从离目标节点 ID 最近的非空 $K$ 桶中取出 $α$ 个节点（如果 $K$ 桶中节点不足 $α$ 个，则从其他 $K$ 桶中取满 $α$ 个）。起始接地并行向这 $α$ 个节点发送 <em>FIND_NODE</em> RPC 调用。$α$ 是一个系统级参数，例如 3。</p><p>在递归调用阶段，初始节点根据 $α$ 个节点返回的节点列表再次发送 <em>FIND_NODE</em> 请求（递归调用在所有 $α$ 个节点完成返回前就可以开始）。起始节点从其他节点返回的大小为 $k$ 的节点列表中选出 $α$ 个之前没有查询过的节点，向它们发送 <em>FIND_NODE</em> RPC 调用。失败的节点将不再会纳入考虑范围。如果有一轮 <em>FIND_NODE</em> 调用中返回的所有节点都不比之前知晓的 $k$ 个节点更加接近，则当初始节点完成对最近的这个 $k$ 个节点的查询并得到响应之后，查询结束。当 $a=1$，查询算法在信息开销和故障节点的检查延迟上与 Chord 类似。但是 Kademlia 可以灵活地从 $k$ 个节点中选择任一一个发送请求以降低查询延迟。</p><h4 id="存储键值对与重新发布时间"><a href="#存储键值对与重新发布时间" class="headerlink" title="存储键值对与重新发布时间"></a>存储键值对与重新发布时间</h4><p>上述查询过程实现了大部分的操作。为了存储一个 key-value 对，起始节点通过上述操作定位到 $k$ 个离 key 最近的节点，并向它们发送 <em>STORE</em> 调用。另外，每个节点会在需要的情况下重新发布 key-value 以使 key-value 持续存在。在 Kademlia 当前的应用中（文件分享），key-value 的原始发布者需要每个 24 小时重新进行发送。否则，key-value 将在发布 24 小时后失效，以限制系统中不可用的索引信息。对于其他的应用，比如数字证书或者用于值映射的加密哈希，更长的过期时间也许会更合适。</p><h4 id="查询键值对与过期时间"><a href="#查询键值对与过期时间" class="headerlink" title="查询键值对与过期时间"></a>查询键值对与过期时间</h4><p>为了找到一个 key-value 对，节点发起一个节点查找以找到 ID 与 key 最接近的 $k$ 个节点。值查询使用的是 <em>FIND_VALUE</em> 调用而不是 <em>FIND_NODE</em> 调用。而且，如果任何一个节点返回了值，则这个过程立即结束。出于缓存的目的，一旦查找成功，发起节点将会将 key-value 存储至其知晓的相对 key 最近的，但是在查找过程中并没有返回值的节点。</p><p>由于拓扑是单向的，随后对于相同 key 的查找很可能在查询到最近的节点之前就命中存储在非最近节点中缓存。在某个 key 活跃度非常高的情况下，系统可能会将其存储在很多节点。为了避免这种过度存储，我们为 key-value 设置了过期时间，这个时间与节点 ID 相对于 key 的距离成指数反比。虽然简单的 LRU 策略会产生类似的生命周期分布，但是没有合适的方法去选择cache的大小，因为节点对于系统将要储存多少值没有先验知识。</p><h4 id="K-桶更新与加入网络"><a href="#K-桶更新与加入网络" class="headerlink" title="$K$ 桶更新与加入网络"></a>$K$ 桶更新与加入网络</h4><p>$K$ 桶会根据经过节点的请求而保持更新。为了解决因为某个特殊的 ID 段长时间没有查询的特殊情况，节点会刷新那些在过去一小时内没有过查询请求的 $K$ 桶。刷新就是随机选取一个处在当前 $K$ 桶范围的 ID，然后对其进行节点查询。</p><p>为了加入网络，一个节点 $u$ 必须要与一个已存在在网络中的节点 w 有联系。$u$ 将 w 插入到合适的 $K$ 桶中，随后 $u$ 对自己的 nodeID 进行一次节点查询，最后，$u$ 会联系到离它邻居更远的节点，然后更新相应的 $K$ 桶。在刷新过程中，$u$ 填充了自己的 $K$ 桶同时也将自己插入到其他节点的 $K$ 桶中。</p><h3 id="Routing-Table（路由表）"><a href="#Routing-Table（路由表）" class="headerlink" title="Routing Table（路由表）"></a>Routing Table（路由表）</h3><p>Kademlia 的基础路由表结构非常直观，但是需要对高度不平衡的树进行一些细节处理。路由表是一棵叶子节点为 $K$ 桶的二叉树。每个 $K$ 桶包含了一些具有公共前缀的 ID。$K$ 桶公共前缀就是其在二叉树中所处的位置。可见，每个 $K$ 桶覆盖了一部分 ID 空间，所有的 $K$ 桶集合无重叠地覆盖了整个 160 比特 ID 空间。</p><p>路由二叉树中的节点是按需动态分配的。图 4 表示了这一个过程。初始状态下，节点 $u$ 的路由树只有一个节点，一个 $K$ 桶覆盖了整个 ID 空间。当 $u$ 得到了一个新的联系人时，它将根据与新的联系人的距离，尝试将其插入到合适的 $K$ 桶中。插入的规则如下：</p><ul><li>如果 $K$ 桶未满，新的联系人就会被直接插入；</li><li>如果 $K$ 桶满了：<ul><li>如果 $K$ 桶的范围包括了 $u$ 自身的 ID，则 $K$ 桶将会一分为二，原 $K$ 桶中的 ID 重新分配到新的 $K$ 桶中，然后再尝试插入；</li><li>如果 $K$ 桶的范围不包括 $u$ 自身的 ID，新的联系人将直接被丢弃；（3）</li></ul></li></ul><p>在这样高度不平衡的二叉树中会出现一个问题，导致这种情况下并不会按照规则 3 进行插入。假设一个系统中，$u$ 是<strong>唯一</strong>一个 ID 以 000 开头的节点，同时有超过 $k$ 个 ID 以 001 开头的节点 $v_1,v_2…v_k…v_n$。对于每个节点 $v$ 的路由树，$u$ 都将会被插入到一个空 $K$ 桶中。但是由于按照规则 3， $u$ 的桶更新只会通知到 $u$ 的路由树所记录的所有 $v$ 中的 $k$ 个。为了避免剩余的 $v$ 无法得到 $u$ 的桶更新信息，Kademlia 节点通过拆分以保存了超过 $k$ 个的所有有效的节点，即使不是因为 $K$ 桶中包括了自身的 ID。图 5 展示了这种额外的拆分。当 $u$ 刷新了桶，所有前缀为 001 的节点都会知晓。</p><p><img src="kademlia-4.png" alt="图四：路由表随时间的演变。一开始，节点只有一个 $K$ 桶。随着 $K$ 桶被填充，包含节点 ID 的桶被不断一分为二。"></p><p><img src="kademlia-5.png" alt="图五：一个 ID 为 $00...00$ 的节点的宽松路由表。为了确保其知晓它周围最小子树（至少 $k$ 个节点）的所有联系人，这个路由表进行了额外的拆分。"></p><h3 id="Efficient-Key-Re-publishing（Key-的高效重发布）"><a href="#Efficient-Key-Re-publishing（Key-的高效重发布）" class="headerlink" title="Efficient Key Re-publishing（Key 的高效重发布）"></a>Efficient Key Re-publishing（Key 的高效重发布）</h3><p>为了保证 key-value 对的持久存在，节点必须周期性重发布 key。否则，两种情况下可能导致对有效 key 的查询失败。</p><ul><li>一些获得 key-value 对的节点离开了网络</li><li>新的相比原始被发布过 key-value 对的节点 ID 更近的节点加入了网络</li></ul><p>在这两种情况下，拥有这个 key-value 对的节点需要将其重新发布到离 key 最近的 $k$ 个节点。</p><p>为了弥补节点离开网络的情况，节点每隔一个小时重新发布 key-value 对，一个直接的实现就是将会产生很多消息——每个存储这个 key-value 对的节点（至多 $k$ 个）间隔一小时会发起一次查询，然后向其他 $k-1$ 个节点发起 <em>STORE</em> 请求。这个重新发布操作可以大大简化。首先，当一个节点收到对某个 key-value 对的 <em>STORE</em> 调用，它假设这个 RPC 调用同样被发送给了另外 $k-1$ 个节点，这个节点在下一个小时不会再重新发布此 key-value 对。这保证了知道复制间隔不是完全同步的，每隔小时内只有一个节点会重新发布 key-value 对。</p><p>第二个优化在于在重新发布 key 之前避免进行节点查询。像上一节所说的，为了处理不平衡树，在必要的时候节点将会拆分 $K$ 桶来确保它对至少 $k$ 个节点的周围子树充分了解。如果节点在重新发布 key-value 之前更新了该 $k$ 节点子树的所有 $K$ 桶，它将自动获知距离给定 key 最近的 $k$ 个节点。对于这些 $K$ 桶的更新代价可以分摊给许多 key 的重新发布（平均而言，这样就降低了单个 key 重新发布时的代价）。</p><p>要搞清楚为什么在 $u$ 更新规模大于等于 $k$ 的子树的所有 $K$ 桶后不再需要节点查询了，需要分为两种情况。如果要被充发布的 key 在该子树的 ID 范围内，那么因为子树的规模至少为 $k$ 而且 $u$ 具有该子树的全部知识，显然 $u$ 肯定知道距离 key 的最近 $k$ 个节点。如果要被充发布的 key 在该子树的 ID 范围外，因为 $u$ 是 $k$ 个距离 key 最近的节点之一（否则 $u$ 不会存储关于该 key 的信息），显然所有距离该 key 比距离子树更近一些的 $K$ 桶中的元素都少于 $k$。因此，$u$ 将会知晓所有这些 $K$ 桶中的所有节点，再加上关于子树的知识，就可以得到距离该 key 最近的 $k$ 个节点。</p><p>当一个新节点加入网络，对于每个 key-vaule 对来说，如果该节点为其 $k$ 个最近节点之一，那么必须对其进行存储。网路中原有的节点同样可以通过其边缘子树的完整知识，知道哪些 key-value 对需要存储在该新增节点上。每个了解到新节点的节点都会发起 <em>STORE</em> 调用把相关的 key-value 对传送到新节点之上。为了避免重复的 STORE 调用 ，只有那些自身 ID 比其他节点 ID 更接近 key 的节点才会进行 key-value 对的传送。</p><h2 id="Sketch-of-Proof（待译）"><a href="#Sketch-of-Proof（待译）" class="headerlink" title="Sketch of Proof（待译）"></a>Sketch of Proof（待译）</h2><p>待翻译</p><h2 id="Implementation-Notes（待译）"><a href="#Implementation-Notes（待译）" class="headerlink" title="Implementation Notes（待译）"></a>Implementation Notes（待译）</h2><p>待翻译</p><h2 id="Summary（总结）"><a href="#Summary（总结）" class="headerlink" title="Summary（总结）"></a>Summary（总结）</h2><p>由于采用基于 XOR 度量的拓扑，Kademlia 是第一个结合了可证明的一致性，性能，低时延路由以及单向对称拓扑的点对点系统。Kademlia 还引入了并发参数 $α$，它允许人们在带宽中交换常数因子，以实现异步最低延迟路由选择和无延迟错误恢复。最后，Kademlia 是第一个利用节点故障与正常运行时间成反比关系这一事实的点对点系统。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol><li><a href="https://blog.csdn.net/hoping/article/details/5307320" target="_blank" rel="noopener">Kademlia ：一种基于 XOR 度量的 P2P 信息系统</a></li><li><a href="http://www.huamo.online/2018/06/12/P2P%E7%BD%91%E7%BB%9C-Kademlia%E5%8D%8F%E8%AE%AE/" target="_blank" rel="noopener">P2P网络–Kademlia协议</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是论文 &lt;a href=&quot;http://www.scs.stanford.edu/~dm/home/papers/kpos.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Kademlia: A Peer-to-Peer Information System Based on the XOR Metric&lt;/a&gt; 的翻译。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Algorithm" scheme="https://0ranga.com/tags/Algorithm/"/>
    
      <category term="翻译" scheme="https://0ranga.com/tags/%E7%BF%BB%E8%AF%91/"/>
    
  </entry>
  
  <entry>
    <title>在 IPFS 上部署静态博客</title>
    <link href="https://0ranga.com/2018/09/22/ipfs-blog/"/>
    <id>https://0ranga.com/2018/09/22/ipfs-blog/</id>
    <published>2018-09-22T13:12:00.000Z</published>
    <updated>2020-07-18T07:11:02.024Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>本文主要记录在 IPFS 上部署博客的过程，用以熟悉 IPFS 的基本操作。<a href="https://ipfs.0ranga.com/" target="_blank" rel="noopener">https://ipfs.0ranga.com</a> 就是博主博客在 IPFS 上部署的版本。</p><a id="more"></a><h2 id="IPFS"><a href="#IPFS" class="headerlink" title="IPFS"></a>IPFS</h2><h3 id="安装-IPFS"><a href="#安装-IPFS" class="headerlink" title="安装 IPFS"></a>安装 IPFS</h3><p>首先得在计算机上安装 IPFS，博主 PC 的操作系统的 Arch，可以直接使用包管理器进行安装。如果之后需要为博客添加域名则需要在云服务器上部署 IPFS，博主选择的是 DightOcean 的 CentOS 7。所以提供了以上两种操作系统的安装方式，其他系统如何安装请自行探索。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Arch</span></span><br><span class="line"><span class="comment">## 包管理器直接安装</span></span><br><span class="line">pacman -S go-ipfs </span><br><span class="line"></span><br><span class="line"><span class="comment"># CentOS</span></span><br><span class="line"><span class="comment">## 从 https://dist.ipfs.io/#go-ipfs 获取最新安装包，例如</span></span><br><span class="line">wget https://dist.ipfs.io/go-ipfs/v0.4.17/go-ipfs_v0.4.17_linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment">## 解压</span></span><br><span class="line">tar xvfz go-ipfs_v0.4.17_linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment">## 安装</span></span><br><span class="line"><span class="built_in">cd</span> go-ipfs &amp;&amp; ./install.sh</span><br></pre></td></tr></table></figure><p>安装完成后需要先初始化 IPFS</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipfs init</span><br></pre></td></tr></table></figure><p>另外，一般在云服务器上需要将 IPFS 设置为自启动服务，设置方式如下，首先需要添加 service 描述文件</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/systemd/system/ipfs.service</span><br></pre></td></tr></table></figure><p>文件内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=IPFS Daemon</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/usr/local/bin/ipfs daemon --enable-namesys-pubsub</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>然后使服务开机自启动同时立即启动：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> ipfs</span><br><span class="line">systemctl start ipfs</span><br></pre></td></tr></table></figure><h3 id="部署一个文件"><a href="#部署一个文件" class="headerlink" title="部署一个文件"></a>部署一个文件</h3><p>接下来在本地创建一个文件 <code>index.html</code>，在里面写入简单的话</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">'hello, my simple blog!'</span> &gt; index.html</span><br></pre></td></tr></table></figure><p>随后添加至 IPFS 中</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipfs add index.html</span><br></pre></td></tr></table></figure><p>得到返回如下</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ipfs add index.html </span><br><span class="line"><span class="comment"># added QmaqwGFUj34wDLPzHVxmJhEN6n27xidsfrmf2WUnhSTKTr index.html</span></span><br><span class="line"><span class="comment"># 23 B / 23 B [=========================================] 100.00%</span></span><br></pre></td></tr></table></figure><p>可以通过如下命令查看文件内容</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipfs cat QmaqwGFUj34wDLPzHVxmJhEN6n27xidsfrmf2WUnhSTKTr</span><br></pre></td></tr></table></figure><p>当我们使用如下命令启动节点后，文件内容将会逐渐被 IPFS 网络存储</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ipfs daemon</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">systemctl start ipfs</span><br></pre></td></tr></table></figure><p>随后可以通过访问 <a href="https://gateway.ipfs.io/ipfs/QmaqwGFUj34wDLPzHVxmJhEN6n27xidsfrmf2WUnhSTKTr" target="_blank" rel="noopener">https://gateway.ipfs.io/ipfs/QmaqwGFUj34wDLPzHVxmJhEN6n27xidsfrmf2WUnhSTKTr</a> 得到该文件。如果你不介意将这句简单的话作为你的博客的全部内容的话，那至此博客的全部创建完成了，而且理论上永远不会消失。</p><h2 id="部署静态博客框架：以-Hexo-为例"><a href="#部署静态博客框架：以-Hexo-为例" class="headerlink" title="部署静态博客框架：以 Hexo 为例"></a>部署静态博客框架：以 Hexo 为例</h2><p>虽然小标题写的是“以 Hexo 为例”，但本文不会细讲如何使用 Hexo，<a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">Hexo 官方文档</a>提供了细致的帮助。如果你之前用过 Hexo 而且因为懒得写作而把它丢弃在硬盘里，这里有几个命令可以帮助你快速回想起使用方法。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建新文章</span></span><br><span class="line">hexo new post &lt;new_post_name&gt;</span><br><span class="line"><span class="comment"># 清理</span></span><br><span class="line">hexo clean</span><br><span class="line"><span class="comment"># 生成博客</span></span><br><span class="line">hexo g</span><br><span class="line"><span class="comment"># 启动本地服务器</span></span><br><span class="line">hexo s --open</span><br><span class="line"><span class="comment"># 部署</span></span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><p>在使用 <code>hexo g</code> 生成静态博客后，我们可以在 <strong>public</strong> 目录中找到部署博客需要的所有文件，入口是熟悉的 <strong>index.html</strong>。（其他博客框架也有个类似 public 的文件夹用于存放整个博客）</p><p>使用如下命令将整个 public 文件夹放入 IPFS</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipfs add -r public</span><br></pre></td></tr></table></figure><p>添加后的输出中最后一行是目录 public 的哈希值，比如博主得到的是</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># added QmSc5D1ahPbVkAhHFxJvqnWDEWrgMQw9B9BGmQv5i1VAwt public</span></span><br></pre></td></tr></table></figure><p>然后访问 <a href="https://gateway.ipfs.io/ipfs/QmSc5D1ahPbVkAhHFxJvqnWDEWrgMQw9B9BGmQv5i1VAwt/" target="_blank" rel="noopener">https://gateway.ipfs.io/ipfs/QmSc5D1ahPbVkAhHFxJvqnWDEWrgMQw9B9BGmQv5i1VAwt/</a> 就可以看到保存在 IPFS 上的博客了。不过，在修改文章更新 public 目录之后，目录的哈希值会变化，因此以上的连接只是博客在当前的一个（永久）状态，如果想要通过一个链接访问不断更新的博客，就需要借助 IPNS，IPNS 的作用就是将某个文件与 PeerID 进行绑定，一般情况下，PeerID 可以保持不变，这样，通过访问 PeerID，就可以访问与 PeerID 绑定的内容了，这和 DNS 中域名与 IP 的关系类似。</p><p>通过以下命令将当前的 public 目录哈希与 PeerID，PeerID 不需要显示指定，得到绑定结果后的 PeerID 实际上与通过 <code>ipfs id</code> 命令得到的 ID 一致。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绑定</span></span><br><span class="line">ipfs name publish &lt;file_hash&gt;</span><br><span class="line">ipfs name publish QmSc5D1ahPbVkAhHFxJvqnWDEWrgMQw9B9BGmQv5i1VAwt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绑定后的输出</span></span><br><span class="line"><span class="comment"># Published to QmRP5ZT2B5W8zWTXhPwpgZQpuj8Gv5bNaXWbttRB6niAYo:</span></span><br><span class="line"><span class="comment"># /ipfs/QmSc5D1ahPbVkAhHFxJvqnWDEWrgMQw9B9BGmQv5i1VAwt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 访问（列出目录） IPNS QmRP5ZT2B5W8zWTXhPwpgZQpuj8Gv5bNaXWbttRB6niAYo</span></span><br><span class="line">ipfs ls /ipns/&lt;peer_id&gt;</span><br><span class="line">ipfs ls /ipns/QmRP5ZT2B5W8zWTXhPwpgZQpuj8Gv5bNaXWbttRB6niAYo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 反向解析</span></span><br><span class="line">ipfs name resolve &lt;peer_id&gt;</span><br><span class="line">ipfs name resolve QmRP5ZT2B5W8zWTXhPwpgZQpuj8Gv5bNaXWbttRB6niAYo</span><br></pre></td></tr></table></figure><p>绑定 IPNS 之后，可以通过 <a href="https://gateway.ipfs.io/ipns/QmRP5ZT2B5W8zWTXhPwpgZQpuj8Gv5bNaXWbttRB6niAYo/" target="_blank" rel="noopener">https://gateway.ipfs.io/ipns/QmRP5ZT2B5W8zWTXhPwpgZQpuj8Gv5bNaXWbttRB6niAYo/</a> 访问到博客。</p><p><strong>但是直接部署 public 目录存在一个问题</strong>：hexo 这类的博客中所有本地资源的路径均为根目录开头的相对站点根目录的绝对路径，例如对于 <code>/css/home.css</code>，当访问 <code>https://gateway.ipfs.io/ipfs/&lt;file_hash&gt;</code> 这样在文件中有类似绝对路径链接时，相当于访问 <code>https://gateway.ipfs.io/css/home.css</code>，显然这个 <code>home.css</code> 文件是不存在的。如果想要使得网站可以正确访问，有两种解决办法：</p><ol><li>使用相对路径 <code>./css/home.css</code>，这样就相当于访问 <code>https://gateway.ipfs.io/ipfs/&lt;file_hash&gt;/css/home.css</code>，如此可以正确访问。如果博客框架自身支持将所有本站资源的绝对路径替换成这样，或者整个博客是自己实现如此，那不需要额外的操作就可以得到一个完美的博客。</li><li>让 <code>http://gateway.site/css/home.css</code> 真实存在，即将 <code>http://gateway.ipfs.io/ipfs/&lt;file_hash&gt;</code> 替换成一个独立域名 <code>http://gateway.site</code>，这就需要用到 IPFS 提供的 <a href="https://github.com/ipfs/go-dnslink" target="_blank" rel="noopener">dnslink</a> 增强。</li></ol><h2 id="为博客添加域名"><a href="#为博客添加域名" class="headerlink" title="为博客添加域名"></a>为博客添加域名</h2><p>还是以我自己的域名 0ranga.com 为例，这个域名托管在 Namecheap 上，使用 Namecheap 的 DNS 管理，可以为域名增加一个子域名 TXT 记录如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TXT 0ranga.com dnslink=/ipns/QmRP5ZT2B5W8zWTXhPwpgZQpuj8Gv5bNaXWbttRB6niAYo</span><br></pre></td></tr></table></figure><p>这样，我们可以通过地址 <a href="https://gateway.ipfs.io/ipns/0ranga.com" target="_blank" rel="noopener">https://gateway.ipfs.io/ipns/0ranga.com</a> 访问到部署在 IPFS 上博客。我们还可以进一步缩短访问链接长度，在 DNS 管理中进一步添加如下记录（为了不与原博客 0ranga.com 冲突，这里使用子域名 ipfs.0ranga.com）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 1. 为子域名 ipfs.0ranga.com 添加 A 记录，绑定到一个 Gateway 的 IP，</span><br><span class="line">#    示例中是 209.94.78.78 ，这个 IP 是 gateway.ipfs.io 的众多 IP 中的一个</span><br><span class="line">A ipfs.0ranga.com 209.94.78.78</span><br><span class="line"></span><br><span class="line"># 2. 为子域名 ipfs.0ranga.com 添加 TXT 记录，指定 IPNS</span><br><span class="line">TXT ipfs.0ranga.com dnslink=/ipns/QmRP5ZT2B5W8zWTXhPwpgZQpuj8Gv5bNaXWbttRB6niAYo</span><br></pre></td></tr></table></figure><p>等待 DNS 记录生效后，可以通过 <a href="http://ipfs.0ranga.com/" target="_blank" rel="noopener">http://ipfs.0ranga.com</a> 访问博客。至此，博客的短链接改造已经基本完成。接下来会记录些自己另外的一些尝试，包括对博客的访问进行加速等。</p><h2 id="进阶"><a href="#进阶" class="headerlink" title="进阶"></a>进阶</h2><h3 id="部署云服务器以增强博客的可用性同时加快访问速度"><a href="#部署云服务器以增强博客的可用性同时加快访问速度" class="headerlink" title="部署云服务器以增强博客的可用性同时加快访问速度"></a>部署云服务器以增强博客的可用性同时加快访问速度</h3><p>如果部署了博客的本地 PC 关机，同时博客的访问量不是那么可观，则可能存在一部分博客文件无法访问的情况，因为在没有激励的情况下 IPFS 上的其他节点一般不会主动存储其他用户往 IPFS 中添加的文件。所以配置一个云服务器来存储博客本身就可以确保文件的可用性（请问：那为什么还要用 IPFS 来部署博客？），同时随着 FileCoin 激励与 IPFS 的结合，事情会变得不那么糟糕。</p><p>云服务部署的步骤如下：</p><ol><li><p>按照<strong>安装 IPFS</strong> 这小节中的安装方法在云服务器上部署一个 IPFS 服务；</p></li><li><p>为了 Gateway 可以被公网访问，需要将 IPFS 配置文件 <code>～/.ipfs/config</code> 中 <code>Addresses:Gateway</code> 的配置改为 <code>/ip4/0.0.0.0/tcp/80</code> ，用以监听所有网卡上的 TCP 80 端口，随后重启 IPFS 服务使配置生效；</p></li><li><p>通过本地浏览器直接访问云服务器的 IP （博主目前测试使用的服务器实例的 IP 为 <code>104.248.70.88</code>）结果为 <strong>404 page not found</strong> ，则表明服务部署成功。进一步，访问 <a href="http://104.248.70.88/ipfs/QmaqwGFUj34wDLPzHVxmJhEN6n27xidsfrmf2WUnhSTKTr" target="_blank" rel="noopener">http://104.248.70.88/ipfs/QmaqwGFUj34wDLPzHVxmJhEN6n27xidsfrmf2WUnhSTKTr</a> 可以得到 <strong>部署一个文件</strong> 这节中的 <strong>index.html</strong> 文件，至此完成了 IPFS Gateway 的部署与共享；</p></li><li><p>为 Gateway 绑定域名。类似之前的做法，添加一条 DNS A 记录。待记录生效后，访问连接变为 <a href="http://gateway.0ranga.com/ipfs/QmaqwGFUj34wDLPzHVxmJhEN6n27xidsfrmf2WUnhSTKTr" target="_blank" rel="noopener">http://gateway.0ranga.com/ipfs/QmaqwGFUj34wDLPzHVxmJhEN6n27xidsfrmf2WUnhSTKTr</a></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A gateway.0ranga.com 104.248.70.88</span><br></pre></td></tr></table></figure></li><li><p>改用自己的 Gateway。将之前配置的子域名 ipfs.0ranga.com 的 A 记录对应的 IP 改成云服务器的 IP（TXT 记录保持不变），当浏览器访问 ipfs.0ranga.com 这个域名时，首先会访问 104.248.70.88 这台 Gateway 服务器，Gateway 再向整个 IPFS 网络收集当前页面的碎片；</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A ipfs.0ranga.com 104.248.70.88</span><br></pre></td></tr></table></figure></li><li><p>通过 Pin 操作将本地博客 public 目录”钉“至云服务器 IPFS 节点，然后将 public 目录哈希绑定至云服务器中 IPFS 的 PeerID，另外记得修改子域名 ipfs.0ranga.com 的 TXT 记录中的 IPNS 地址。此后即使关闭本地 PC 的 IPFS 服务，部署在 IPFS 上博客也可以被正常访问，访问地址依然是 <a href="http://ipfs.0ranga.com;/" target="_blank" rel="noopener">http://ipfs.0ranga.com；</a></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipfs pin add QmSc5D1ahPbVkAhHFxJvqnWDEWrgMQw9B9BGmQv5i1VAwt</span><br></pre></td></tr></table></figure></li><li><p>如果觉着同步文件至云服务器，而又不介意一直运行本地 PC 的 IPFS 服务，但是博客的访问速度又不快，可以考虑使用以下方式将云服务器上 IPFS 节点直接加入到本地 Peer 列表中，这样可以帮助云服务器上的 IPFS 节点快速找到本地 PC IPFS 节点中的博客文件。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipfs swarm connect /ip4/104.248.70.88/tcp/4001/ipfs/QmamxGp6sw2dKUHm2RnaJ7zRDeR3w8m98kKAYgfpszeqHR</span><br></pre></td></tr></table></figure></li></ol><h3 id="HTTPS-加持"><a href="#HTTPS-加持" class="headerlink" title="HTTPS 加持"></a>HTTPS 加持</h3><p>在云服务器 CentOS 系统上安装 Nginx 服务，然后使用 Certbot 生成 Let’s Encrypt 证书，过程比较简单，Certbot 的安装在<a href="https://certbot.eff.org/lets-encrypt/centosrhel7-nginx" target="_blank" rel="noopener">官方教程</a>有详细的说明，此处省略。最终，子域名 ipfs.0ranga.com 的 Nginx 的配置大致如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    server_name  ipfs.0ranga.com;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">            proxy_pass http://localhost:8080/;</span><br><span class="line">            proxy_set_header Host $host;</span><br><span class="line">            proxy_buffering off;</span><br><span class="line">            proxy_pass_request_headers on;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    listen 443 ssl; # managed by Certbot</span><br><span class="line">    ssl_certificate /etc/letsencrypt/live/ipfs.0ranga.com/fullchain.pem; # managed by Certbot</span><br><span class="line">    ssl_certificate_key /etc/letsencrypt/live/ipfs.0ranga.com/privkey.pem; # managed by Certbot</span><br><span class="line">    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot</span><br><span class="line">    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">    if ($host = ipfs.0ranga.com) &#123;</span><br><span class="line">        return 301 https://$host$request_uri;</span><br><span class="line">    &#125; # managed by Certbot</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    listen       80 default_server;</span><br><span class="line">    server_name  ipfs.0ranga.com;</span><br><span class="line">return 404; # managed by Certbot</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意，由于端口由 Nginx 进行控制， Gateway 不能再占用 80 端口，因此这里将其（<code>～/.ipfs/config</code> 中 <code>Addresses:Gateway</code> 配置）重新设定为 8080。gateway.0ranga.com 的 Nginx 配置也是类似。Hurray！现在我们可以通过 <a href="https://ipfs.0ranga.com/" target="_blank" rel="noopener">https://ipfs.0ranga.com</a> 访问博主部署在 IPFS 上的博客，通过 <a href="https://gateway.0ranga.com/" target="_blank" rel="noopener">https://gateway.0ranga.com</a> 访问博主的 Gateway 了。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>可以用以下几个网址进行总结：</p><table><thead><tr><th>序号</th><th>链接</th><th>改进之处</th></tr></thead><tbody><tr><td>1</td><td><a href="https://gateway.ipfs.io/ipfs/" target="_blank" rel="noopener">https://gateway.ipfs.io/ipfs/</a><root_path_hash>/</root_path_hash></td><td>原始博客目录</td></tr><tr><td>2</td><td><a href="https://gateway.ipfs.io/ipns/" target="_blank" rel="noopener">https://gateway.ipfs.io/ipns/</a><peer_id>/</peer_id></td><td>IPNS 映射目录，站点更新时链接保持不变</td></tr><tr><td>3</td><td><a href="https://gateway.ipfs.io/ipns/0ranga.com" target="_blank" rel="noopener">https://gateway.ipfs.io/ipns/0ranga.com</a></td><td>dnslink 绑定，增加链接可读性</td></tr><tr><td>4</td><td><a href="http://ipfs.0ranga.com/" target="_blank" rel="noopener">http://ipfs.0ranga.com</a></td><td>实现完全自定义域名</td></tr><tr><td>5</td><td><a href="https://ipfs.0ranga.com/" target="_blank" rel="noopener">https://ipfs.0ranga.com</a></td><td>为域名添加 HTTPS 证书</td></tr></tbody></table><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://michalzalecki.com/set-up-ipfs-node-on-the-server/" target="_blank" rel="noopener">https://michalzalecki.com/set-up-ipfs-node-on-the-server/</a></li><li><a href="https://github.com/ipfs/notes/issues/39" target="_blank" rel="noopener">https://github.com/ipfs/notes/issues/39</a></li><li><a href="https://www.cloudxns.net/Support/detail/id/304.html" target="_blank" rel="noopener">https://www.cloudxns.net/Support/detail/id/304.html</a></li><li><a href="https://ipfs.io/ipns/Qme48wyZ7LaF9gC5693DZyJBtehgaFhaKycESroemD5fNX/post/putting_this_blog_on_ipfs/" target="_blank" rel="noopener">https://ipfs.io/ipns/Qme48wyZ7LaF9gC5693DZyJBtehgaFhaKycESroemD5fNX/post/putting_this_blog_on_ipfs/</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要记录在 IPFS 上部署博客的过程，用以熟悉 IPFS 的基本操作。&lt;a href=&quot;https://ipfs.0ranga.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://ipfs.0ranga.com&lt;/a&gt; 就是博主博客在 IPFS 上部署的版本。&lt;/p&gt;
    
    </summary>
    
    
      <category term="IPFS" scheme="https://0ranga.com/tags/IPFS/"/>
    
  </entry>
  
  <entry>
    <title>BT 增强建议之 Peer</title>
    <link href="https://0ranga.com/2018/08/30/bt-peer/"/>
    <id>https://0ranga.com/2018/08/30/bt-peer/</id>
    <published>2018-08-30T11:14:00.000Z</published>
    <updated>2020-07-18T07:11:02.021Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>本文是 BT 系列文章中的一篇，主要介绍 Peer 以及 Peer 间的通信，有需要的话可以先阅读博文 <a href="/2018/08/26/bt-overview/" title="BT 增强建议之概述">BT 增强建议之概述</a>。</p><h2 id="Peer-来源"><a href="#Peer-来源" class="headerlink" title="Peer 来源"></a>Peer 来源</h2><p>在讲 Peer 间的通信前，先总结一下 Peer 的来源。</p><ol><li><strong>Magnet</strong>：磁力连接中有 <strong>x.pe</strong> 参数可以预设一些 Peer；</li><li><strong>Tracker</strong>：Tracker 服务器的作用就是提供 Peer；</li><li><strong>Local Service Discovery</strong>（<a href="http://bittorrent.org/beps/bep_0014.html" target="_blank" rel="noopener">BEP14</a>）:通过对本地组播地址 <code>239.192.152.143:6771</code> 和 <code>[ff15::efc0:988f]:6771</code> 发出 info_hash 宣告来尝试获得响应，如果有响应，则添加为 Peer；</li><li><strong>Peer Exchange</strong>：通过 Peer 间的 <strong>Peer Exchange</strong> 扩展消息来与其他 Peer 交换 Peer，后面会详细提到；</li><li><strong>DHT</strong>：通过 DHT 网络获取；</li></ol><h2 id="协议概述"><a href="#协议概述" class="headerlink" title="协议概述"></a>协议概述</h2><p>Peer 间的通信属于应用层协议，它使用的应用层协议可以是 TCP 或者 µTP。</p><p>Peer 间按照元数据中描述的文件片段索引（起始索引为 0）进行数据交换，当一个 peer 下载完成一个分片而且经过了通过了 hash 值的校验，它会通知它的所有 peer 自己拥有了这个片段。</p><p>Peer 连接的 Peer 会有一定上限数量，所有的 Peer 按照 <a href="http://bittorrent.org/beps/bep_0040.html" target="_blank" rel="noopener">BEP40 - Canonical Peer Priority</a> 中定义的基于双方 IP 的 crc32-c 值的算法进行排序，选择这个值更小的若干 Peer 进行连接。</p><p>每个连接会包含两个状态位，choked or not（表示是否对对方 choked），interested or not（表示是否对对方的数据感兴趣），状态在连接建立时的初始值为 choked 以及 not interested。因为交互是双方的，一方不仅要存储自己给对方设定的状态，也要存储对方给自己设定的状态，因此实际上会有四个状态位（BEP 中表示只有两个状态位，但是由于主动与被动语态的复杂性以及考虑到实际源码的实现，这里引入成四个状态位，增加了一定的冗余，但便于写作，一定程度上也便于理解）。</p><p>假设 A，B 是在下载同一个资源的对等体。用 A.B 表示 peer A 中 A 与 B 的连接。所以 A 与 B 连接建立时，在 A 的内存空间中的保存的对于 B 的连接会有如下的状态：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">choked = <span class="literal">true</span>;</span><br><span class="line">interested = <span class="literal">false</span>;</span><br><span class="line">peer_choked = <span class="literal">true</span>;</span><br><span class="line">peer_interested = <span class="literal">false</span>;</span><br></pre></td></tr></table></figure><p>同样道理，B 中也会有类似的这样四个状态。且初始状态相同。只有当 A 的 <code>interested == true</code> 而且 <code>peer_choked == false</code> 时，A 才能向 B 索要数据。</p><p>对于 A 而言，有下面四个时机更新这一组状态：</p><ul><li>在收到 B 发来的 <strong>choke</strong>/<strong>unchoke</strong> 消息时，会更新 <code>peer_choked</code> 状态置为 true/false；</li><li>在收到 B 发来的 <strong>interested</strong>，<strong>not interested</strong> 消息时，会更新 <code>peer_interested</code> 状态置为 true/false；</li><li>不断根据自己所拥有的分片与 B 拥有分片的状态（B 通过 <strong>bitfield</strong> 消息告知 A）更新 <code>interested</code> 状态，并通过发送 <strong>interested</strong>/<strong>not interested</strong> 消息给 B；</li></ul><h2 id="消息类型"><a href="#消息类型" class="headerlink" title="消息类型"></a>消息类型</h2><p><strong>handshake</strong> 是连接 peer 间连接建立后发送的第一个消息，主要用于通告 info_hash 与 peer_id：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| 19 (1) | &quot;BitTorrent protocol&quot; (19) | reserved_byte (8) | info_hash (20) | peer_id (20) |</span><br></pre></td></tr></table></figure><p><strong>keepalive</strong>，第一个字段为消息体长度，keepalive 消息长度体为 0：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| len (4) |</span><br></pre></td></tr></table></figure><p>除基础消息外的其他消息均有固定的格式如下：消息体长度 + 类型 + 负载。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| len (4) | type (1) | payload |</span><br></pre></td></tr></table></figure><p>可能的类型值有：</p><ul><li>0 - choke</li><li>1 - unchoke</li><li>2 - interested</li><li>3 - not interested</li><li>4 - have</li><li>5 - bitfield</li><li>6 - request</li><li>7 - piece</li><li>8 - cancel</li><li>20 - extend message</li></ul><p>其中 <strong>choke</strong>，<strong>unchoke</strong>，<strong>interested</strong>，<strong>not interested</strong> 消息没有负载。</p><p><strong>bitfield</strong> 消息仅在 handshake 后双方各发送一次，每个比特表示对应的分片是否完整。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| len (4) | 5 (1) | bitfield |</span><br></pre></td></tr></table></figure><p><strong>have</strong> 消息的负载是一个整型数字，peer 在一个分片下载完成并校验通过后发送该附带刚下载完成分片的索引的消息给其他 peer。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| len (4) | 4 (1) | index (4) |</span><br></pre></td></tr></table></figure><p><strong>request</strong> 消息结构如下，用于请求指定分片（index）的范围为 <code>[ offset, offset + length )</code> 的字节，length 一般为 2^14 (16 kiB)，超过则会关闭连接。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| len (4) | 6 (1) | index (4) | offset (4) | length (4) |</span><br></pre></td></tr></table></figure><p><strong>piece</strong> 消息用于回复 request 消息，即返回自身分片（index）的范围为 <code>[ offset, offset + length )</code> 的字节</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| len (4) | 7 (1) | index (4) | offset (4) | block (length) |</span><br></pre></td></tr></table></figure><p><strong>cancel</strong> 消息除了类型和 request 消息不同外，其他均与 request 一致，用于向 peer 取消之前发出的 request 请求。这是由于为了加快最后若干分片的下载速度，客户端会启用 <strong>Endgame</strong> 模式，这个模式下，peer 会向所有的 peer 请求相同的分片片段，当 peer 从某个 peer 获得所需的分片片段后，需要向剩余的 peer 发送 cancel 消息以减少不必要的传输。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| len (4) | 8 (1) | index (4) | offset (4) | length (4) |</span><br></pre></td></tr></table></figure><p>类型为 20 的是扩展消息。</p><h2 id="扩展消息"><a href="#扩展消息" class="headerlink" title="扩展消息"></a>扩展消息</h2><p><a href="http://bittorrent.org/beps/bep_0010.html" target="_blank" rel="noopener">BEP10 - Extension Protocol</a> 中定义了扩展消息。peer 通过将 handshake 消息的保留字节的右数第 20 个比特置为 1 来通告其他 peer 自身支持扩展消息。即可以通过判断表达式 <code>reserved_byte[5] &amp; 0x10</code> 来判断 peer 是否支持扩展消息。</p><p>扩展消息的基础结构如下，实际上相当于是类型为 20 的普通消息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| len (4) | 20 (1) | extended_messag_id (1) | payload |</span><br></pre></td></tr></table></figure><p>extended_messag_id 为 0 的消息是 <strong>Extend Handshake</strong> 消息。</p><h3 id="Extend-Handshake"><a href="#Extend-Handshake" class="headerlink" title="Extend Handshake"></a>Extend Handshake</h3><p>Extend Handshake 消息的有效载荷是一个 bencode 字典。字典中的所有键都是可选的，peer 需要忽略所有自己不支持的键。可选的键（还可以有更多）如下:</p><ul><li><strong>m</strong>：字典，表示支持的扩展消息，键是扩展消息名称，值是扩展消息的 id（与 extended_messag_id 对应）。peer 通过这个键通告其他 peer 自己支持的消息类型，且该 peer 之后发送其他的扩展消息就会使用在这里对应的 extended_messag_id。扩展消息名称的格式一般为 <code>客户端缩写_消息名称</code>，这样可以实现全网全局消息类型唯一（侧重实现）；而 extended_messag_id 则是自己客户端自己定义，在 m 字典中不重复即可（侧重索引），这样便可以做到单向通信唯一。</li><li><strong>p</strong>：整型，表示本地监听端口。帮助另一方了解自己的端口信息。连接的接收方是不需要发送这个扩展消息的，因为接收方的端口是已知的。（实际上 peer 间通信无论是基于 TCP 还是 µTP（UDP），接收方理论上都可以从传输层获得端口数据）。</li><li><strong>v</strong>：字符串，表示客户端的名称与版本，这个比 peer id 更可靠一些。</li><li><strong>yourip</strong>：字符串，表示在 peer 视角中对方 peer 的 IP，一般客户端通过此获取自己的公网 IP。</li><li><strong>ipv6</strong>：字符串，表示自身压缩格式的 IPv6 地址。可能对方 peer 更喜欢使用 IPv6 地址。 </li><li><strong>ipv4</strong>：字符串，表示自身压缩格式的 IPv4 地址。可能对方 peer 更喜欢使用 IPv4 地址。</li><li><strong>reqq</strong>：整型，表示自身的在不丢弃消息情况下可以保留的未处理的消息数量。在 libtorrent 中这个值是 250。</li></ul><p>这个消息需要在普通 handshake 成功后立即发送，在连接的生命周期内这个 Extend Handshake 多次发送都是有效的，但实际实现中有可能被忽略。如果后续的 Extend Handshake 消息指定 m 字典中某些扩展的扩展 id 为 0，则表示禁用这些扩展。</p><h3 id="Metadata-Request-ut-metadata"><a href="#Metadata-Request-ut-metadata" class="headerlink" title="Metadata Request(ut_metadata)"></a>Metadata Request(ut_metadata)</h3><p><a href="http://bittorrent.org/beps/bep_0009.html" target="_blank" rel="noopener">BEP9 - Extension for Peers to Send Metadata Files</a> 中定义了磁力链接，同时也定义了用于从 Peer 获取元数据的扩展消息 <strong>UT Metadata</strong>。</p><p>如果一个 peer 的客户端支持 <strong>UT Metadata</strong> 消息，那么在该 peer 向其他 peer 发送 Extend Handshake 消息时，需要在字典 m 中加入 <strong>ut_metadata</strong> 这个键，同时保持其对应的消息 id 在 m 字典中唯一。特殊的是对于这个消息的支持还需要在 Extend Handshake 消息负载字典中加入一个键 <strong>metadata_size</strong>，表示元数据的字节数。</p><p><strong>UT Metadata</strong> 消息的负载也是一个 bencode 字典，有如下的键：</p><ul><li><strong>msg_type</strong>：整型，代表消息类型，可能的类型有：<ul><li><strong>request</strong>：0。请求类型，即请求序号为 <strong>piece</strong> 的 metadata 片段。请求类型的返回类型为 <strong>data</strong> 或者 <strong>reject</strong>；</li><li><strong>data</strong>：1。正常返回序号为 <strong>piece</strong> 的 metadata 片段。元数据会按照 16 kiB 大小切分，除了最后一片段，其余的都应该为 16 kiB 大小，序号也由此分割大小得来。元数据片段作为负载的一部分跟在整个字典后面，其并不使用 bencode 编码，但是长度需要计算在 <strong>len</strong> 中。</li><li><strong>reject</strong>：2。表示被请求的 peer 没有序号为 <strong>piece</strong> 的 metadata 片段。也有可能是一定时间内请求超过数量限制，为了防止洪泛攻击，直接表示拒绝。</li></ul></li><li><strong>piece</strong>：指定元数据的分片序号。</li><li><strong>total_size</strong>：仅在 <strong>data</strong> 类型消息中出现，和握手消息中的 <strong>metadata_size</strong> 语义一致。</li></ul><h3 id="Partial-Seeds"><a href="#Partial-Seeds" class="headerlink" title="Partial Seeds"></a>Partial Seeds</h3><p>这个扩展是为了让 BT 支持对 Partial Seeds（部分种子，<a href="http://bittorrent.org/beps/bep_0021.html" target="_blank" rel="noopener">BEP21 - Extension for partial seeds</a>）的识别与进一步优化。部分种子就是资源不完整但是也不再进行下载的 peer。这种情况发生在多文件种子中，用户只设定下载一部分文件。</p><p>这个扩展不定义额外的扩展消息，但是在扩展握手消息的字典中加入一个键 <strong>upload_only</strong>，值为整型，如果 peer 对下载不感兴趣则需要讲此值置为 1。</p><p>在 Tracker 的 Scrape 请求回复中，定义了 <strong>complete</strong>, <strong>incomplete</strong> 以及 <strong>downloaded</strong> 三种状态的 peer。为了让其他 peer 可以通过 Tracker 知晓 Partial Seeds 的情况，扩展定义了在 Scrape 回复中加入类型 <strong>downloaders</strong>，表示处于活跃状态，未完成下载且仍然需要继续下载的 peer 数量，Partial Seed 的数量可以通过 <code>incomplete - downloaders</code> 得到。同时让 Tracker 知晓 peer 自身处于 Partial Seed 状态，则需要通过 <code>event=paused</code> 事件进行告知，且每次通告时都要发送该事件。</p><h3 id="Peer-Exchange-ut-pex"><a href="#Peer-Exchange-ut-pex" class="headerlink" title="Peer Exchange(ut_pex)"></a>Peer Exchange(ut_pex)</h3><p>Peer Exchange(PEX) 用于在 peer 间交换 peer 列表。通过在 Extend Handshake 消息的 字典 m 中加入 <strong>ut_pex</strong> 这个消息名称来表明支持，同样道理，消息 id 在 m 字典中保持唯一即可。</p><p>PEX 消息的负载也是一个 bencode 字典，有如下的键：</p><ul><li><strong>added</strong>：当前连接的 IPv4 peer 压缩格式列表，告知对方进行添加</li><li><strong>added.f</strong>：当前连接的 IPv4 peer 标志位，每个 peer 一个字节</li><li><strong>added6</strong>：当前连接的 IPv6 peer 压缩格式列表，告知对方进行添加</li><li><strong>added6.f</strong>：当前连接的 IPv6 peer 压缩格式列表标志位</li><li><strong>dropped</strong>：过去断开连接的 IPv4 peer 压缩格式列表，告知对方进行删除</li><li><strong>dropped6</strong>：过去断开连接的 IPv6 peer 压缩格式列表，告知对方进行删除</li></ul><p>标志位定义如下：</p><ul><li>0x02：属于 seed 或者 partial seed</li><li>0x04：支持 uTP</li><li>0x01：prefers encryption, as indicated by e field in extension handshake</li><li>0x08：peer indicated ut_holepunch support in extension handshake</li><li>0x10：outgoing connection, peer is reachable</li></ul><h4 id="发送规则"><a href="#发送规则" class="headerlink" title="发送规则"></a>发送规则</h4><ul><li>如果 peer 与某些 peer 断开连接，则需要需要在适当时候发送 PEX 消息，将断开连接的 peer 放在 dropped 中；</li><li>每分钟发送的 PEX 消息不能超过一条；</li><li>不需要在握手后立即发送 PEX 消息，在收集满一定的 peer 之后再发送效果更好；</li><li>添加或删除的 peer 列表中不能包括重复项，也不能在同一个 PEX 消息中删除添加的 peer；</li><li>除了最初的 PEX 消息之外，每条消息中添加的 peer 数量或者 删除的 peer 数量均不能超过 50 条；</li><li>added, added6, dropped, dropped6 四个键中至少需要有一个；</li><li>peer 可能会与严重违反这些规则的 peer 断开连接；</li></ul><h4 id="扩充-seed"><a href="#扩充-seed" class="headerlink" title="扩充 seed"></a>扩充 seed</h4><p>每个 peer 会执行如下的执行一些规则来断开与部分 peer 的连接。比如</p><ol><li>在作种的时候会断开与 seed 和 partial seed 的连接；</li><li>根据 peer id 断开 IPv4 以及 IPv6 地址实际上属于同一个 peer 的一个连接，保留自己偏爱的地址家族连接；</li></ol><p>这样的策略下，在 seed 占主导地位的 swarm 中通过 PEX 传播的活跃 peer 会不足。类似地，在 IPv4 占主导的 swarm 中，只支持 IPv6 的 peer 将很难获得 IPv6 的 peer。这很大程度降低了 PEX 消息的有效性。</p><p>为了解决这些问题，如果一个 peer 连接到一个特定地址家族的 peer 少于25个，活跃度的要求就会放宽。因为一下原因导致连接断开的 peer 也会被保存下来，并有资格被发在 PEX 消息的 added 中：</p><ol><li>因为 peer id 相同而被断开的另一个地址家族的连接；</li><li>因缺乏兴趣而断开连接的 peer，比如对方是 seed/partial seed 或者对方拥有的分片不满足自己的需求；</li><li>因为超过本地资源限制而断开的连接，比如全局的连接上限；</li></ol><p>为了保证 peer 的有效性，因为这些原因添加到 added 中的 peer 只能通过 PEX 消息发送一次，发送完后必须从等待发送列表中删除。</p><h4 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h4><p>通过 PEX 获得的 peer 应该视为不可信的。攻击者可能通多伪造 PEX 消息来攻击这个 swarm。攻击者也可能通过 PEX 消息诱导 BT 客户端对特定 IP 进行尝试连接而引发 DDoS 攻击。</p><p>为了缓解这些问题，peer 应该避免从单个 PEX 源获取其所有连接作为候选连接。应忽略具有不同的端口的重复 IP，还可以根据 peer 的优先级来进行（协议概述中提到）排序。</p><h2 id="快速扩展（Fast-Extension）"><a href="#快速扩展（Fast-Extension）" class="headerlink" title="快速扩展（Fast Extension）"></a>快速扩展（Fast Extension）</h2><p>另外还有类似扩展消息的快速扩展消息，通过将握手消息的 <code>reserved_byte[7] |= 0x04</code> 来通告支持快速扩展，这里只列出快速扩展消息的种类，具体协议格式可参见 <a href="http://bittorrent.org/beps/bep_0006.html" target="_blank" rel="noopener">BEP06 - Fast Extension</a>。</p><ul><li><strong>Have All/Have None</strong>：来表示拥有所有分片或者未拥有任何分片，是 <strong>bitfield</strong> 消息的快速版本；</li><li><strong>Suggest Piece</strong>：建议其他 peer 下载某分片；</li><li><strong>Reject Request</strong>：拒绝 peer 对某个片段的请求；</li><li><strong>Allowed Fast</strong>：表示如果 peer 请求这个分片，即使它处于 choked 状态也会给它；</li><li><strong>lt Dont Have</strong>：在某些情况下（比如资源短缺，LRU Cache 过期）会导致 peer 不再拥有某个片段，则可以通过此消息告知其他 peer，该扩展定义在 <a href="http://bittorrent.org/beps/bep_0054.html" target="_blank" rel="noopener">BEP54 - The lt_donthave extension</a> 中；</li></ul><h2 id="分片选择策略"><a href="#分片选择策略" class="headerlink" title="分片选择策略"></a>分片选择策略</h2><p>选择一个好的分片下载顺序与否对下载性能有这很大影响。如果选择了一个差的分片下载选择算法，则某一时刻可能所有分片你都可以下载，但是之后就没有你想下载的分片了。BT 中执行一下策略：</p><h3 id="Strict-Priority（严格模式）"><a href="#Strict-Priority（严格模式）" class="headerlink" title="Strict Priority（严格模式）"></a>Strict Priority（严格模式）</h3><p>一旦请求了某个分片的子片段，那么就会在请求其他子片段之前请求该特定分片的剩余子片段，以尽量优先获得这个完整的分片。</p><h3 id="Rarest-First（稀有优先）"><a href="#Rarest-First（稀有优先）" class="headerlink" title="Rarest First（稀有优先）"></a>Rarest First（稀有优先）</h3><p>在选择接下来下载哪个分片时，peer 会选择最稀有的分片（自己没有这个分片，同时其他 peer 有，但是有这个分片的 peer 数量相对其他分片最少）进行下载。这个算法保证了不稀有的分片在之后仍然能被下载到，同时稀有的分片在逐渐变多。通过尽快复制最稀有的分片，减小了稀有分片在当前连接的 peer 中完全消失的可能性。</p><h3 id="Random-First-Piece（随机首分片）"><a href="#Random-First-Piece（随机首分片）" class="headerlink" title="Random First Piece（随机首分片）"></a>Random First Piece（随机首分片）</h3><p>当下载开始时，不会使用稀有优先算法。开始时 peer 没有分片可以用于上传，所以最重要的是尽快得到一个完整的分片。稀有的分片往往只被某一个 peer 拥有，从这个 peer 处下载这个分片（分成多个子片段）将会慢于从多个 peer 处下载相同分片的不同子片段。出于这个原因，刚开始下载时，会随机选择一个分片进行下载，随后策略转为稀有优先。</p><h3 id="Endgame-Mode"><a href="#Endgame-Mode" class="headerlink" title="Endgame Mode"></a>Endgame Mode</h3><p>有时从一个 peer 请求某个分片会很慢，这在下载整个资源你的中途不会是一个问题（因为中途同时发生不少请求），但是这种情况可能会影响最终的即将下载完成阶段。当所有剩余的子片段都已经在向其他 peer 请求时，它会同时向所有的 peer 请求这些子片段。当某一个 peer 返回了一个子片段，就向剩余的 peer 发送 cancel 消息以节约带宽。在实践过程中，Endgame 模式持续时间非常短，所以浪费的带宽不多，而且使得资源的最后一部分下载非常快。</p><h2 id="Choking-算法"><a href="#Choking-算法" class="headerlink" title="Choking 算法"></a>Choking 算法</h2><p>BT 没有中心化的资源分配，每个 peer 有责任去最大化自己的下载速率。Peer 执行一种变种 tit-fot-tat 策略，从与自己相连的 peer 处下载分片，并选择合适的 peer 进行上传，对其他 peer 进行 choke。choke 表现为拒绝上传，但下载仍可继续，同时连接被保持不销毁，在 choke 结束后连接不需要重建。Choking 算法对于 BT 来说不是必须的，但是如果需要有一个好的下载性能是非常重要的。一个好的 choking 算法需要利用好所有的资源，提供好的上传给其他 peer，同时惩罚那些只下载不上传的 peer。</p><p>BT 中使用的变种 tit-fot-tat 策略是囚徒困境的应用，博主 youxu 的文章 <a href="https://blog.youxu.info/2008/12/31/tit-for-tac-and-p2p-software/" target="_blank" rel="noopener">P2P客户端的策略和奇妙的对策论</a> 对这此有着很通俗易懂的解释。</p><p>对于某个 peer 的 Choking 算法 可以描述如下： </p><ol><li><strong>Choking Algorithm</strong>：每 T 时间选择合适的 k 个 peer 进行 unchoke，选择的标准为过去 S 时间 peer 的下载速率；</li><li><strong>Optimistic Unchoking</strong>：每 nT 时间，随机选择一个 peer 进行 unchoke，以尝试发现更优质的 peer；</li><li><strong>Anti-snubbing</strong>：如果 mT 时间内没有从某个 peer 处获取到一个分片，则认为被 <strong>snubbed</strong> 了，对其进行 choke；</li><li><strong>Upload Only</strong>：当一个 peer 下载完成了，即成为了一个 seed，则只进行上传，不再下载。peer 会选择那些该 peer 对其有较高上传速率的 peer 进行上传。</li></ol><p>实际实现中 T = 10s, k = 7, S = 20s, n = 3, m = 6。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://forum.utorrent.com/topic/90069-question-about-canonical-peer-priority/" target="_blank" rel="noopener">Question About Canonical Peer Priority</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
    
      <category term="BT" scheme="https://0ranga.com/tags/BT/"/>
    
  </entry>
  
  <entry>
    <title>BT 增强建议之 Tracker</title>
    <link href="https://0ranga.com/2018/08/27/bt-tracker/"/>
    <id>https://0ranga.com/2018/08/27/bt-tracker/</id>
    <published>2018-08-26T16:00:00.000Z</published>
    <updated>2020-07-18T07:11:02.021Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>本文是 BT 系列文章中的一篇，主要介绍种子文件结构与磁力链接的原理，有需要的话可以先阅读博文<a href="/2018/08/26/bt-overview/" title="BT 增强建议之概述">BT 增强建议之概述</a>。</p><p>p2p 是 peer-to-peer 的缩写，为了让网络中的一个 peer 如何才能找到另外志同道合的 peer，Tracker 扮演着至关重要的月老作用。Tracker 是一个 HTTP 或者 UDP 服务器，作用是帮助 peer 找到其他拥有相同资源的 peer。</p><p>后来有了 DHT 网络之后，Tracker 的作用逐渐弱化，但是 Tracker 代表的这种中心化一定程度上相对 DHT 代表的去中心化效率还是比较高的。如同在概述前言中所说的一样，”过时“的技术某些情况下是会“复活”的，所以了解一下 Tracker 的工作原理并不是坏事。</p><h2 id="HTTP-Tracker"><a href="#HTTP-Tracker" class="headerlink" title="HTTP Tracker"></a>HTTP Tracker</h2><p>HTTP Tracker 处理的来自 peer 的 GET 请求包括以下参数：</p><ul><li><strong>info_hash</strong>：即需要下载的资源的 torrent 文件的 info 部分的 SHA1 值，或者磁力链接中的 xt 值。</li><li><strong>peer_id</strong>：标示这个客户端的字符串，一般会包含客户端的版本信息以及随机数据（<a href="http://www.bittorrent.org/beps/bep_0020.html" target="_blank" rel="noopener">BEP20 - Peer ID Conventions</a>）。</li><li><strong>ip</strong>：可选，peer 的 IP。</li><li><strong>port</strong>：可选，peer 监听的端口，一般是 6881。理论上 Tracker 应该需要对这个 ip 和 port 的组合进行 NAT 检查。</li><li><strong>uploaded</strong>：该资源至今为止的上传字节数。</li><li><strong>downloaded</strong>：该资源至今为止的下载字节数。</li><li><strong>left</strong>：该资源剩余未完成下载的字节数。</li><li><strong>event</strong>：可选，当前资源下载状态，可以是<code>started</code>，<code>completed</code>，<code>stopped</code>，每次发生状态变化时进行通告。</li></ul><p>这个请求的回复是使用 bencode 编码的字典，有如下的键：</p><ul><li><strong>failure reason</strong>：字符串，如果请求失败就会有这个键，表示失败的原因，另外 <a href="http://www.bittorrent.org/beps/bep_0031.html" target="_blank" rel="noopener">BEP31 - Failure Retry Extension</a> 中定义了一个 <strong>retry in</strong> 字段来告知发起请求的 peer 重试间隔分钟数，或者永远不进行重试。如果成功就会有以下两个键。</li><li><strong>interval</strong>：整型，告知 peer 之后进行 GET 请求的时间间隔，但是如果 peer 的状态发生变化或者需要从 Tracker 获取更多的 peer 就会不管这个时间间隔限制而直接重新请求。</li><li><strong>peers</strong>：列表，每个子项都是字典，字典的键分别为 <strong>id</strong>，<strong>ip</strong>，<strong>port</strong>，分别与 GET 请求中的 peer_id，ip，port 含义一致，用于唯一确定每个其他 peer。</li></ul><p>在 HTTP Tracker 的 URL 上进行适当的改造可以得到 Scrape URL（在 <a href="http://www.bittorrent.org/beps/bep_0048.html" target="_blank" rel="noopener">BEP48 - Tracker Protocol Extension: Scrape</a> 中提出）。通过请求 Scrape URL 可以得到指定 info_hash 的当前 peers 的大致统计信息，包括处于活跃状态且已完成下载（<strong>complete</strong>）的 peer 数量、处于活跃状态但未完成下载（<strong>incomplete</strong>）的 peer 数量、曾经完成过下载（<strong>downloaded</strong>）的 peer 数量。支持同时请求多个 info_hash 。这些数据帮助 peer 决定是否应该执行 Tracker GET 请求，从而一定程度上减小 HTTP Tracker 服务器的压力。</p><p>而 UDP 本身比 HTTP 消耗更小些，且直接实现了 Scrape 请求。</p><h2 id="UDP-Tracker"><a href="#UDP-Tracker" class="headerlink" title="UDP Tracker"></a>UDP Tracker</h2><p>由于 HTTP 是基于 TCP 的，连接的打开和关闭会带来一定损耗。这种类似的发现服务使用 UDP 可以大大降低 Tracker 服务器的压力。<a href="http://www.bittorrent.org/beps/bep_0015.html" target="_blank" rel="noopener">BEP15 - UDP Tracker Protocol</a> 提出了基于 UDP 的 Tracker 方案。</p><p>为了防止 UDP Flood 攻击，peer 与 UDP Tracker 的通信会首先通过 <strong>connect</strong> 动作进行类似 TCP 的三次握手，约定一个 connection_id，之后所有的动作都会使用这个 connection_id。<strong>announce</strong> 动作可以向 UDP Tracker 完成类似对 HTTP Tracker 的 GET 请求。使用 <strong>scrape</strong> 动作完成类似对 HTTP Tracker 的 Scrape 请求。如果出现错误，Tracker 会触发 <strong>error</strong> 动作。</p><p>GET 请求如果需要扩展参数只需要在请求的 URL 中增加相关的参数即可，在 UDP Tracker 中，实现这种增加参数的可扩展性则需要另外想办法。<a href="http://www.bittorrent.org/beps/bep_0041.html" target="_blank" rel="noopener">BEP41 - UDP Tracker Protocol Extensions</a> 对于其实现方案举了一个这样的例子：一个 Tracker 服务器想要提高它的运行效率而限制其所能服务的 info_hash，他们考虑在在 peer 对 Tracker 的 URL 中加入一个 auth 字段，即该 info_hash 的签名，这样的情况下，Tracker 可以通过 Torrent 或者 Magnet 发布这个带有 info_hash 签名的 Tracker URL，peer 对该 Tracker 的请求时带上该签名，Tracker 就可以验证这个签名是否与 info_hash 相匹配以及这个 info_hash 是否在其服务的范围，从而实现限制。</p><p>比如 Tracker 在一个 Magnet 中附加的 tr 参数如下，auth 字段就是指的 info_hash 的示例签名：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">udp://tracker.example.com:80/?auth=0xA0B1C</span><br></pre></td></tr></table></figure><p>实现 BEP41 方案后的客户端在对 UDP Tracker 发起 <strong>announce</strong> 请求动作时，会在包体尾部添加如下字节：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0x2, 0xC, &apos;/&apos;, &apos;？&apos;, &apos;a&apos;, &apos;u&apos;, &apos;t&apos;, &apos;h&apos;, &apos;=&apos;, &apos;A&apos;, &apos;0&apos;, &apos;B&apos;, &apos;1&apos;, &apos;C&apos;, 0x1, 0x1, 0x0</span><br></pre></td></tr></table></figure><p><code>0x2</code> 表示附加的选项类型是 <strong>URLData</strong>，这个选项会紧跟着两个参数，<code>0xC</code> 表示后面的内容长度为 12，后续的 12 字节就是 URLData 的内容；<code>0x1</code> 表示附加的选项类型是 <strong>NOP</strong> ,即填充字节，连续两个 <code>0x1</code> 表示填充两个字节，<code>0x0</code> 表示附加的选项类型是 <strong>EndOfOptions</strong>，即结束标志。最后三个选项不是必须的，这里加入他们只是说明有这些选项。</p><p>当然这里例子在 HTTP Tracker 中也容易实现，但是 UDP Tracker 有着更好的网络优化。</p><h2 id="Tracker-相关增强方案"><a href="#Tracker-相关增强方案" class="headerlink" title="Tracker 相关增强方案"></a>Tracker 相关增强方案</h2><p>BEP 中还有不少改进提案是针对 Tracker 的：</p><h3 id="Torrent-文件多-Tracker-支持"><a href="#Torrent-文件多-Tracker-支持" class="headerlink" title="Torrent 文件多 Tracker 支持"></a>Torrent 文件多 Tracker 支持</h3><p>Torrent 文件中 <strong>announce</strong> 字段只支持定义一个 Tracker，<a href="http://www.bittorrent.org/beps/bep_0012.html" target="_blank" rel="noopener">BEP12 - Multitracker Metadata Extension</a> 中提出了让 Torrent 携带多个 Tracker 的方案。<br>在 Torrent 文件根节点增加一个键 <strong>announce-list</strong>，这里简易的表示为 <strong>/announce-list</strong>，之后在 Torrent 中增加键时也会简易地表示成这样。如果 Torrent 文件中有 <strong>announce-list</strong>，则会忽略 <strong>announce</strong>。<strong>announce-list</strong> 是一个列表，**<em>列表的每个子项是都是一个子项是 Tracker URL 的列表**</em>。之所以是一个子项为列表的列表的原因在 BEP12 中有详细的介绍与举例。此处不详细展开。</p><h3 id="DNS-辅助纠正-Tracker-地址"><a href="#DNS-辅助纠正-Tracker-地址" class="headerlink" title="DNS 辅助纠正 Tracker 地址"></a>DNS 辅助纠正 Tracker 地址</h3><p>考虑到部分种子中的 Tracker 服务器可能变更服务端口或者讲 HTTP 服务改为 UDP 服务。<a href="http://www.bittorrent.org/beps/bep_0034.html" target="_blank" rel="noopener">BEP34 - DNS Tracker Preferences</a> 一种基于 DNS 的解决方案。<br>如果客户端发现自己所请求的 Tracker 没有相应，则可以查询相应域名的 DNS TXT 记录。如果有 TXT 记录是以 ”BITTORRENT“ 开头，则可以对这个 Tracker 地址进行纠正。这类 TXT 记录有以下几种类型：</p><ul><li>“BITTORRENT”：表明该主机不再运行任何 Tracker 服务。</li><li>“BITTORRENT DENY ALL”：和前一个一致，但是表意更加明显。</li><li>“BITTORRENT UDP:1337 TCP:80”：表示这个主机运行两个 Tracker 服务，分别时在 UDP 端口 1337 和 TCP 端口 80 上，且优先建议使用 UDP 端口。</li></ul><p>以下是一个相关的 TXT 记录查询过程，这个主机在多个 UDP 端口上运行了 Tracker 服务：</p><figure class="highlight shell"><figcaption><span>dig txt</span><a href="/downloads/code/bt_dig_dns_txt.txt">view raw</a></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> dig 9.rarbg.to txt</span></span><br><span class="line">;; QUESTION SECTION:</span><br><span class="line">;9.rarbg.to.                    IN      TXT</span><br><span class="line"></span><br><span class="line">;; ANSWER SECTION:</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     "BITTORRENT UDP:2710"</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     "BITTORRENT UDP:2720"</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     "BITTORRENT UDP:2730"</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     "BITTORRENT UDP:2740"</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     "BITTORRENT UDP:2750"</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     "BITTORRENT UDP:2770"</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     "BITTORRENT UDP:2780"</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     "BITTORRENT UDP:2790"</span><br><span class="line">9.rarbg.to.             5134    IN      TXT     "BITTORRENT UDP:2800"</span><br><span class="line"></span><br><span class="line">;; Query time: 207 msec</span><br><span class="line">;; SERVER: 1.1.1.1#53(1.1.1.1)</span><br><span class="line">;; WHEN: Sat Aug 25 05:46:02 CST 2018</span><br><span class="line">;; MSG SIZE  rcvd: 327</span><br></pre></td></tr></table></figure><h3 id="Tracker-返回公网-IP"><a href="#Tracker-返回公网-IP" class="headerlink" title="Tracker 返回公网 IP"></a>Tracker 返回公网 IP</h3><p><a href="http://www.bittorrent.org/beps/bep_0024.html" target="_blank" rel="noopener">BEP24 - Tracker Returns External IP</a> 通过在 GET 请求的返回中（UDP 也适用，下同）增加一个 <strong>external ip</strong> 字段来告知发起请求的 peer 自身的公网 IP。[Todo:客户端需要知道自己的公网 IP 做什么用暂时还不太清楚……ff]<br>通过 peer 间的 yourip 扩展消息也可以获得自身的公网 IP。</p><h3 id="Tracker-返回压缩-peer-列表"><a href="#Tracker-返回压缩-peer-列表" class="headerlink" title="Tracker 返回压缩 peer 列表"></a>Tracker 返回压缩 peer 列表</h3><p><a href="http://www.bittorrent.org/beps/bep_0023.html" target="_blank" rel="noopener">BEP23 - Tracker Returns Compact Peer Lists</a> 提出了一种压缩 GET 请求返回中 peers 字段值的方式以在一定程度上减小 Tracker 服务器的流量压力。<br>这种方案的返回值中 peers 字段不再是一个列表，而是一个字符串，它由代表每个 peer 的六个字节（4 个字节用于 IP 地址，2 个字节用于端口）拼接而成。去除了 peer_id 这个字段，事实证明没有这个字段也没什么关系。<br>Peer 通过在 GET 请求中增加 <strong>compact</strong> 参数来告知 Tracker 服务器自己更喜欢什么格式，0 为原始格式，1 为压缩格式。但是 Tracker 不一定会接受这个参数的建议，所以客户端仍然需要同时支持两种格式。</p><h3 id="IPv6-支持"><a href="#IPv6-支持" class="headerlink" title="IPv6 支持"></a>IPv6 支持</h3><p><a href="http://www.bittorrent.org/beps/bep_0007.html" target="_blank" rel="noopener">BEP7 - IPv6 Tracker Extension</a> 提供了优化 Tracker 对 IPv6 支持的方案。<br>通过在 GET 请求中增加 <strong>ipv6</strong> 参数或者 <strong>ipv4</strong> 参数来告知 Tracker 服务器自己的相应 IP 版本的地址，如果在这两个字段中没有端口信息，那么将 <strong>port</strong> 字段作为端口。如果 Tracker compact 格式返回 peer 列表，那么它会在回复中增加 <strong>peers6</strong> 字段以返回使用 IPv6 的 peer，每个 peer 占用 18 字节。编码方式与 peers 字段一致。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2>]]></content>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
    
      <category term="BT" scheme="https://0ranga.com/tags/BT/"/>
    
  </entry>
  
  <entry>
    <title>BT 增强建议之 Metadata：Torrent 与 Magnet</title>
    <link href="https://0ranga.com/2018/08/26/bt-metadata/"/>
    <id>https://0ranga.com/2018/08/26/bt-metadata/</id>
    <published>2018-08-26T14:00:00.000Z</published>
    <updated>2020-07-18T07:11:02.020Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>本文是 BT 系列文章中的一篇，主要介绍 Tracker 服务器的工作原理，有需要的话可以先阅读博文<a href="/2018/08/26/bt-overview/" title="BT 增强建议之概述">BT 增强建议之概述</a>。</p><p>在磁力链接出现前，BT 下载的第一步就是获取 Torrent（种子）文件。种子文件中包含了资源的最关键信息 —— Metadata（元数据）。Magnet（磁力链接）的引入则省去了获取种子文件这一步，但是仍然需要元数据，只是改为从 peer 处获取。有了元数据后，才能知道整个资源的概况，继而进行下载。</p><h2 id="Torrent"><a href="#Torrent" class="headerlink" title="Torrent"></a>Torrent</h2><h3 id="文件结构"><a href="#文件结构" class="headerlink" title="文件结构"></a>文件结构</h3><p>种子文件使用 bencode 进行编码，整个文件是一个字典。有下列主要的 key（value 中，整型值的单位均为字节，字符串默认使用 UTF-8 编码）：</p><ul><li><strong>announce</strong>：字符串。tracker 的 URL 地址，仅能定义一个 Tracker。</li><li><strong>info</strong>：字典。也就是资源的元数据：<ul><li><strong>length</strong>：整型。如果有该字段，则代表种子为单文件种子，代表该文件的大小。</li><li><strong>files</strong>：列表，子项类型为字典。如果有该字段，则代表种子为多文件种子。一个种子只能为单文件种子或者多文件种子，因此 <strong>files 字段和上述 length 字段只能选其中之一</strong>。files 字典的字段包括：<ul><li><strong>length</strong>：整型。代表该文件的大小。</li><li><strong>path</strong>：列表，子项类型为字符串。子目录名称列表，最后一项为文件名，因此该列表长度至少需要为 1。</li></ul></li><li><strong>name</strong>：字符串。如果是单个文件的种子，那么这个字段表示该文件的文件名，否则表示多个文件存储的根目录。</li><li><strong>piece length</strong>：整型。为了方便传输与节点间交换数据，文件被分片，这个字段代表每个片段的大小，除了最后一片可能会被截断，这个值一般为 2 的幂次。</li><li><strong>pieces</strong>：被编码成字符串，但是需要被解析成 SHA1 值。代表所有片段的 SHA1 值（每个值占用 160 比特）。</li></ul></li></ul><h3 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h3><h4 id="单文件种子"><a href="#单文件种子" class="headerlink" title="单文件种子"></a>单文件种子</h4><p>这是一个单文件种子文件的 JSON 化结构示意，文件 debian-503-amd64-CD-1.iso 被分成大小为 256 KiB 的 $\left(\lceil\frac{length}{piece length}\rceil = 2588\right)$ 片。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"announce"</span>: <span class="string">"http://bttracker.debian.org:6969/announce"</span>,</span><br><span class="line">    <span class="attr">"info"</span>:</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">"name"</span>: <span class="string">"debian-503-amd64-CD-1.iso"</span>,</span><br><span class="line">        <span class="attr">"piece length"</span>: <span class="number">262144</span>,</span><br><span class="line">        <span class="attr">"length"</span>: <span class="number">678301696</span>,</span><br><span class="line">        <span class="attr">"pieces"</span>: &lt;binary SHA1 hashes&gt;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="多文件种子"><a href="#多文件种子" class="headerlink" title="多文件种子"></a>多文件种子</h4><p>这个一个包含两个文件的种子的示例。相对于单文件种子，它使用了 files 字段取代了 length 字段。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"announce"</span>: <span class="string">"http://tracker.site1.com/announce"</span>,</span><br><span class="line">    <span class="attr">"info"</span>:</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">"name"</span>: <span class="string">"directoryName"</span>,</span><br><span class="line">        <span class="attr">"piece length"</span>: <span class="number">262144</span>,</span><br><span class="line">        <span class="attr">"files"</span>:</span><br><span class="line">        [</span><br><span class="line">            &#123;<span class="attr">"path"</span>: [<span class="string">"111.txt"</span>], <span class="attr">"length"</span>: <span class="number">111</span>&#125;,</span><br><span class="line">            &#123;<span class="attr">"path"</span>: [<span class="string">"222.txt"</span>], <span class="attr">"length"</span>: <span class="number">222</span>&#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="attr">"pieces"</span>: &lt;binary SHA1 hashes&gt;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Magnet"><a href="#Magnet" class="headerlink" title="Magnet"></a>Magnet</h2><h3 id="MAGNET-URI-Project"><a href="#MAGNET-URI-Project" class="headerlink" title="MAGNET-URI Project"></a>MAGNET-URI Project</h3><p>提到 Magnet（磁力链接）大家都会想到 BT，但是磁力链接不是因为 BT 而诞生的，也不止用于 BT，事实上磁力链接的来自 <a href="http://magnet-uri.sourceforge.net/" target="_blank" rel="noopener">MAGNET-URI Project</a> 这个项目：</p><blockquote><p>MAGNET is a work-in-progress URI specification, and collection of standard practices/implementing code to allow a website to seamlessly integrate with features made available by local utility programs. In one way, it could be thought of as a vendor- and project-neutral generalization of the “freenet:” and “ed2k:” URI-schemes used by the Freenet and EDonkey2000 peer-to-peer networks, respectively.</p><footer><strong>Gordon Mohr</strong><cite><a href="http://magnet-uri.sourceforge.net/magnet-draft-overview.txt" target="_blank" rel="noopener">magnet-uri.sourceforge.net/magnet-draft-overview.txt</a></cite></footer></blockquote><p>磁力链接是一个统一的规范，它希望这种 p2p 的链接都可以以按照这个规范展示，这样的话当用户在网页上点击磁力链接的时候，就可以磁力链接的参数（<code>xt</code>，下文会提及）“召唤”合适的客户端。它先被 eDonkey（电驴）推动，电驴链接理论上可以被转换成磁力链接。转换过程大致如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ed2k://|file|&lt;name&gt;|&lt;file-size&gt;|&lt;ed2k-hash&gt;|/</span><br><span class="line">magnet:?xt=urn:ed2k:&lt;ed2k-hash&gt;&amp;xl=&lt;file-size&gt;&amp;dn=&lt;name&gt;</span><br></pre></td></tr></table></figure><p>然而，这个 MAGNET-URI Project 后来应该没有被推动下去，导致甚至连电驴自己的客户端都没有支持 ed2k 的 magnet 格式。直到后来在 BT 中大放异彩，导致现在狭义上的磁力链接就是指 BT 中使用的磁力链接。</p><h3 id="BT-中的磁力链接"><a href="#BT-中的磁力链接" class="headerlink" title="BT 中的磁力链接"></a>BT 中的磁力链接</h3><p>BT 中的磁力链接大概有这两种格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">v1: magnet:?xt=urn:btih:&lt;info-hash&gt;&amp;dn=&lt;name&gt;&amp;tr=&lt;tracker-url&gt;&amp;x.pe=&lt;peer-address&gt;</span><br><span class="line">v2: magnet:?xt=urn:btmh:&lt;tagged-info-hash&gt;&amp;dn=&lt;name&gt;&amp;tr=&lt;tracker-url&gt;&amp;x.pe=&lt;peer-address&gt;</span><br></pre></td></tr></table></figure><p>根据 <a href="https://zh.wikipedia.org/wiki/%E7%BB%9F%E4%B8%80%E8%B5%84%E6%BA%90%E5%AE%9A%E4%BD%8D%E7%AC%A6" target="_blank" rel="noopener">URL 的定义</a>，<code>magnet</code> 前缀表示这个链接是磁力链接，<code>？</code> 后表示为 GET 模式查询参数列表，参数使用 <code>&amp;</code> 符号隔开。BT 磁力链接的参数如下:</p><ul><li><strong>xt</strong>：表示包含文件散列函数值的 URN，这是唯一一个必选参数，可能的 URN 类型有：<ul><li><strong>btih</strong>：表示 Torrent 文件 info 部分的 SHA1 值，可以是 Hex 编码或者 Base32 编码形式。</li><li><strong>btmh</strong>：表示 Torrent 文件 info 部分的 HEX 编码 <a href="https://github.com/multiformats/multihash" target="_blank" rel="noopener">multihash</a> 值，multihash 是由创造 IPFS  的 Protocal Lab 的项目，用于编码多种 hash 函数的 hash 结果。<strong>btmh 可以和 btih 同时存在，这个应该和 <a href="https://security.googleblog.com/2017/02/announcing-first-sha1-collision.html" target="_blank" rel="noopener">SHA1 被破解</a>相关——有 btmh 中使用其他 hash 函数得到的 hash 值加上原来的 SHA1 值就可以做到兼容，同时检测碰撞。</strong></li></ul></li><li><strong>dn</strong>：表示建议显示的文件名。</li><li><strong>tr</strong>：表示 Tracker的 URL，如果有多个 Tracker,则会有多个 <code>tr</code> 参数。</li><li><strong>x.pe</strong>：表示 Peer 的，格式为 <code>hostname:port</code>，<code>ipv4-literal:port</code> 或者 <code>[ipv6-literal]:port</code>，这些 peer 可以被添加到 peer 列表中用于获取元数据以及后续的文件片段获取。实际上 Magnet 链接中定义了一个通用的参数 <code>xt</code> 用于指定类似 <code>x.pe</code> 所表示的 p2p 连接，但是由于没有合适的 URI 标识符分配给 BT（比如电驴有 ed2k），所以 BT 使用了这个参数，而不是 <code>xt</code>。</li><li><strong>so</strong>：定义在 <a href="http://www.bittorrent.org/beps/bep_0053.html" target="_blank" rel="noopener">BEP53 - Magnet URI extension - Select specific file indices for download</a> 中，用于指定下载特定文件，比如 <code>so=0,2,4,6-8</code> 表示下载 files 列表中索引为 0,2,4,6,7,8 的这六个文件。</li></ul><p>有了磁力链接，客户端就可以向 peer 请求 Torrent 文件的 info 部分了，获取完成后就相当于拥有了 Torrent 文件，也就是有了完整的元数据，继而可以下载资源。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://en.wikipedia.org/wiki/Torrent_file#Draft_extensions" target="_blank" rel="noopener">Wikipedia - Torrent file</a></li><li><a href="http://marquisdegeek.com/code_bencode.php" target="_blank" rel="noopener">Online Torrent File Decoder</a></li><li><a href="http://magnet2torrent.me/" target="_blank" rel="noopener">Online Magnet Link to Torrent File converter</a></li><li><a href="https://en.wikipedia.org/wiki/Magnet_URI_scheme" target="_blank" rel="noopener">Wikipedia - Magnet URI scheme</a></li><li><a href="https://stackoverflow.com/questions/4913343/what-is-the-difference-between-uri-url-and-urn" target="_blank" rel="noopener">Stack Overflow - What is the difference between URI, URL and URN?</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
    
      <category term="BT" scheme="https://0ranga.com/tags/BT/"/>
    
  </entry>
  
  <entry>
    <title>BT 增强建议之概述</title>
    <link href="https://0ranga.com/2018/08/26/bt-overview/"/>
    <id>https://0ranga.com/2018/08/26/bt-overview/</id>
    <published>2018-08-26T09:00:00.000Z</published>
    <updated>2020-07-18T07:11:02.020Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>在版权意识愈渐加强的今天，BT 流量占全球流量的比重不断下降，这种 p2p 技术的应用在<a href="http://www.donews.com/article/detail/4805/11133.html" target="_blank" rel="noopener">逐渐衰落</a>。但是请记住</p><ul><li>“技术无罪”——纵然据说爱因斯坦也曾对“把原子弹送到了疯子手里”感到后悔。</li><li>“个体重复系统发育”：<blockquote><p>技术的变化会导致某些思想过时并迅速消失，这种情形经常发生。但是，技术的另一种变化还可能使某些思想再次复活。</p><footer><strong>Andrew Tanenbaum</strong><cite>现代操作系统</cite></footer></blockquote></li></ul><h2 id="总目录"><a href="#总目录" class="headerlink" title="总目录"></a>总目录</h2><p>下面进入正题。一个使用 BT 进行下载的过程可以简短地描述如下：</p><p>当你获取了一个<strong>磁力链接</strong>或者<strong>种子文件</strong>，使用 BT 客户端打开文件确认下载后，客户端就成为了一个 peer，客户端通过连接 <strong>Tracker</strong> 服务器或者 <strong>DHT</strong> 网络寻找到其他拥有所需要文件分片的 peer，从这些 peer 中下载资源分片，同时客户端也上传数据给其他来索要自己所拥有分片的 peer，以此反复，直到下载完成。</p><p>搞清楚这个下载过程中到底发生了什么事情就是记录这个系列文章的目的所在。整个学习过程以 BT 增强建议 <a href="http://www.bittorrent.org/beps/bep_0000.html" target="_blank" rel="noopener">BEP</a> 为主要参考，同时适当参考 <a href="https://github.com/atomashpolskiy/bt" target="_blank" rel="noopener">BT 的一个 Java 版本实现源码</a>。</p><p>整个系列分为：</p><ul><li><a href="/2018/08/26/bt-overview/" title="BT 增强建议之概述">BT 增强建议之概述</a>：主要介绍 BEP 与 Bencode 编码</li><li><a href="/2018/08/26/bt-metadata/" title="BT 增强建议之 Metadata：Torrent 与 Magnet">BT 增强建议之 Metadata：Torrent 与 Magnet</a>：Torrent 种子文件结构与 Magnet 磁力链接的原理</li><li><a href="/2018/08/27/bt-tracker/" title="BT 增强建议之 Tracker">BT 增强建议之 Tracker</a>：作为 Peer 间桥梁的 Tracker 服务器的工作原理</li><li><a href="/2018/08/30/bt-peer/" title="BT 增强建议之 Peer">BT 增强建议之 Peer</a>： Peer 间的通信的过程以及以牙还牙策略</li><li>DHT：使得 BT 网络脱离 Tracker，实现完全去中心化<ul><li><a href="/2018/11/08/dht-kademlia/" title="DHT 网络之 Kademlia 算法">DHT 网络之 Kademlia 算法</a></li><li><a href="/2018/11/12/bt-dht/" title="BT 增强建议之 DHT">BT 增强建议之 DHT</a></li></ul></li><li><a href="/2018/11/15/bt-advanced/" title="BT 增强建议之进阶改进方案">BT 增强建议之进阶改进方案</a>：BEP 中提出的一些进阶改进方案</li></ul><p>用于保证 BT 高速下载时其他应用低时延网络通信的传输层协议 <strong>µTP</strong> 已在独立的博文 <a href="/2018/08/04/µtp/" title="µTP 协议 —— 对 BEP29 的简要理解">µTP 协议 —— 对 BEP29 的简要理解</a> 中介绍。</p><p>这个系列将尽可能涵盖所有的 BEP。下面的表格显示了章节与 BEP 的引用关系，因此在每篇文章的参考资料中将不在列举相关 BEP。</p><h2 id="BEP"><a href="#BEP" class="headerlink" title="BEP"></a>BEP</h2><p>BEP（BitTorrent Enhancement Proposal）是 BitTorrent 社区仿照 PEP（Python Enhancement Proposal）来改进 BitTorrent 的技术文档，可以视为一种开发方式。一个<a href="http://www.bittorrent.org/beps/bep_0002.html" target="_blank" rel="noopener">规范</a>的 BEP 被提出后可能经历如下的几个过程，但是目前只有 Final，Accepted，Draft，Deferred 四种状态的 BEP。<br><img src="bep_possible_paths.png" alt="BEP 可能经历的过程"><br>同时 Bittorrent 和 Python 还有个相似的共同点，他们的最初设计者都<strong>曾经</strong>是自己项目的终身仁慈独裁者（Benevolent Dictator For Life，<a href="https://en.wikipedia.org/wiki/Benevolent_dictator_for_life" target="_blank" rel="noopener">BDFL</a>）。例如 <a href="http://www.bittorrent.org/beps/bep_0000.html" target="_blank" rel="noopener">BEP1000 - Pending Standards Track Documents</a> 中所说的这个不存在的 BEP13 - Protocol Encryption 一直没能成为正式的 BEP 的原因就和 BitTorrent 的作者 Bram Cohen 反对 BT 流量加密相关。</p><ul><li>2018年7月，Guido van Rossum 宣布不再担任 Python 社区的 BDFL。</li><li>2018年8月，在自己一手创办的公司被波场收购后，Bram Cohen 表示自己已经离开了 Bittorrent，<a href="https://chia.net/" target="_blank" rel="noopener">目前在做数字货币相关的工作</a>。</li></ul><h2 id="Bencode"><a href="#Bencode" class="headerlink" title="Bencode"></a>Bencode</h2><p>bencode 是 BT 协议在传输数据过程中广泛采用的一种编码格式。主要支持以下四种数据类型的编码：</p><ul><li><strong>String</strong>：十进制字符串占用字节数 + ‘:’ + 字符串。例如 “spam”会被编码成“4:spam”</li><li><strong>Integer</strong>：’i’ + 十进制整形数字 + ‘e’。除 0 之外，不能以 0 开头。例如：i3e、i-3e</li><li><strong>List</strong>：使用字符 ‘l’ 和 ‘e’ 进行界定，中间是其他元素。例如 <em>l4:spami:-42ee</em> 代表列表 <em>[spam, -42]</em></li><li><strong>Dictionary</strong>：使用字符 ‘d’ 和 ‘e’ 进行界定，中间是每个键值对元素,而且所有键为字符串类型并按字典顺序排列。例如 <em>d3:cow3:moo4:spam4:eggse</em> 代表字典 <em>{cow: moo, spam: eggs}</em></li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://github.com/bittorrent/bittorrent.org" target="_blank" rel="noopener">BEP 的 Github 地址</a></li><li><a href="https://en.wikipedia.org/wiki/BitTorrent_protocol_encryption" target="_blank" rel="noopener">Wikipedia - BitTorrent protocol encryption</a></li><li><a href="http://cdmd.cnki.com.cn/Article/CDMD-10614-2010234919.htm" target="_blank" rel="noopener">BT流量识别技术的研究</a></li><li><a href="http://pcedu.pconline.com.cn/960/9603584_all.html" target="_blank" rel="noopener">谈eD2k和电驴的兴衰</a></li><li><a href="https://tech.slashdot.org/story/18/08/20/0457247/bittorrent-founder-bram-cohen-has-left-the-company" target="_blank" rel="noopener">Slashdot - BitTorrent Founder Bram Cohen Has Left the Company</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
    
      <category term="BT" scheme="https://0ranga.com/tags/BT/"/>
    
  </entry>
  
  <entry>
    <title>µTP 协议 —— 对 BEP29 的简要理解</title>
    <link href="https://0ranga.com/2018/08/04/%C2%B5tp/"/>
    <id>https://0ranga.com/2018/08/04/µtp/</id>
    <published>2018-08-04T09:05:00.000Z</published>
    <updated>2020-07-18T07:11:02.033Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>在 <a href="/2018/07/20/tcp/" title="TCP 温故知新">TCP 温故知新</a>中回顾了 TCP，而这篇文章主要讲用于 BT 网络的基于 UDP 的运输层协议 µTP，同时顺便回顾 UDP。下面的内容更多是基于对 <a href="http://www.bittorrent.org/beps/bep_0029.html" target="_blank" rel="noopener">BEP29</a> 的理解。</p><h2 id="名字探究"><a href="#名字探究" class="headerlink" title="名字探究"></a>名字探究</h2><p>  µTP 的主要文档 BEP29 的创建于 2009 年，姑且认为这也是设计完成的大致时间，µTP 在 uTorrent 的 1.8 中首次加入（2009 年）这个事实也佐证了这点。它的设计者包括：</p><ul><li><a href="https://en.wikipedia.org/wiki/Ludvig_Strigeus" target="_blank" rel="noopener">Ludvig Strigeus</a>（μTorrent 作者，BitTorrent 公司 2006 年收购 μTorrent，目前在 Spotify 工作）</li><li>Greg Hazel</li><li><a href="https://www.linkedin.com/in/shalunov" target="_blank" rel="noopener">Stanislav Shalunov</a>（µTP 中的拥塞算法 <a href="https://tools.ietf.org/html/rfc6817" target="_blank" rel="noopener">LEDBAT</a> 主要作者，后来还创造了可以脱离现有蜂窝网络使用的 IM 应用 <a href="https://www.opengarden.com/firechat.html" target="_blank" rel="noopener">FireChat</a> —— 它被多次用到”占中”这样的公民运动中）</li><li>Arvid Norberg（libtorrent 开发者，目前在 <a href="https://blockstream.com/" target="_blank" rel="noopener">Blockstream</a> 工作）</li><li>Bram Cohen（BitTorrent 作者）</li></ul><h2 id="设计原因"><a href="#设计原因" class="headerlink" title="设计原因"></a>设计原因</h2><p>  在过去多年前，如果使用 BT 进行下载热门资源的话可以感受到到速度飞快，但是同时带来的问题就是如果想要同时看在线视频就会带来卡顿。问题在于 DSL 和 modem 的往往有一个和它们的发送速率不成比例的发送缓冲区，不成比例到可以容纳几秒钟的数据量。而 BT 往往会与许多 peer 建立 TCP 连接，在 TCP 将带宽均匀地分配到每个连接的前提下，BT 就占用了较多的带宽，但是其他诸如浏览网页、即时通讯这些场景的优先级实际上应该要比 BT 传输更高些，但是因为 BT 和 物理层的这种特性导致了其他服务有延迟，影响了使用 BT 时其他服务的体验。<br>  µTP 通过将 modem 的缓冲队列的大小作为一个控制因子来调整发送速率，当队列过大时，将会放慢发送速度。这种策略使得 BT 在没有竞争的情况下可以充分利用上传带宽，在有大量其他流量的情况下则放慢发送速率。<br>  上述时 Bittorrent 文档中的说法，但是实际上 µTP 是基于包的延时的，而不是基于队列大小的。而且 µTP 具体对拥塞算法 LEDBAT 的实现有与在 IETF 互联网草案 <a href="https://tools.ietf.org/html/rfc6817" target="_blank" rel="noopener">RFC 6817</a> 中的描述有所区别（这里的实现指 C++ 版本的 <a href="https://github.com/bittorrent/libutp" target="_blank" rel="noopener">libutp</a>，各个版本的实现不完全一致）。</p><h2 id="UDP-和-µTP-首部"><a href="#UDP-和-µTP-首部" class="headerlink" title="UDP 和 µTP 首部"></a>UDP 和 µTP 首部</h2><p>  为了方便与 TCP 做简单的对比，把 UDP 的首部（前四个字节）与 µTP 的首部（剩余部分）放在了一个图中示意。从 UDP 首部字段数量皆可以发现 UDP 协议相对 TCP 协议是如此简单，以至于我们w可以将 TCP 协议看成是类似 µTP 协议一样的基于 UDP 协议的运输层协议。<br><img src="udp_utp_header.png" alt="UDP Header And µTP Header"></p><h3 id="UDP-首部"><a href="#UDP-首部" class="headerlink" title="UDP 首部"></a>UDP 首部</h3><ul><li><strong>源 / 目端口（Source / Destination port）</strong>：用于确认通信进程双方。源端口是可选的，如果设置了源端口，则接收方将其视为回复端口。如果不需要回复就不需要设置；</li><li><strong>总长度（Length）</strong>：定义了 UDP 用户数据报的总长度，包括首部和数据。TCP 首部中是没有所谓“报文段总长度”的字段的，长度可以通过 IP 层的长度减去 IP 首部长度计算所得，所以一定程度上时冗余的，可以参考 Stack OverFlow 上的<a href="https://stackoverflow.com/a/16748680/5091903" target="_blank" rel="noopener">相关讨论</a>；</li><li><strong>校验和（Checksum）</strong>：用于对整个用户数据报的校验，通过 IP 位首部与和用户数据报计算得到；</li></ul><p>可见 UDP 首部的这些字段在理论上可以是 TCP 首部字段的子集。因此我们可以粗略地讲 <strong>TCP 是基于 UDP 的传输层协议。</strong><br>UDP 服务是一个“尽力而为”的服务，它<strong>没有流量控制</strong>，<strong>只能通过校验和进行差错控制，丢包不会知晓，也不会重传</strong>，也<strong>没有拥塞控制</strong>。</p><h3 id="µTP-首部"><a href="#µTP-首部" class="headerlink" title="µTP 首部"></a>µTP 首部</h3><ul><li><strong>version</strong>：版本号，现在为 1，<a href="https://github.com/boundary/wireshark/blob/master/epan/dissectors/packet-bt-utp.c" target="_blank" rel="noopener">还有一个原始版本号 0 存在</a></li><li><strong>connection_id</strong>：用于标记连接。<a href="http://www.calvinneo.com/2017/12/05/libutp%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/#utp-context%E7%9A%84%E6%88%90%E5%91%98" target="_blank" rel="noopener">这个字段是必须的么?</a>；</li><li><strong>timestamp_microseconds</strong>：发送数据包的时间，和计算延迟时间，rtt 相关；</li><li><strong>timestamp_difference_microseconds</strong>：当前时间和上一次收到的包中的 timestamp_microseconds 之差；</li><li><strong>wnd_size</strong>：表示另一端建议的窗口大小，相当于 TCP 中的接收窗口；</li><li><strong>extension</strong>：代表第一个扩展的类型，0 表示没有扩展，1 表示 Selective ACKs（选择确认扩展）。</li><li><strong>type</strong>：数据包的类型。可以有：<ul><li>ST_DATA  = 0：承载有效数据的数据包；</li><li>ST_FIN   = 1：终止连接。是通信单方发送的最后一个包，类似于 TCP 的 FIN 标记。但是发送 ST_FIN 的一方还是会等待可能丢失或者失序到达的包，即使收到了对方的 ST_FIN 包；</li><li>ST_STATE = 2：用于报告状态，传输一个没有数据的 ACK。和 TCP 中未携带数据的 ACK 包一样，它不消耗序号；</li><li>ST_RESET = 3：强制重置连接。类似 TCP 的 RST 标记。</li><li>ST_SYN   = 4：发起连接。类似 TCP 的 SYN 标记。发起方会随机一个 connection_id ID 用于给接收方后续的回复使用。然后发起方之后的包中传输的 connection_id 为 ID + 1；</li></ul></li><li><strong>seq_nr</strong>：表示这个数据包的序号。注意和 TCP 中代表字号号的序号有所不同。初始序号同样也是随机生成。</li><li><strong>ack_nr</strong>：表示最后收到的数据包的seq_nr；</li></ul><h2 id="连接过程"><a href="#连接过程" class="headerlink" title="连接过程"></a>连接过程</h2><p>  图示为一次在 qBittorrent 中对一个种子开始 BT 下载二十秒左右后停止下载时，与其中一个 peer 的交互过程。<br><img src="wireshark.png" alt="连接过程（以 connection_id 为 8671 和 8672 的这一个过程为例）"></p><h2 id="丢包"><a href="#丢包" class="headerlink" title="丢包"></a>丢包</h2><p>和丢包处理有一个和窗口相关的变量需要先进行说明：</p><ul><li><strong><em>max_window</em></strong>：定义了未被确认的字节的上限，相当与 TCP 中的拥塞窗口；</li><li><strong><em>wnd_size</em></strong>：同首部中的 wnd_size，和 TCP 中相同，实际的发送窗口大小为 <code>min(max_windows, wnd_size)</code>；</li><li><strong><em>cur_window</em></strong>：表示当前未被确认的字节的数量；</li></ul><p>当需要发送数据包时，仅当 <code>cur_window + packet_size &lt;= min(max_windows, wnd_size)</code> 成立，这个数据包才能被发送。</p><ul><li>当序号为 <code>seq_nr - cur_window</code> 的数据包（发送队列中年龄最大的未被确认的数据包，下一个理论上需要被确认的就是它）没有被确认，但是已经有至少三个序号大于它的数据包通过 Selective ACK 被确认，那么这个数据包被认为是丢失了。</li><li>如果 <code>ack_nr + 1</code> 这个包已经发送了，而收到三个重复的 <code>ack_nr</code> 的 ACK，那么 <code>ack_nr + 1</code>这个包被认为是丢失了。</li></ul><p>如果检测到丢包，那么拥塞窗口 <strong>max_window</strong> 大小减半。</p><h2 id="超时"><a href="#超时" class="headerlink" title="超时"></a>超时</h2><p>µTP 的超时计时和 TCP 中 RTO 计时器不太一样，RTO 计时器主要用于对 ACK 的计时，但是　µTP 的计时器则是指接收任何数据包超时时间，如果超时时间内没有任何数据包到达则超时，如果超时，则 <strong>packet_size</strong> 和 <strong>max_window</strong> 将都会被设置为最小数据包大小（150 字节）。 <strong>（疑问？：packet_size 的调整策略是什么）</strong></p><h3 id="超时时间的计算"><a href="#超时时间的计算" class="headerlink" title="超时时间的计算"></a>超时时间的计算</h3><p>每当收到一个数据包的 ACK，就会更新往返时间（不考虑重传的包），往返时间用于计算超时时间。先说明下相关的变量：</p><ul><li><strong><em>rtt</em></strong>：往返时间；</li><li><strong><em>rtt_var</em></strong>：往返时间差异；</li><li><strong><em>packet_rtt</em></strong>：当前收到 ACK 对应的包的往返时间，即当前时间减去这个包发送时的时间，即首部中的 timestamp 字段记录的值。</li><li><strong><em>timeout</em></strong>：超时时间；</li></ul><p>通过以下公式更新 rtt：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">delta = rtt - packet_rtt</span><br><span class="line">rtt_var += (abs(delta) - rtt_var) / 4;</span><br><span class="line">rtt += (packet_rtt - rtt) / 8;</span><br></pre></td></tr></table></figure><p>正常情况下通过 rtt 计算得到 timeout（第一次由于没有 rtt，timeout 使用初始值 1000 ms，）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">timeout = max(rtt + rtt_var * 4, 500);</span><br></pre></td></tr></table></figure><p>如果遇到超时，则 timeout 翻倍。</p><h2 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h2><p>在<strong>丢包</strong>和<strong>超时</strong>部分已经涉及到拥塞窗口的调整了。µTP 的拥塞控制可以理解为一种基于延迟的负反馈拥塞控制，通过延迟的变化控制窗口大小的变化，达到拥塞控制目的。计算窗口大小过程中的相关常量和变量的定义如下：</p><ul><li><strong><em>CONTROL_TARGET</em></strong>：µTP 所能接收的上行缓冲延迟，现在是 100 ms；</li><li><strong><em>base_delay</em></strong>：两分钟内的收到的数据包的最低延迟；</li><li><strong><em>our_delay</em></strong>：当前的数据包延迟；</li><li><strong><em>off_target</em></strong>：实际延迟和目标延迟的差距。即<code>CONTROL_TARGET - our_delay</code>；</li><li><strong><em>outstanding_packet</em></strong>：已经被发送但是未被确认的数据包；</li></ul><p>具体计算过程如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">delay_factor = off_target / CCONTROL_TARGET;</span><br><span class="line">window_factor = outstanding_packet / max_window;</span><br><span class="line">scaled_gain = MAX_CWND_INCREASE_PACKETS_PER_RTT * delay_factor * window_factor;</span><br><span class="line"></span><br><span class="line">max_window += scaled_gain;</span><br></pre></td></tr></table></figure><p>当 <code>off_target &gt; 0</code> 时，当前包的延迟时间比设定的还小一些，那么窗口会缩小，发送速率就会放慢；反之，窗口增加，速率加快。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="http://www.bittorrent.org/beps/bep_0029.html" target="_blank" rel="noopener">BitTorrent Enhancement Proposal 29 - µTorrent transport protocol</a></li><li><a href="https://tools.ietf.org/html/rfc6817" target="_blank" rel="noopener">RFC 6817 - Low Extra Delay Background Transport (LEDBAT)</a></li><li><a href="http://www.calvinneo.com/2017/12/05/libutp%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/" target="_blank" rel="noopener">Calvin’s Marbles - libutp源码简析</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
    
      <category term="BT" scheme="https://0ranga.com/tags/BT/"/>
    
      <category term="Network" scheme="https://0ranga.com/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>TCP 温故知新</title>
    <link href="https://0ranga.com/2018/07/20/tcp/"/>
    <id>https://0ranga.com/2018/07/20/tcp/</id>
    <published>2018-07-19T16:00:00.000Z</published>
    <updated>2020-07-18T07:11:02.027Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>生产环境遇到些网络问题，知对 TCP 协议还是有些生疏，在此复习记录。</p><a id="more"></a><h2 id="协议"><a href="#协议" class="headerlink" title="协议"></a>协议</h2><h3 id="报文段格式"><a href="#报文段格式" class="headerlink" title="报文段格式"></a>报文段格式</h3><p>TCP 协议报文段主要由<strong>首部（Header）</strong> 与<strong>数据（Data）</strong> 两部分组成。在计算校验和是还会加上虚拟的伪首部。此处主要说明首部的组成。<br><img src="tcp_header.png" alt="图 1 TCP Header (From: WikiPedia)"><br>TCP 在网络模型中属于运输层，用于提供进程与进程间的字节流通信服务，因此需要<strong>源 / 目端口（Source / Destination port）</strong> 以确定通信双方进程。使用<strong>序号（Sequence number，seq）</strong> 表明本报文段第一个数据字节的编号，初始序号由双方在 TCP 连接建立时随机生成。使用<strong>确认号（Acknowledgment number，ack）</strong> 表示接受方期望从发送方接受的字节编号。<strong>数据偏移量（Data Offset）</strong> 顾名思义报文段数据开始字节处的偏移量，即 TCP header 的长度，由于选项的存在，首部长度的范围是 20～60 Bytes，但是该字段只有 4 Bits，因此该字段指出首部长度有多少个 4 Bytes。接下来的 3 Bits 被<strong>保留（Reserved）</strong> 。随后会讨论 9 个<strong>标志位（Flags）</strong>。<strong>窗口大小（Window Size）</strong> 定义了接受方的接受窗口大小，由接受方决定，然后告知发送方。在计算<strong>校验和（Checksum）</strong> 时需要加上伪首部，伪首部的内容包括源目 IP 地址，TCP 报文段长度等。如果 URG 标志位被设定了，那<strong>紧急指针（Urgent pointer）</strong> 用于指示紧急数据最后一个字节在报文段数据部分中的偏移量。最后的 40 Bytes 留给<strong>选项（Options）</strong>。</p><h3 id="Flags"><a href="#Flags" class="headerlink" title="Flags"></a>Flags</h3><ul><li><strong>URG</strong>：为 1 表示数据中有紧急数据。这个标记比较少见，可以找到的一些应用有：<a href="https://stackoverflow.com/questions/24476458/understanding-tcp-urg-flag" target="_blank" rel="noopener">FTP</a>，<a href="http://packetlife.net/blog/2011/mar/2/tcp-flags-psh-and-urg/" target="_blank" rel="noopener">Telnet</a>；</li><li><strong>ACK</strong>：为 1 表示确认号字段有效；</li><li><strong>PSH</strong>：为 1 表示有推送数据，这个字段主要完成<a href="http://packetlife.net/blog/2011/mar/2/tcp-flags-psh-and-urg/" target="_blank" rel="noopener">两个功能</a>：发送方应用层提醒 TCP 需要立即发送数据；接受方 TCP 需要将收到的数据立即提交给应用层；</li><li><strong>RST</strong>：为 1 表示出现严重差错。可能需要重现创建 TCP 连接。还可以用于拒绝非法的报文段和拒绝连接请求；</li><li><strong>SYN</strong>：为 1 表示这是连接请求或是连接接受请求，用于创建连接和使顺序号同步；</li><li><strong>FIN</strong>：为 1 表示发送方没有数据要传输了，要求释放连接；</li></ul><h2 id="阶段"><a href="#阶段" class="headerlink" title="阶段"></a>阶段</h2><p>TCP 连接可以分为三个阶段：建立连接，传输数据，终止连接。可以用一个有限状态机表示：<br><img src="tcp_connection.png" alt="图 2 TCP 连接 (From: Computer Networks)&lt;br&gt;图中（A/B）这样的文字表示“收到A后执行B，A与B可以是标志位或者指令”&lt;br&gt;深实线表示 Client 的行为，深虚线表示 Server 的行为，浅色线表示特殊行为"><br>下面结合一个用 Rust 写的 Echo Server 与抓包工具 Wireshark 来演示这三个过程。代码如下：</p><figure class="highlight rust"><figcaption><span>Echo Server</span><a href="/downloads/code/echo_server.rs">view raw</a></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> std::net::{TcpListener, TcpStream};</span><br><span class="line"><span class="keyword">use</span> std::thread;</span><br><span class="line"><span class="keyword">use</span> std::io::Read;</span><br><span class="line"><span class="keyword">use</span> std::io::Write;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() {</span><br><span class="line">    <span class="keyword">let</span> listener = TcpListener::bind(<span class="string">"::1:9999"</span>).unwrap();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> stream <span class="keyword">in</span> listener.incoming() {</span><br><span class="line">        <span class="keyword">match</span> stream {</span><br><span class="line">            <span class="literal">Ok</span>(stream) =&gt; {</span><br><span class="line">                thread::spawn(|| {</span><br><span class="line">                    handle_client(stream);</span><br><span class="line">                });</span><br><span class="line">            }</span><br><span class="line">            <span class="literal">Err</span>(_) =&gt; {</span><br><span class="line">                <span class="built_in">println!</span>(<span class="string">"Error"</span>);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">handle_client</span></span>(<span class="keyword">mut</span> stream: TcpStream) {</span><br><span class="line">    <span class="keyword">loop</span> {</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut</span> read = [<span class="number">0</span>; <span class="number">1024</span>];</span><br><span class="line">        <span class="keyword">match</span> stream.read(&amp;<span class="keyword">mut</span> read) {</span><br><span class="line">            <span class="literal">Ok</span>(n) =&gt; {</span><br><span class="line">                <span class="keyword">if</span> n == <span class="number">0</span> {</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                }</span><br><span class="line">                stream.write(&amp;read[<span class="number">0</span>..n]).unwrap();</span><br><span class="line">            }</span><br><span class="line">            <span class="literal">Err</span>(err) =&gt; {</span><br><span class="line">                <span class="built_in">panic!</span>(err);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure><p>Echo Server 启动之后使用 telnet 工具连接至服务器，与服务器交互两次，即回显两次字符串，然后从退出 telnet。抓到的包截图如下：<br><img src="wireshark.png" alt="图 3 Wireshark 抓包"></p><p>在下面的表述中，客户端表示在这一阶段先发起请求的一方，服务端表示在这一阶段先接受请求的一方。在 TCP 中，服务端和客户端之间可以进行双向通信，他们可以理解为对等的，在连接建立后，实际上没有服务端和客户端的区别。</p><h3 id="建立连接"><a href="#建立连接" class="headerlink" title="建立连接"></a>建立连接</h3><p>前三个包代表了建立连接的过程，分为三步，大多数情况下就如同抓包所示，称为<strong>三次握手（3-way handshake）</strong>。图 2 中还画出了双方同时打开连接与连接复位这两种比较少见的情景。</p><ol><li>客户端发送给服务端一个 <strong>SYN</strong> 报文，用以告知服务端初始序号为 0（此处的 Seq 经过 Wireshark 的处理，变成了相对值），然后客户端进入 <strong><em>SYN_SENT</em></strong> 状态。</li><li>服务器收到 1 中报文后，发给客户端一个 <strong>SYN + ACK</strong> 报文，告知客户端初始序号为 0，且接下来期望从客户端收到的序号 Ack 为 1。服务端进入 <strong><em>SYN_RCVD</em></strong> 状态。可见 <strong>SYN 报文消耗了一个序号</strong>。</li><li>客户端给服务端回复 <strong>ACK</strong> 报文，进入 <strong><em>ESTABLISHED</em></strong> 状态，服务端在收到这个报文连接建立完成。可见 <strong>ACK 报文在不携带数据的情况下不消耗序号</strong>。</li></ol><h3 id="传输数据"><a href="#传输数据" class="headerlink" title="传输数据"></a>传输数据</h3><p>图 3 中 P17～P20 与 P72～P74 分别展示了两次交互过程。以第二次交互为例：</p><ol><li>P72 中，客户端将想要回显字符串发送给服务端，告知服务器这个报文段的数据首字节序号为 8，并且希望从服务端收到的下一个序号是 8。</li><li>服务端将回显的字符串与对 P72 的确认一起发送给客户端。P72 的长度为 9，因此报文段中数据的序号范围为 [8,17)，因此在 P73 中 Ack 为 17。</li><li>客户端确认 P73。</li></ol><p>需要注意的是，这两次交互有所区别：第一次交互时，服务端先返回了一个确认给客户端，然后再额外发送一条携带回显内容的报文段。但是第二次交互时省略了单独的确认。</p><h3 id="终止连接"><a href="#终止连接" class="headerlink" title="终止连接"></a>终止连接</h3><p>根据“广大博主”写作的文章与<a href="https://www.zhihu.com/question/50646354" target="_blank" rel="noopener">问答网站的讨论</a>以及各种面经，基本一致认为，终止连接通常被成为<strong>四次挥手（4-way termination）</strong>，即通信双方会有四次交互，但是如图 2 所示，也存在<strong>三次挥手</strong>的可能性，且我本地的多次抓包也如图 3 一致——均为三次挥手，且无一例外。下面对四次挥手进行分析，三次挥手可以被其概括：</p><ol><li>客户端发起终止连接，发出一个 <strong>FIN</strong> 报文给服务端，假设该报文的 Seq 为 X，Ack 为 Y。然后客户端进入 <strong><em>FIN_WAIT1</em></strong> 状态，除重传 FIN 报文与发送 ACK 确认之外，不再发送应用数据给服务端。</li><li>服务端收到 FIN 报文段后先回复一个 <strong>ACK</strong> 报文，进入 <strong><em>CLOSE_WAIT</em></strong> 状态，该报文的 Seq 为 Y，Ack 为 X+1。</li><li>客户端在收到 FIN 的 ACK 之后进入 <strong><em>FIN_WAIT2</em></strong> 状态。此时服务端还可以继续将未发送完的应用数据发送给客户端。</li><li>服务端发送完数据后发送一条 <strong>FIN</strong> 报文，进入 <strong><em>LAST_ACK</em></strong> 状态，该报文的 Seq 为 Y+K，Ack 为 X+1。</li><li>客户端收到服务端的 FIN 后，发送最后的 <strong>ACK</strong> 报文给服务器，然后进入 <strong><em>TIME_WAIT</em></strong> 状态。如果在 2MSL（最大报文段寿命，通常为30～60s）后客户端没再次收到 FIN 报文，则进入 <strong><em>CLOSED</em></strong> 状态，否则重发 ACK 报文进行重试。</li><li>服务端在收到 ACK 报文后进入 <strong><em>CLOSED</em></strong> 状态。</li></ol><p>三次挥手表现为步骤 2～4 合并为一步，即同时发送对客户端 FIN 的 ACK 报文与 服务端自己的 FIN 报文。这条 <strong>FIN+ACK</strong> 报文的 Seq 为 Y，Ack 为 X+1。</p><p>至于在什么情景下出现三次握手或者四次握手，大多数的观点认为先收到 FIN 报文的一方还需要向上层应用询问是否仍然有数据需要发送，因为要等待上层的回复，所以“为何不早点把对 FIN 的 ACK 发出去呢？！”而且立即 Ack 能防止对方重传 FIN。但是有没有存在不需要询问上层或者不需要立即回复 Ack 的可能，就如同传输数据出现的情况一样，这些应该与 TCP 的具体实现相关，目前能力与精力有限，还有待对 <a href="https://github.com/torvalds/linux/blob/master/net/ipv4/tcp_output.c" target="_blank" rel="noopener">Linux TCP 实现源码</a>进行阅读。</p><h2 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h2><p>滑动窗口是 TCP 中用于实现诸如 ACK 确认、流量控制、拥塞控制的承载结构。如图所示:<br><img src="sliding_window.png" alt="图 4 滑动窗口"><br>先将 TCP 看作是简单的单向通信，则发送方有一个发送窗口，接收方有一个接收窗口。正如图中所示，传输的是报文段，窗口大小的单位是字节。两个窗口中<strong>白色区域</strong>为空白位置，等待被应用层或者网络层填满；<strong>灰色区域</strong>是已经发送但是还没有接受到确认的字节；<strong>粉色区域</strong>在发送窗口中表示等待被发送的字节，在接收窗口汇总表示等待交付的字节。<br>发送窗口的大小为接受方通过首部中窗口大小字段告知的接收窗口大小 rwnd 和之后会讲到的拥塞窗口的大小 cwnd 两者中的较小值，即 <code>min(rwnd , cwnd)</code>。接收窗口大小是接收方可用缓存空间大小，为 <code>rwnd = 缓存大小 - 准备交付的字节数</code>。</p><h2 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h2><p>流量控制用于平衡生产者产生数据与消费者消耗数据的速度。TCP 中的流量控制实现的主要途径是不断调整发送窗口的大小实现。发送 TCP 一旦发现发送发送窗口满了就会对发送进程进行反馈。接受方根据之前从发送方收到的数据量和服务器已经消耗的数据量得到自身接收窗口的大小，将这个值告知发送方，发送方根据收到的窗口大小调整自身窗口大小。<br>还有正对通信双方产生数据小或者消费数据慢产生糊涂窗口综合征时，有其他方面的流量控制。当发送方数据量相对于首部小很多的报文很多时，可以使用 <strong>Nagle 算法</strong>减少这种小报文量。当接受方消耗数据很慢时，每次告知发送方的窗口大小会比较小，也可能产生很多小报文，此时可以使用 <strong>Clark 解决方法</strong>或者进行<strong>推迟确认</strong>。关于这几种方案的分析及具体的使用情景可以参考 dog520 大神的这篇文章——<a href="https://blog.csdn.net/dog250/article/details/21303679" target="_blank" rel="noopener">再次谈谈 TCP 的 Nagle 算法与 TCP_CORK 选项</a>。</p><h2 id="差错控制"><a href="#差错控制" class="headerlink" title="差错控制"></a>差错控制</h2><p>差错控制用于描述 TCP 在发送或者接受到报文段发生异常时的行为，其主要表现在如下几个方面：</p><ol><li><strong>校验和</strong>：在接受方，如果收到的报文段未通过校验和校验，则立即丢弃，反之，则通过<strong>确认规则</strong>（下面马上提及）进行确认；</li><li><strong>重传</strong>：在发送方，如果一个报文段重传超时计时器（RTO）超时，即在 RTO 时间之后仍然未收到 ACK，则立即重传未被确认的最小的报文段；如果收到四个相同的的 ACK ，则立即重传下一个报文段；</li></ol><h3 id="确认规则"><a href="#确认规则" class="headerlink" title="确认规则"></a>确认规则</h3><ol><li>当接受方向发送方发送数据报文段时，必须<strong>捎带</strong> ACK；</li><li>当接受方没有数据要发送时，但是收到一个<strong>按序到达</strong>的报文，同时前一个报文段也已经确认过了，那么接收方就推迟发送确认报文段，直到另一个报文段到达或者延迟一段时间以减少 ACK 报文量；</li><li>当所期望的报文段到达，且前一个<strong>按序到达</strong>的报文还未被确认，则立即 ACK（ACK 的序号仍然是下一个正常期望的序号，下同）；</li><li>当序号比期望的大的报文段（<strong>失序</strong>报文段）到达，则立即 ACK，且存储该报文段；</li><li>当<strong>丢失</strong>的报文段到达时，则立即 ACK；</li><li>当<strong>重复</strong>的报文段到达时，则丢弃，且立即 ACK；</li></ol><h2 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h2><p>拥塞控制是为了避免因为网络受限导致网络不能按照发送方产生的数据的速度将报文段交付给接受方。与流量控制考察的对象是通信双方不同，拥塞控制的考察对象是通信双方间的网络。拥塞控制的方式表现在发送方的拥塞窗口的变化，从而控制发送方的数据发送快慢。TCP 最初使用的拥塞策略称为 <strong>TCP Tahoe and Reno</strong>。</p><h3 id="Tahoe-and-Reno"><a href="#Tahoe-and-Reno" class="headerlink" title="Tahoe and Reno"></a>Tahoe and Reno</h3><p>这个拥塞策略主要分为慢启动、拥塞避免、拥塞检测三个阶段。</p><h4 id="慢启动"><a href="#慢启动" class="headerlink" title="慢启动"></a>慢启动</h4><p>假设接收窗口大小远大于拥塞窗口，且不考虑延迟确认。拥塞窗口大小从一个最大报文长度 MSS （连接建立时通过 TCP 选项告知）开始，之后每当有一个报文段被确认，拥塞窗口就增大一个 MSS。在这样的策略下，慢启动阶段的拥塞窗口大小呈指数增长。即从 <code>1 -&gt; 2 -&gt; 4 -&gt; 8</code>。当到达慢启动门限时，就进入拥塞避免阶段。</p><h4 id="拥塞避免"><a href="#拥塞避免" class="headerlink" title="拥塞避免"></a>拥塞避免</h4><p>拥塞避免阶段拥塞窗口大小继续增加，但是速度放慢，改成当整个窗口大小的报文段都被确认后，窗口大小才增加一个 MSS。表现为 <code>8 -&gt; 9 -&gt; 10 -&gt; 11</code>，呈现线性增长。</p><h4 id="拥塞检测"><a href="#拥塞检测" class="headerlink" title="拥塞检测"></a>拥塞检测</h4><p>如果拥塞发生了，因为发生在网络中路由器出现丢包现象，在接受方处的表现为出现以下两种情况，并做出对应的反应：</p><ol><li><p>RTO 计时器超时。这说明网络拥塞的可能性较大，TCP 做出较强烈的反应：<br> a. 把慢启动门限值调整为当前窗口大小的一半；<br> b. 把 cwnd 重新设置为 1 MSS；<br> c. 重新进入慢启动阶段；</p></li><li><p>收到四个相同的 ACK；说明出现拥塞的可能性较小，但是出现了丢包，TCP 做出较弱的反应，Reno 算法表现为快恢复（Fast recovery）：<br> a. 把慢启动门限值调整为当前窗口大小的一半；<br> b. 把 cwnd 重新设置为慢启动门限值；<br> c. 重新进入拥塞避免阶段；</p></li></ol><p>图示如下：<br><img src="congestion_control_example.png" alt="拥塞控制示例"><br>Tahoe 算法与 Reno （Tahoe 的改进版本）的区别在于收到四个相同 ACK 时，Tahoe 算法的策略和 RTO 计时器超时时一致。</p><h3 id="其他拥塞策略"><a href="#其他拥塞策略" class="headerlink" title="其他拥塞策略"></a>其他拥塞策略</h3><p>拥塞控制策略只需要在发送方实现即可，不需要接受方的参与，因此可以仅在发送方部署一套算法。现在 TCP 网络上的算法也在不断<a href="https://en.wikipedia.org/wiki/TCP_congestion_control" target="_blank" rel="noopener">改进</a>，涌现出诸如 <a href="http://www4.ncsu.edu/~rhee/export/bitcp/cubic-paper.pdf" target="_blank" rel="noopener"><strong>TCP CUBIC</strong></a>、<a href="https://ai.google/research/pubs/pub45646" target="_blank" rel="noopener"><strong>TCP BBR</strong></a> 这样的算法。</p><h2 id="TCP-中的计时器"><a href="#TCP-中的计时器" class="headerlink" title="TCP 中的计时器"></a>TCP 中的计时器</h2><h3 id="重传计时器"><a href="#重传计时器" class="headerlink" title="重传计时器"></a>重传计时器</h3><p>重传计时器的超时时间为 RTO，RTO 主要根据测量所得的报文段往返时间 RTTm计算而来，计算过程如下：</p><p>首先计算平滑 RTT，即RTTs：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RTTs = RTTm // 第一次测量</span><br><span class="line">RTTs = (1 - α)RTTs + αRTTm // 随后的测量</span><br></pre></td></tr></table></figure><p>然后计算 RTT 的偏差 RTTd：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RTTd = RTTm / 2 // 第一次测量</span><br><span class="line">RTTd = (1 - β)RTTd + β|RTTs - RTTm| // 随后的测量</span><br></pre></td></tr></table></figure><p>重传超时 RTO 的计算如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RTO = 6s // 原始值</span><br><span class="line">RTO = RTTs + 4RTTd // 第一次测量后</span><br></pre></td></tr></table></figure><p>任意时刻只有一个 RTT 在进行测量，当重传发生时会影响 RTT 的测量，根据 <strong>Karn 算法</strong>，TCP 忽略重传报文的 RTT，而对于重传的报文，RTO 值为原报文的两倍，如果发生第二次重传，则为四倍，以此类推。</p><h3 id="持续计时器"><a href="#持续计时器" class="headerlink" title="持续计时器"></a>持续计时器</h3><p>当接受方发送窗口值为 0 的报文段之后，后来因为接收窗口增加需要通告接窗口为非 0，但是通告的 ACK 丢失，这会导致发送方一直等待非 0 窗口通告，导致死锁。持续计时器就是接受方在收到 0 窗口通告后启用，如果超时则发送探测报文，促使接受方重传 ACK。</p><h3 id="Keep-Alive-计时器"><a href="#Keep-Alive-计时器" class="headerlink" title="Keep-Alive 计时器"></a>Keep-Alive 计时器</h3><p>Keep-Alive 计时器用于防止 TCP 连接长时间空闲，每当收到对方的报文段，这个计时器就复位。这个计时器的超时时间通常可以通过接口进行设定。</p><h3 id="Time-Wait-计时器"><a href="#Time-Wait-计时器" class="headerlink" title="Time-Wait 计时器"></a>Time-Wait 计时器</h3><p>Time-Wait 计时器对最后的 FIN 进行确认时启动的超时计时器。如果在时常为 2MSL 的计时器超时前再次收到 FIN，则重传 ACK，否则连接彻底关闭。</p><h2 id="传输层的未来"><a href="#传输层的未来" class="headerlink" title="传输层的未来"></a>传输层的<a href="https://blog.apnic.net/2017/12/12/internet-protocols-changing/" target="_blank" rel="noopener">未来</a></h2><p><a href="https://www.chromium.org/quic" target="_blank" rel="noopener">QIUC</a> 了解一下下？</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://book.douban.com/subject/5386194/" target="_blank" rel="noopener">TCP/IP 协议族 第四版</a></li><li><a href="https://book.douban.com/subject/5344443/" target="_blank" rel="noopener">Andrew S.Tanenbaum - Computer Networks 5th</a></li><li><a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol" target="_blank" rel="noopener">WikiPedia - Transmission Control Protocol</a></li><li><a href="https://en.wikipedia.org/wiki/TCP_congestion_contro" target="_blank" rel="noopener">WikiPedia - TCP congestion control</a></li><li><a href="http://packetlife.net/blog/2011/mar/2/tcp-flags-psh-and-urg/" target="_blank" rel="noopener">TCP Flags: PSH and URG</a></li><li><a href="https://www.nada.kth.se/kurser/kth/2D1392/05/lectures/lecture_4.pdf" target="_blank" rel="noopener">KTH - Internetworking Lecture 4</a></li><li><a href="https://blog.csdn.net/dog250/article/details/81256550" target="_blank" rel="noopener">一个 TCP FIN_WAIT2 状态细节引发的感慨</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;生产环境遇到些网络问题，知对 TCP 协议还是有些生疏，在此复习记录。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Network" scheme="https://0ranga.com/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>闲云孤鹤</title>
    <link href="https://0ranga.com/2018/07/10/hello-world/"/>
    <id>https://0ranga.com/2018/07/10/hello-world/</id>
    <published>2018-07-10T13:24:55.000Z</published>
    <updated>2018-07-10T13:24:55.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Blog</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"斯是陋室，惟吾德馨"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
    
      <category term="Essay" scheme="https://0ranga.com/tags/Essay/"/>
    
  </entry>
  
</feed>
